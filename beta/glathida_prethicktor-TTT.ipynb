{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install ing_theme_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import qbstyles\n",
    "# from ing_theme_matplotlib import mpl_style\n",
    "import glacierml as gl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Organize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load and organize the Glathida dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa42/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (2,4,5,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POINT_LAT</th>\n",
       "      <th>POINT_LON</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>THICKNESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.767380</td>\n",
       "      <td>-121.819644</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.764904</td>\n",
       "      <td>-121.821909</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.761662</td>\n",
       "      <td>-121.825264</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.757063</td>\n",
       "      <td>-121.829107</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.753715</td>\n",
       "      <td>-121.832006</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854274</th>\n",
       "      <td>47.092690</td>\n",
       "      <td>12.380504</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854275</th>\n",
       "      <td>47.093780</td>\n",
       "      <td>12.379642</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854276</th>\n",
       "      <td>47.094839</td>\n",
       "      <td>12.378200</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854277</th>\n",
       "      <td>47.094829</td>\n",
       "      <td>12.378174</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854278</th>\n",
       "      <td>47.094853</td>\n",
       "      <td>12.374525</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3854279 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POINT_LAT   POINT_LON  ELEVATION  THICKNESS\n",
       "0        48.767380 -121.819644     2962.0          0\n",
       "1        48.764904 -121.821909     2813.0         29\n",
       "2        48.761662 -121.825264     2598.0         41\n",
       "3        48.757063 -121.829107     2383.0         71\n",
       "4        48.753715 -121.832006     2284.0         82\n",
       "...            ...         ...        ...        ...\n",
       "3854274  47.092690   12.380504     3329.0         36\n",
       "3854275  47.093780   12.379642     3353.0         26\n",
       "3854276  47.094839   12.378200     3381.0         39\n",
       "3854277  47.094829   12.378174     3381.0         39\n",
       "3854278  47.094853   12.374525     3369.0         50\n",
       "\n",
       "[3854279 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTT = pd.read_csv('/home/sa42/data/glac/T_models/TTT.csv')\n",
    "TTT = TTT.drop([\n",
    "    'GlaThiDa_ID',\n",
    "    'POLITICAL_UNIT',\n",
    "    'GLACIER_NAME',\n",
    "    'SURVEY_DATE',\n",
    "    'PROFILE_ID',\n",
    "    'POINT_ID',\n",
    "#     'POINT_LAT',\n",
    "#     'POINT_LON',\n",
    "#     'ELEVATION',\n",
    "#     'THICKNESS',\n",
    "    'THICKNESS_UNCERTAINTY',\n",
    "    'DATA_FLAG',\n",
    "    'REMARKS'\n",
    "],axis=1)\n",
    "TTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate out features - what will be trained to predict desired attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POINT_LAT</th>\n",
       "      <td>51.085289</td>\n",
       "      <td>50.990492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POINT_LON</th>\n",
       "      <td>-38.778802</td>\n",
       "      <td>47.801070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATION</th>\n",
       "      <td>1175.125764</td>\n",
       "      <td>937.657677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean         std\n",
       "POINT_LAT    51.085289   50.990492\n",
       "POINT_LON   -38.778802   47.801070\n",
       "ELEVATION  1175.125764  937.657677"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TTT.sample(frac=0.8, random_state=0)\n",
    "test_dataset = TTT.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "#define label - attribute training to be picked\n",
    "train_labels = train_features.pop('THICKNESS')\n",
    "test_labels = test_features.pop('THICKNESS')\n",
    "\n",
    "train_features.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Setup the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]2022-03-23 16:47:10.491506: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-23 16:47:10.491964: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sermeq.ess.washington.edu): /proc/driver/nvidia/version does not exist\n",
      "2022-03-23 16:47:10.492930: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "100%|██████████| 3/3 [01:44<00:00, 35.00s/it]\n"
     ]
    }
   ],
   "source": [
    "normalizer = {}\n",
    "variable_list = list(train_features)\n",
    "for variable_name in tqdm(variable_list):\n",
    "\n",
    "    normalizer[variable_name] = gl.preprocessing.Normalization(input_shape=[1,], axis=None)\n",
    "    normalizer[variable_name].adapt(np.array(train_features[variable_name]))\n",
    "    \n",
    "    \n",
    "normalizer['ALL'] = gl.preprocessing.Normalization(axis=-1)\n",
    "normalizer['ALL'].adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = {}\n",
    "linear_history = {}\n",
    "linear_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for variable_name in tqdm(variable_list):\n",
    "\n",
    "    linear_model[variable_name] = gl.build_linear_model(normalizer[variable_name])\n",
    "    linear_history[variable_name] = linear_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=100,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    \n",
    "    \n",
    "    linear_results[variable_name] = linear_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(2,6,figsize=(10,10))\n",
    "# for i, variable_name in enumerate(variable_list):\n",
    "# #     mpl_style(\"dark\")\n",
    "#     ax = plt.subplot(4,4,i+1)\n",
    "#     plt.subplot(4,4,i+1)\n",
    "#     gl.plot_loss(linear_history[variable_name])\n",
    "#     ax.set_title(variable_name)\n",
    "# #     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = gl.build_linear_model(normalizer['ALL'])\n",
    "\n",
    "linear_history['MULTI'] = linear_model.fit(\n",
    "train_features, train_labels,        \n",
    "   epochs=100,\n",
    "   verbose=0,\n",
    "   validation_split = 0.2)\n",
    "\n",
    "linear_results['MULTI'] = linear_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gl.plot_loss(history_full)\n",
    "# # plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_full_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = {}\n",
    "dnn_history = {}\n",
    "dnn_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for variable_name in tqdm(variable_list):\n",
    "\n",
    "    dnn_model[variable_name] = gl.build_dnn_model(normalizer[variable_name])\n",
    "    dnn_history[variable_name] = dnn_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=100,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    dnn_results[variable_name] = dnn_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "# for i, variable_name in enumerate(variable_list):\n",
    "#     plt.subplot(4,4,i+1)\n",
    "#     xmax = np.max(train_features[variable_name])\n",
    "#     xmin = np.min(train_features[variable_name])\n",
    "#     x = tf.linspace(xmin, xmax, 101)\n",
    "#     y = dnn_model[variable_name].predict(x)\n",
    "#     plot_single_model_variable(x,y,variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "fig.patch.set_facecolor('w')\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    gl.plot_loss(dnn_history[variable_name])\n",
    "    ax.set_ylim([13,22])\n",
    "    ax.set_title(variable_name)\n",
    "#     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_loss.eps\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_full_model = gl.build_dnn_model(normalizer['ALL'])\n",
    "\n",
    "dnn_history['MULTI'] = dnn_full_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100)\n",
    "\n",
    "dnn_results['MULTI'] = dnn_full_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.plot_loss(dnn_history['MULTI'])\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_full_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dnn_full_model.predict(test_features)\n",
    "plt.plot(test_labels,y,'.')\n",
    "plt.plot((0,200),(0,200),'-')\n",
    "plt.xlabel('True Thickness (m)')\n",
    "plt.ylabel('Model Thickness (m)')\n",
    "plt.xlim((0,200))\n",
    "plt.ylim((0,200))\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_res.EPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame()\n",
    "for variable_name in list(dnn_history):    \n",
    "    df1 = pd.DataFrame(dnn_history[variable_name].history)\n",
    "    df1 = df1.loc[[df1.last_valid_index()]]\n",
    "    df1['Architecture'] = 'DNN'\n",
    "    df1.insert(0, 'Variable', [variable_name])\n",
    "\n",
    "    df2 = pd.DataFrame(linear_history[variable_name].history)\n",
    "    df2 = df2.loc[[df2.last_valid_index()]]\n",
    "    df2['Architecture'] = 'Linear'\n",
    "    df2.insert(0, 'Variable', [variable_name])\n",
    "    \n",
    "    df = pd.concat([df1,df2])\n",
    "    dfs = dfs.append(df)\n",
    "    \n",
    "df = dfs[[\n",
    "    'Architecture',\n",
    "    'Variable',\n",
    "    'loss',\n",
    "    'val_loss'\n",
    "]]\n",
    "df.rename(columns = {\n",
    "    'loss':'Training Loss',\n",
    "    'val_loss':'Test loss'\n",
    "},inplace=True)\n",
    "df = df.sort_values(by=['Architecture','Variable'], ascending=[False,False])\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (Cartopy)-f",
   "language": "python",
   "name": "python-cartopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
