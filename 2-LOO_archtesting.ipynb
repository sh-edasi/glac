{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563ee1f5",
   "metadata": {},
   "source": [
    "#### Import dependancies and set environment determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4b08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:35:37.257995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "#     tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    0\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEED = 378\n",
    "# SEED = 123\n",
    "print(SEED)\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ec4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f8a64",
   "metadata": {},
   "source": [
    "#### define SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfc7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_path,l1,l2,loss):\n",
    "            \n",
    "    normalizer = preprocessing.Normalization(axis=-1)\n",
    "    normalizer.adapt(np.array(trfeat))\n",
    "\n",
    "    model = gl.build_dnn_model(\n",
    "        normalizer, learning_rate = 0.01, \n",
    "        layer_1 = l1, layer_2 = l2,loss = loss\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        trfeat,\n",
    "        trlabs,\n",
    "        validation_split=0.2,\n",
    "        callbacks = [callback],\n",
    "        verbose=0, \n",
    "        epochs=500\n",
    "    )\n",
    "    model_filename = os.path.join(model_path)\n",
    "    model.save(model_filename)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# # if os.path.isdir(res_dir) == False:\n",
    "\n",
    "# def run_model(model_path,l1,l2,loss,n):\n",
    "#     normalizer = preprocessing.Normalization(axis=-1)\n",
    "#     normalizer.adapt(np.array(trfeat[n]))\n",
    "\n",
    "#     model = gl.build_dnn_model(\n",
    "#         normalizer, learning_rate = 0.01, \n",
    "#         layer_1 = l1, layer_2 = l2,loss = loss\n",
    "#     )\n",
    "\n",
    "#     model_history = model.fit(\n",
    "#         trfeat[n],\n",
    "#         trlabs[n],\n",
    "#         validation_split=0.2,\n",
    "#         callbacks = [callback],\n",
    "#         verbose=0, \n",
    "#         epochs=500\n",
    "#     )\n",
    "\n",
    "#     model_results = model.evaluate(tefeat[n],telabs[n],verbose = 0)\n",
    "# #     model_filename = os.path.join(model_path)\n",
    "#     print(model_history)\n",
    "#     print(model_results)\n",
    "#     model.save(model_path)\n",
    "    \n",
    "#     return model, model_results, model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d42863",
   "metadata": {},
   "source": [
    "#### Create callback function to quit training if loss does not improve after 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6765b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.001,\n",
    "    patience = 10,\n",
    "    verbose = 0,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d66d34",
   "metadata": {},
   "source": [
    "#### Define path to save arch test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4787996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = ''\n",
    "\n",
    "arch_test_path = 'arch_testing'\n",
    "\n",
    "path = os.path.join(home_path,arch_test_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71058207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gl.coregister_data('4')\n",
    "# df = df[:-7]\n",
    "df = df.drop(df[df['RGIId'].duplicated(keep = False)].index)\n",
    "df = df.sample(frac = 1,random_state = 0)\n",
    "df = df.reset_index().drop('index', axis = 1)\n",
    "\n",
    "dft = df.copy()\n",
    "\n",
    "trfeat, tefeat, trlabs, telabs = gl.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b8f66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CenLat      CenLon  Slope  Zmin  Zmed  Zmax     Area  Aspect   Lmax\n",
      "218  77.285700   14.994900    5.3   135   407   917  312.535     229  35580\n",
      "259  78.107100   17.697800    9.5   110   445   773   39.032      87  13945\n",
      "225  44.572747   80.173226   16.6  3447  3719  3997    1.361     203   2396\n",
      "111  47.051000   12.409900   20.9  3053  3099  3150    0.052     122    280\n",
      "178  80.580500   50.433100   13.6     0   263   421  512.015     143  15512\n",
      "..         ...         ...    ...   ...   ...   ...      ...     ...    ...\n",
      "170  78.767800   12.191900    9.1     2   439   974   57.860     325  16274\n",
      "121  28.470000   85.816000    9.2  5710  5866  5944    1.327      30   1244\n",
      "140  37.746680 -119.282740   23.9  3598  3694  3779    0.263     359    440\n",
      "214  79.599900   12.207700   12.1    92   217   813   12.934      88   5762\n",
      "240  50.049675   87.745522   19.3  2355  3301  3696    2.619      49   3827\n",
      "\n",
      "[191 rows x 9 columns]        CenLat      CenLon  Slope  Zmin  Zmed  Zmax    Area  Aspect  Lmax\n",
      "1   -38.71120  -71.740500   14.4  1783  2167  3059   6.985     237  3688\n",
      "9    45.23513   80.808350   14.8  3191  3547  3826   2.286     347  2582\n",
      "11  -33.18750  -70.268900   29.7  3879  4371  4859   0.585     177  1747\n",
      "17   46.97400   11.152800   17.8  2510  3163  3404   2.534      13  2788\n",
      "25   44.10747 -121.783660   20.8  2297  2567  2857   0.557     318  1471\n",
      "..        ...         ...    ...   ...   ...   ...     ...     ...   ...\n",
      "260  45.92440    7.322840   19.4  2369  3057  4190   6.904      73  5756\n",
      "261  50.05558   87.507866   16.3  2833  3127  3359   1.102     110  2125\n",
      "263  49.85968   87.354538   15.7  2836  3056  3310   1.389      21  1818\n",
      "266  45.37141 -121.717890   29.0  1813  2450  3005   1.010     280  2294\n",
      "269  45.95660    7.457320   13.7  2477  3022  3748  11.614     248  8845\n",
      "\n",
      "[82 rows x 9 columns] 218    273.0\n",
      "259     74.0\n",
      "225     59.0\n",
      "111     22.0\n",
      "178    176.0\n",
      "       ...  \n",
      "170    175.0\n",
      "121     47.0\n",
      "140     17.0\n",
      "214     68.0\n",
      "240     86.0\n",
      "Name: Thickness, Length: 191, dtype: float64 1      16.0\n",
      "9      49.0\n",
      "11     23.0\n",
      "17     49.0\n",
      "25     21.0\n",
      "       ... \n",
      "260    82.0\n",
      "261    69.0\n",
      "263    51.0\n",
      "266    24.0\n",
      "269    43.0\n",
      "Name: Thickness, Length: 82, dtype: float64\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "l1_list = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "l2_list = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "loss_list = ['mse','mae']\n",
    "df = gl.coregister_data('4')\n",
    "df = df.iloc[:,:-7]\n",
    "\n",
    "df = df.drop(df[df['RGIId'].duplicated(keep = False)].index)\n",
    "\n",
    "df = df.sample(frac = 1,random_state = 0)\n",
    "df = df.reset_index().drop('index', axis = 1)\n",
    "\n",
    "dft = df.copy()\n",
    "\n",
    "trfeat, tefeat, trlabs, telabs = gl.split_data(df)\n",
    "print(trfeat,tefeat,trlabs,telabs)\n",
    "for loss in loss_list:\n",
    "    for l2 in l2_list:\n",
    "        for l1 in l1_list:\n",
    "            if l2 >= l1:\n",
    "                continue\n",
    "            else:\n",
    "\n",
    "                model = {}\n",
    "                model_history = {}\n",
    "                normalizer = {}\n",
    "#                 path = '/data/fast1/glacierml/models/LOO_loss_testing/'\n",
    "                model_path = os.path.join(\n",
    "                   path ,loss,str(l1)+'-'+str(l2)\n",
    "                )\n",
    "                res_dir = os.path.join(path, loss,'final_results.pkl')\n",
    "                if os.path.isdir(res_dir) == True:\n",
    "                    continue\n",
    "\n",
    "                isdir = model_path\n",
    "                if os.path.isdir(isdir) == True:\n",
    "                    continue\n",
    "                if os.path.isdir(isdir) == False:\n",
    "                    print(model_path)\n",
    "                    set_global_determinism(seed=SEED)\n",
    "                    run_model(model_path,l1,l2,loss)\n",
    "print('all done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# l1_list = [3,4,5,6]\n",
    "# l2_list = [2,3,4,5]\n",
    "# loss_list = ['mse','mae']\n",
    "# df = gl.coregister_data('4')\n",
    "# df = df.drop(df[df['RGIId'].duplicated(keep = False)].index)\n",
    "\n",
    "# df = df.sample(frac = 1,random_state = 0)\n",
    "# df = df.reset_index().drop('index', axis = 1)\n",
    "# df = df[list(df)[:-7]]\n",
    "\n",
    "# trfeat = {}\n",
    "# trlabs = {}\n",
    "# tefeat = {}\n",
    "# telabs = {}\n",
    "\n",
    "# for n in df.index:\n",
    "#     mask = df.index.isin([n])\n",
    "#     trfeat[n] = df.loc[~mask].drop(['RGIId','Thickness'], axis = 1)\n",
    "#     tefeat[n] = df.loc[mask].drop(['RGIId','Thickness'], axis = 1)\n",
    "#     trlabs[n] = df['Thickness'].loc[~mask]\n",
    "#     telabs[n] = df['Thickness'].loc[mask]\n",
    "\n",
    "# results = pd.DataFrame(\n",
    "#     columns = ['Coregistration','Arch','Metric','Loss']\n",
    "# )\n",
    "\n",
    "# for loss in loss_list:\n",
    "    \n",
    "#     res_dir = os.path.join(arch_test_path,loss,'final_results.pkl')\n",
    "#     if os.path.isdir(res_dir) == True:\n",
    "#         continue\n",
    "#     else:\n",
    "#         for l2 in l2_list:\n",
    "#             for l1 in l1_list:\n",
    "#                 if l2 >= l1:\n",
    "#                     continue\n",
    "#                 else:                    \n",
    "#                     model = {}\n",
    "#                     model_results = {}\n",
    "#                     model_history = {}\n",
    "#                     normalizer = {}\n",
    "#                     for n in tqdm(df.index):\n",
    "#                         model_path = os.path.join(\n",
    "#                         home_path,arch_test_path ,loss,str(l1)+'-'+str(l2), str(n)\n",
    "#                         )\n",
    "#                         if os.path.isdir(model_path) == True:\n",
    "#                             continue\n",
    "#                             #                             set_global_determinism(seed=SEED)\n",
    "\n",
    "#                         elif os.path.isdir(model_path) == False:\n",
    "#                             set_global_determinism(seed=SEED)\n",
    "#                             model, model_results, model_history = run_model(\n",
    "#                             model_path, l1, l2, loss, n\n",
    "#                             )\n",
    "#                             break\n",
    "# #                             print(model_results[n])\n",
    "# #                             print(model_history([n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbf0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.8.10)",
   "language": "python",
   "name": "new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
