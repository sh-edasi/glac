{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from scipy.stats import gaussian_kde\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import shapiro \n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e91d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pr = 0.075\n",
    "model = {}\n",
    "model_history = {}\n",
    "results = {}\n",
    "normalizer = {}\n",
    "y = {}\n",
    "test_features = {}\n",
    "test_labels = {}\n",
    "train_features = {}\n",
    "train_labels = {}\n",
    "l1 = {}\n",
    "l2 = {}\n",
    "q75 = {}\n",
    "q25 = {}\n",
    "iqr = {}\n",
    "gamma = {}\n",
    "unc = {}\n",
    "residuals = pd.DataFrame()\n",
    "for i in (range(1,5,1)):\n",
    "    m = str(i)\n",
    "\n",
    "    \n",
    "    df = gl.coregister_data(m)\n",
    "    df = df.drop(['RGIId'],axis = 1)\n",
    "#     df['Area'] = np.log(df['Area'])\n",
    "\n",
    "#     if m == '4':\n",
    "#         df = df.drop_duplicates(keep = False)\n",
    "#         df = df.drop(df[df['Thickness'] >= 300].index)\n",
    "#         df = df.drop(df[df['Thickness'] == 267].index)\n",
    "#         df = df.drop(df[df['Thickness'] == df['Thickness'].min()].index)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    total_inputs = (len(df.columns)) * len(df)\n",
    "    dp = pr * total_inputs\n",
    "    tp = dp - (len(df.columns) + (len(df.columns)-1) )\n",
    "    g = (len(df.columns) + (len(df.columns) - 1))\n",
    "    l2[m] = 4\n",
    "    l1[m] = int((dp - 1 - g - 2*l2[m]) / (10 + l2[m]))\n",
    "    \n",
    "    arch = str(l1[m]) + '-' + str(l2[m])\n",
    "\n",
    "    svd_mod_pth = 'saved_models/singles_' + m + '/' + arch \n",
    "    svd_res_pth = 'saved_results/singles_' + m + '/'\n",
    "    \n",
    "    \n",
    "    isdir = os.path.isdir(svd_mod_pth)\n",
    "    if isdir == False:\n",
    "        os.makedirs(svd_mod_pth)\n",
    "    isdir = os.path.isdir(svd_res_pth)\n",
    "    if isdir == False:\n",
    "        os.makedirs(svd_res_pth)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        min_delta = 0.001,\n",
    "        patience = 10,\n",
    "        verbose = 0,\n",
    "        mode = 'auto',\n",
    "        baseline = None,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    train_features[m], test_features[m], train_labels[m], test_labels[m] = gl.split_data(df)\n",
    "    normalizer = preprocessing.Normalization(axis=-1)\n",
    "    normalizer.adapt(np.array(train_features[m]))\n",
    "\n",
    "    model[m] = gl.build_dnn_model(\n",
    "        normalizer, learning_rate = 0.01, layer_1 = l1[m], layer_2 = l2[m],loss = 'mae'\n",
    "    )\n",
    "\n",
    "    model_history[m] = model[m].fit(\n",
    "        train_features[m],\n",
    "        train_labels[m],\n",
    "        validation_split=0.2,\n",
    "        callbacks = [callback],\n",
    "        verbose=0, \n",
    "        epochs=500\n",
    "    )\n",
    "    \n",
    "#     model[m].save(svd_mod_pth)\n",
    "#     pd.DataFrame(model_history[m].history).to_pickle(svd_res_pth + '.pkl')\n",
    "    \n",
    "    total_params = model[m].count_params()\n",
    "    print(f'parameters = {total_params}')\n",
    "\n",
    "    \n",
    "    trained_parameters = model[m].count_params() - (\n",
    "        len(df.columns) + (len(df.columns) - 1)\n",
    "    )\n",
    "    print(f'trained parameters = {trained_parameters}')\n",
    "    \n",
    "\n",
    "\n",
    "#     cp = 9 + l1[m]*((len(df.columns))) + l2[m]*(l1[m]+1)\n",
    "    cp = l1[m]*(9+1) + l2[m]*(l1[m]+1) + 1*(l2[m]+1) + g\n",
    "    print(f'counted params = {cp}')\n",
    "    \n",
    "    total_inputs = len(df) *( len(df.columns)-1)\n",
    "#     print(f'total inputs = {total_inputs})\n",
    "    parameter_ratio = np.round(trained_parameters / total_inputs,3)\n",
    "    print(f'parameter / input ratio = {parameter_ratio}')\n",
    "    print(l1[m],l2[m])\n",
    "#     print(trained_parameters)\n",
    "    \n",
    "    results[m] = model[m].evaluate(test_features[m], test_labels[m])\n",
    "    y[m] = model[m].predict(test_features[m]).flatten()\n",
    "    \n",
    "    full_res = str(i + 10)\n",
    "    y[full_res] =  (\n",
    "        (model[m].predict(df.drop('Thickness',axis = 1)).flatten() - df['Thickness']) \n",
    "    )\n",
    "    \n",
    "    \n",
    "    full_pred = str(i + 20)\n",
    "    y[full_pred] = (model[m].predict(df.drop('Thickness',axis = 1)).flatten())\n",
    "    \n",
    "    p_res = str(i + 30)\n",
    "    y[p_res] = (y[full_pred] - df['Thickness']) / df['Thickness']\n",
    "\n",
    "    q75[p_res] = np.percentile(y[p_res], 75)\n",
    "    q25[p_res] = np.percentile(y[p_res], 25)\n",
    "\n",
    "    iqr[p_res] = q75[p_res] - q25[p_res]\n",
    "    gamma[p_res] = iqr[p_res]\n",
    "\n",
    "    unc[m] = gamma[p_res] * y[full_pred]\n",
    "    \n",
    "    ver_res = y[full_pred] - df['Thickness']\n",
    "    ver_res_mean = np.mean(ver_res)\n",
    "    ver_res_std =  np.std(ver_res)\n",
    "    \n",
    "    test_res = (y[m] - test_labels[m]) \n",
    "    \n",
    "    tq75 = np.percentile(test_res,75)\n",
    "    tq25 = np.percentile(test_res,25)\n",
    "    TIQR = tq75 - tq25\n",
    "    \n",
    "    vq75 = np.percentile(ver_res,75)\n",
    "    vq25 = np.percentile(ver_res,25)\n",
    "    VIQR = vq75 - vq25\n",
    "    \n",
    "    test_res_m = pd.DataFrame(pd.Series(m,name = 'M'))\n",
    "    test_res_mean = pd.DataFrame(pd.Series(test_res.mean(), name = 'Test Res'))\n",
    "    test_res_std = pd.DataFrame(pd.Series(test_res.std(),name = 'Test STD'))\n",
    "\n",
    "\n",
    "    \n",
    "    test_res_mean = test_res_m.join(test_res_mean)\n",
    "    test_res_mean = test_res_mean.join(test_res_std)\n",
    "    test_res_mean['TRes Max'] = test_res.max()\n",
    "    test_res_mean['TRes Min'] = test_res.min()\n",
    "    test_res_mean['TRes IQR'] = TIQR\n",
    "    test_res_mean['VRes Mean'] = ver_res_mean    \n",
    "    test_res_mean['VRes STD'] = ver_res_std\n",
    "    test_res_mean['VRes Max'] = ver_res.max()\n",
    "    test_res_mean['VRes Min'] = ver_res.min()\n",
    "    test_res_mean['VRes IQR'] = VIQR\n",
    "\n",
    "    residuals = pd.concat([residuals,test_res_mean])\n",
    "    print('')\n",
    "res = pd.DataFrame(results,index = ['Loss']).T\n",
    "res = res.reset_index()\n",
    "\n",
    "residuals = residuals.reset_index()\n",
    "residuals = pd.concat([res, residuals], axis = 1, ignore_index = False)\n",
    "residuals = residuals.drop('index', axis = 1)\n",
    "residuals = residuals.rename(columns = {'Loss':'MAE'})\n",
    "\n",
    "cols = list(residuals.columns)\n",
    "a, b = cols.index('MAE'), cols.index('M')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "residuals = residuals[cols]\n",
    "\n",
    "residuals.sort_values('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f8886",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = str(residuals['M'].iloc[residuals['MAE'].abs().argsort()[0]])\n",
    "# m = '4'\n",
    "df = gl.coregister_data(m)\n",
    "# if m == '4':\n",
    "#     df = df.drop_duplicates(keep = False)\n",
    "#     df = df.drop(df[df['Thickness'] >= 300].index)\n",
    "#     df = df.drop(df[df['Thickness'] == 267].index)\n",
    "#     df = df.drop(df[df['Thickness'] == df['Thickness'].min()].index)\n",
    "fig, ax = plt.subplots(2,2,figsize = (10,10))\n",
    "ax[0][0].plot(\n",
    "    model_history[m].history['loss'], \n",
    "     label='loss',\n",
    "    color = 'blue'\n",
    ")\n",
    "ax[0][0].plot(\n",
    "    model_history[m].history['val_loss'], \n",
    "    label='val_loss',\n",
    "    color = 'orange'\n",
    ")\n",
    "#   plt.ylim([0, 10])\n",
    "ax[0][0].set_xlabel('Epoch')\n",
    "ax[0][0].set_ylabel('Error (m)')\n",
    "ax[0][0].legend()\n",
    "ax[0][0].grid(True)\n",
    "ax[0][0].set_title('Model Training')\n",
    "\n",
    "\n",
    "# y = model[m].predict(test_features).flatten()\n",
    "ax[0][1].scatter(test_features[m]['Area'],test_labels[m],label = 'Data',alpha = 0.25)\n",
    "#     ax[0][1].plot(\n",
    "#         test_labels.sort_values(\n",
    "#         ascending = True),test_labels.sort_values(\n",
    "#         ascending = True),c = 'r',label = 'Data'\n",
    "#     )\n",
    "ax[0][1].plot(\n",
    "    test_features[m]['Area'].sort_values(\n",
    "    ascending = True),np.sort(y[m]),c = 'k',label = 'Predictions'\n",
    ")\n",
    "ax[0][1].set_xscale('log')\n",
    "ax[0][1].set_title('Model Testing')\n",
    "ax[0][1].set_xlabel('Area (km$^2$)')\n",
    "ax[0][1].set_ylabel('GlaThiDa Thickness (m)')\n",
    "ax[0][1].legend()\n",
    "\n",
    "\n",
    "\n",
    "# y[p + str(m)] = model[m].predict(df.drop('Thickness',axis = 1)).flatten()   \n",
    "# residuals = (y[test] - df['Thickness']) \n",
    "ax[1][1].scatter(df['Thickness'],y[str(1)+m],label = 'Data',alpha = 0.25)\n",
    "ax[1][1].plot(\n",
    "    (df['Thickness'].min(),df['Thickness'].max()),\n",
    "    (0,0),\n",
    "    c = 'k',\n",
    "    linestyle = '--'\n",
    ")\n",
    "ax[1][1].set_title('Residuals')\n",
    "ax[1][1].set_ylabel('Residuals (m)')\n",
    "ax[1][1].set_xlabel('GlaThiDa Thickness (m)')\n",
    "mean = np.round(np.mean(y[str(1) + str(m)]), 2)\n",
    "std = np.round(np.std(y[str(1) + str(m)]), 2)\n",
    "ax[1][1].set_title(\n",
    "    r'Verification Residuals $\\left(\\hat{h} - h\\right)$' + '\\n' +\n",
    "    f'Mean = {mean}, STD = {std}'\n",
    ")\n",
    "#     ax[1][1].legend()\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     y = model[k].predict(df.drop('Thickness',axis = 1)).flatten()\n",
    "ax[1][0].scatter(df['Thickness'],y[str(2) + (m)],label = 'Estimates',alpha = 0.25)\n",
    "ax[1][0].plot(\n",
    "    (df['Thickness'].min(),df['Thickness'].max()),\n",
    "    (df['Thickness'].min(),df['Thickness'].max()),\n",
    "    'k'\n",
    ")\n",
    "ax[1][0].set_title('Model Verification')\n",
    "ax[1][0].set_xlabel('GlaThida Thickness (m)')\n",
    "ax[1][0].set_ylabel('Estimated Thickness (m)')\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\n",
    "    'Data Parameterization = ' +  m + '\\n' +\n",
    "    'Layer Architecture = ' + str(l1[m]) + '-' + str(l2[m]),\n",
    "    y = 1.05,\n",
    "    fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Thickness']\n",
    "plt.errorbar(\n",
    "    x,\n",
    "    y[str(2) + m],\n",
    "    yerr = unc[m],\n",
    "    alpha = 0.25,\n",
    "#     label = 'Estimates $\\hat{\\mu}(x)$',\n",
    "    linestyle = 'None',\n",
    "    marker = 'o',\n",
    "    capsize = 8,\n",
    "    color = '#1f77b4',\n",
    "    label = 'Composite Thickness Estimate $\\hat{\\mu}$'\n",
    ")\n",
    "plt.plot(\n",
    "    (x.min(),x.max()),\n",
    "    (x.min(),x.max()),\n",
    "    c = 'k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8dc03a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y[str(1)+str(m)].sort_values().head(7)\n",
    "t = pd.DataFrame(y[str(1)+str(m)])\n",
    "# s = pd.Series(t)\n",
    "mu, std = norm.fit(t) \n",
    "mu = np.round(mu, 2)\n",
    "std = np.round(std, 2)\n",
    "plt.hist(t, bins=50, density = True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.title(\n",
    "    f'Coregistration {m} Residuals\\n' + \n",
    "    f'Mean = {mu}    STD = {std}'\n",
    ")\n",
    "plt.show()\n",
    "fig = sm.qqplot(t['Thickness'],line = 'r')\n",
    "\n",
    "plt.title(f'Coregistration {m} Residuals Q-Q Plot')\n",
    "plt.show()\n",
    "# print(f'coregistration {m}')\n",
    "\n",
    "print(shapiro(y[str(1) + str(m)]))\n",
    "print(kstest(y[str(1) + str(m)], 'norm'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47b36b",
   "metadata": {},
   "source": [
    "### Residuals are not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcebba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(i):\n",
    "    j = str(i)\n",
    "    estimates = pd.Series(y[str(2)+j],name = 'Estimates')\n",
    "    df = gl.coregister_data(j)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    df = df.join(estimates)\n",
    "    data = gl.load_notebook_data('4')\n",
    "    data = data[['RGIId','FMT']]\n",
    "    df = pd.merge(df,data,how = 'inner', on = 'RGIId')\n",
    "    df = df.dropna(subset = ['FMT', 'Estimates'])\n",
    "    print('df' + j + ' loaded')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3205a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load_data(1)\n",
    "df2 = load_data(2)\n",
    "df3 = load_data(3)\n",
    "df4 = load_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2,figsize = (8,15),\n",
    "#                        sharex = True, sharey = True\n",
    "                      )\n",
    "\n",
    "for n, dataset in enumerate((df1, df2,\n",
    "                             df3, df4\n",
    "                            )):\n",
    "    data = dataset\n",
    "    if n == 0:\n",
    "        threshold = 'No Threshold'\n",
    "    if n == 1:\n",
    "        threshold = '0.25'\n",
    "    if n == 2:\n",
    "        threshold = '0.50'\n",
    "    if n == 3:\n",
    "        threshold = '0.75'\n",
    "#     axs = plt.subplot(4, 1, n+1)\n",
    "#     print(data)\n",
    "    data_1 = data['Estimates']\n",
    "    data_2 = data['FMT']\n",
    "    data_3 = data['Thickness']\n",
    "\n",
    "    data_4 = data['Estimates'] - data['Thickness']\n",
    "    data_5 = data['FMT'] - data['Thickness']\n",
    "    \n",
    "    res = np.round(np.mean(data_4),2)\n",
    "    std = np.round(np.std(data_4),2)\n",
    "    fres = np.round(np.mean(data_5),2)\n",
    "    fstd = np.round(np.std(data_5),2)\n",
    "    # data_1 = ref['Farinotti Mean Thickness'] / 1e3 * ref['Area']\n",
    "    # data_2 = ref['Edasi Mean Thickness'] / 1e3 * ref['Area']\n",
    "\n",
    "    print('Sorting data...')\n",
    "    x_1 = np.sort(data_1)\n",
    "    y_1 = 1. * np.arange(len(data_1)) / (len(data_1) - 1)\n",
    "\n",
    "    x_2 = np.sort(data_2)\n",
    "    y_2 = 1. * np.arange(len(data_2)) / (len(data_2) - 1)\n",
    "\n",
    "    x_3 = np.sort(data_3)\n",
    "    y_3 = 1. * np.arange(len(data_3)) / (len(data_3) - 1)\n",
    "\n",
    "    print('Calculating point density...')\n",
    "    # Calculate the point density\n",
    "    xy = np.vstack([np.log10(data_1),np.log10(data_3)])\n",
    "\n",
    "    z_1 = gaussian_kde(xy)(xy)\n",
    "\n",
    "    yz = np.vstack([np.log10(data_2),np.log10(data_3)])\n",
    "\n",
    "    z_2 = gaussian_kde(yz)(yz)\n",
    "    \n",
    "    ax[n,0].scatter(\n",
    "            data_3,\n",
    "            data_1,\n",
    "            c = z_1,\n",
    "            cmap = 'viridis',\n",
    "            marker = '.'\n",
    "        )\n",
    "    ax[n,0].set_xscale('log')\n",
    "    ax[n,0].set_yscale('log')\n",
    "    ax[n,0].plot(\n",
    "        (data['Thickness'].min(), data['Thickness'].max()),\n",
    "        (data['Thickness'].min(), data['Thickness'].max()),\n",
    "        color = 'red',\n",
    "        linestyle = '-'\n",
    "    )\n",
    "    \n",
    "#     ax[n,0].set_xlabel('GlaThiDa Survey Thickness (m)')\n",
    "#     ax[n,0].set_ylabel('Estimated Thickness (m)')\n",
    "    ax[n,0].set_title('Coregistration = ' + str(n+1) + '\\n'+\n",
    "                      f'Mean Residual = {res} $\\pm$ {std}',\n",
    "                     fontsize = 14)\n",
    "    \n",
    "    ax[n,1].scatter(\n",
    "            data_3,\n",
    "            data_2,\n",
    "            c = z_2,\n",
    "            cmap = 'viridis',\n",
    "            marker = '.'\n",
    "        )\n",
    "    ax[n,1].plot(\n",
    "        (data['Thickness'].min(), data['Thickness'].max()),\n",
    "        (data['Thickness'].min(), data['Thickness'].max()),\n",
    "        color = 'red',\n",
    "        linestyle = '-'\n",
    "    )\n",
    "    ax[n,1].set_xscale('log')\n",
    "    ax[n,1].set_yscale('log')\n",
    "    ax[n,1].set_title('Farinotti et al. Thickness\\n'+\n",
    "                       f'Mean Residual = {fres} $\\pm$ {fstd}',\n",
    "                     fontsize = 14)\n",
    "    ax[n,0].tick_params(axis=\"both\", labelsize=14)\n",
    "    ax[n,1].tick_params(axis=\"both\", labelsize=14)\n",
    "#     ax[n,1].set_xlabel('GlaThiDa Survey Thickness (m)')\n",
    "#     ax[n,1].set_ylabel('Farinotti Estimated Thickness (m)')\n",
    "#     ax[n,1].set_title('Farinotti et al. 2019')\n",
    "    \n",
    "# plt.suptitle('Comparison of Non-Ice Sheet Glacier Thickness Estimates', y = 0.99)\n",
    "fig.supylabel('Estimated Thickness (m)', fontsize = 18)\n",
    "fig.supxlabel('GlaThiDa Survey Thickness (m)', fontsize = 18)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Select coregistration number')\n",
    "sc = str(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI = gl.load_RGI()\n",
    "\n",
    "rfp = RGI[list(df.drop('Thickness', axis = 1))]\n",
    "# rfp['Area'] = np.log(rfp['Area'])\n",
    "y = pd.Series(model[sc].predict(rfp.drop('RGIId',axis = 1)).flatten(), name = 'Thickness')\n",
    "\n",
    "rfp = rfp.join(y)\n",
    "rfp['unc'] = (gamma[str(3) + m] * rfp['Thickness'])**2\n",
    "\n",
    "vol = rfp['Area'] * (rfp['Thickness'] / 1e3)\n",
    "vol_unc = rfp['Area'] * (np.sqrt(rfp['unc'] )/ 1e3)\n",
    "\n",
    "sum_vol = sum(vol)\n",
    "sum_vol_unc = np.sqrt(sum(vol_unc**2))\n",
    "\n",
    "print(sum_vol / 1e3)\n",
    "print(sum_vol_unc / 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gl.load_notebook_data('4')\n",
    "data = data[['RGIId','FMT','region']]\n",
    "rfp = pd.merge(rfp, data, how = 'inner',on = 'RGIId')\n",
    "rfp = rfp.dropna(subset = ['FMT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rfp['Area'] * (rfp['FMT'] / 1e3)\n",
    "y = rfp['Area'] * (rfp['Thickness'] / 1e3)\n",
    "xy = np.vstack([np.log10(x),np.log10(y)])\n",
    "z = gaussian_kde(xy)(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_x = np.logspace(np.log10(np.min(x)), np.log10(np.max(x)), 25)\n",
    "bins_y = np.logspace(np.log10(np.min(y)), np.log10(np.max(y)), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_hist(x, y, ax, \n",
    "                 ax_histx, ax_histy\n",
    "                ):\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False, size = 36)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False, size = 36)\n",
    "\n",
    "    # the scatter plot:\n",
    "    ax.scatter(x, y, \n",
    "               c = (z), \n",
    "               s = 100,\n",
    "               cmap = 'viridis',\n",
    "               marker = '.'\n",
    "              )\n",
    "    ax.plot(\n",
    "        (x.min(),x.max()),\n",
    "        (x.min(),x.max()),\n",
    "        '-',\n",
    "        c = 'orange',\n",
    "        linewidth = 5\n",
    "\n",
    "    )\n",
    "\n",
    "    ax_histx.hist(\n",
    "        (x), \n",
    "        bins = bins_x,\n",
    "        edgecolor = 'black',\n",
    "        log = True\n",
    "    )\n",
    "\n",
    "    ax_histy.hist(\n",
    "        (y), \n",
    "        bins = bins_y, \n",
    "        edgecolor = 'black',\n",
    "        orientation='horizontal',\n",
    "        log = True\n",
    "    )\n",
    "    ax_histx.tick_params(axis=\"x\", labelsize=36)\n",
    "    ax_histy.tick_params(axis=\"y\", labelsize=36)\n",
    "    ax_histy.grid(alpha = 0.5,linewidth = 2)\n",
    "    ax_histx.grid(alpha = 0.5,linewidth = 2)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "gs = fig.add_gridspec(2, 2,  width_ratios=(4, 1), height_ratios=(1, 4),\n",
    "                      left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                      wspace=0.05, hspace=0.05)\n",
    "\n",
    "\n",
    "# Create the Axes.\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax_histx = fig.add_subplot(gs[0, 0], sharex = ax)\n",
    "ax_histy = fig.add_subplot(gs[1, 1], sharey = ax)\n",
    "\n",
    "\n",
    "ax_histx.tick_params(axis=\"y\", labelsize=36)\n",
    "ax_histy.tick_params(axis=\"x\",which = 'major', labelsize=36)\n",
    "\n",
    "ax.tick_params(axis=\"both\", labelsize=36)\n",
    "ax.tick_params(which='minor', color='r', labelsize = 36)\n",
    "\n",
    "\n",
    "print('Drawing scatter plot...')\n",
    "scatter_hist(\n",
    "    x, \n",
    "    y,\n",
    "    ax, \n",
    "    ax_histx,\n",
    "    ax_histy,\n",
    ")\n",
    "print('Drawing done')\n",
    "print('Setting scales and labels...')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('This Study Volume (km$^3$)', fontsize = 36)\n",
    "ax.set_xlabel('Farinotti et al. Volume (km$^3$)', fontsize = 36)\n",
    "ax.grid(which = 'major',alpha = 0.5,linewidth = 2)\n",
    "ax.grid(which = 'minor',alpha = 0.5,linewidth = 1,linestyle = '--')\n",
    "# plt.text(1e-16, 300000, 'A.',fontsize = 42)\n",
    "# plt.text(1e-16, 3500, 'C.',fontsize = 42)\n",
    "# plt.text(10, 3500, 'B.',fontsize = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1868a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region in rfp['region'].unique():\n",
    "    dft = rfp[rfp['region'] == region]\n",
    "    x = dft['Area'] * (dft['FMT'] / 1e3)\n",
    "    y = dft['Area'] * (dft['Thickness'] / 1e3)\n",
    "    xy = np.vstack([np.log10(x),np.log10(y)])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    plt.scatter(\n",
    "        x,y,\n",
    "        c = z,cmap = 'viridis',\n",
    "        marker = '.'\n",
    "    )\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.plot(\n",
    "        (x.min(),x.max()),\n",
    "        (x.min(),x.max()),\n",
    "        c = 'orange'\n",
    "    )\n",
    "    plt.title(region)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.8.10)",
   "language": "python",
   "name": "new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "709.844px",
    "left": "283px",
    "right": "20px",
    "top": "49px",
    "width": "651px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
