{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563ee1f5",
   "metadata": {},
   "source": [
    "## Import dependancies and set environment determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "#     tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    0\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEED = 378\n",
    "# SEED = 123\n",
    "print(SEED)\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import shapiro \n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isdir(res_dir) == False:\n",
    "\n",
    "def run_model(model_path, n):\n",
    "            \n",
    "                normalizer = preprocessing.Normalization(axis=-1)\n",
    "                normalizer.adapt(np.array(trfeat[n]))\n",
    "\n",
    "                model[n] = gl.build_dnn_model(\n",
    "                    normalizer, learning_rate = 0.01, \n",
    "                    layer_1 = 16, layer_2 = 4,loss = 'mae'\n",
    "                )\n",
    "\n",
    "                model_history[n] = model[n].fit(\n",
    "                    trfeat[n],\n",
    "                    trlabs[n],\n",
    "                    validation_split=0.2,\n",
    "                    callbacks = [callback],\n",
    "                    verbose=0, \n",
    "                    epochs=500\n",
    "                )\n",
    "                model_filename = os.path.join(model_path,str(n))\n",
    "                model[n].save(model_filename)\n",
    "                \n",
    "\n",
    "def find_results(df,model,n):\n",
    "        results = {}\n",
    "        residuals = {}\n",
    "        final_results = pd.DataFrame()\n",
    "        # residuals = pd.DataFrame()\n",
    "        y = {}\n",
    "        for n in tqdm(df.index):\n",
    "\n",
    "\n",
    "\n",
    "            results[n] = model[n].evaluate(tefeat[n], telabs[n],verbose = 0)\n",
    "            y[n] = model[n].predict(tefeat[n],verbose = 0).flatten()\n",
    "        #     residuals[n] = y[n] - telabs[n].values[0]\n",
    "        #     p_res = residuals[n] / telabs[n].values[0]\n",
    "            RMSE = np.sqrt(metrics.mean_squared_error(telabs[n].values, y[n]))\n",
    "            MAPerror = np.mean((y[n] - (telabs[n].values[0])) / telabs[n].values[0]) * 100 \n",
    "\n",
    "\n",
    "        #     tq75 = np.percentile(residuals[n], 75)\n",
    "        #     tq25 = np.percentile(residuals[n], 25)\n",
    "\n",
    "        #     TIQR = tq75 - tq25\n",
    "\n",
    "            z = model[n].predict(df.drop(['RGIId','Thickness'],axis = 1),verbose = 0).flatten()\n",
    "            ver_res = z - df['Thickness']\n",
    "            ver_res_mean = np.mean(ver_res)\n",
    "            ver_res_std =  np.std(ver_res)\n",
    "            vq75 = np.percentile(ver_res,75)\n",
    "            vq25 = np.percentile(ver_res,25)\n",
    "            VIQR = vq75 - vq25\n",
    "\n",
    "            test_res_n = pd.DataFrame(pd.Series(n,name = 'i'))\n",
    "            test_res = pd.DataFrame(pd.Series((RMSE), name = 'Test Res'))\n",
    "        #     test_res_std = pd.DataFrame(pd.Series(np.std(residuals[n].values),name = 'Val STD'))\n",
    "\n",
    "            test_res_n['Model Loss'] = results[n]\n",
    "            test_res_n['RMSE'] = RMSE\n",
    "            test_res_n['Percent Error'] = MAPerror\n",
    "            trm = test_res_n.join(test_res)\n",
    "        #     test_res_mean = test_res_mean.join(test_res_std)\n",
    "        #     test_res_mean['TRes Max'] = residuals[n].max()\n",
    "        #     test_res_mean['TRes Min'] = residuals[n].min()\n",
    "        #     test_res_mean['TRes IQR'] = TIQR\n",
    "            trm['VRes Mean'] = ver_res_mean    \n",
    "            trm['VRes STD'] = ver_res_std\n",
    "            trm['VRes Max'] = ver_res.max()\n",
    "            trm['VRes Min'] = ver_res.min()\n",
    "            trm['VRes IQR'] = VIQR\n",
    "            trm['est'] = y[n]\n",
    "            trm['Thickness'] = telabs[n].values[0]\n",
    "            trm['Area'] = tefeat[n]['Area'].values[0]\n",
    "            trm['Lmax'] = tefeat[n]['Lmax'].values[0]\n",
    "            trm['Slope'] = tefeat[n]['Slope'].values[0]\n",
    "            trm['Zmin'] = tefeat[n]['Zmin'].values[0]\n",
    "            trm['Zmed'] = tefeat[n]['Zmed'].values[0]\n",
    "            trm['Zmax'] = tefeat[n]['Zmax'].values[0]\n",
    "            trm['CenLat'] = tefeat[n]['CenLat'].values[0]\n",
    "            trm['CenLon'] = tefeat[n]['CenLon'].values[0]\n",
    "            trm['Aspect'] = tefeat[n]['Aspect'].values[0]\n",
    "            final_results = pd.concat([final_results,trm])\n",
    "        fr = final_results\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6765b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.001,\n",
    "    patience = 10,\n",
    "    verbose = 0,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sort = ['none','shuffle','Thickness','Area']\n",
    "asc_list = ['none',True,False]\n",
    "for feat in feat_sort:\n",
    "    for asc in asc_list:\n",
    "        df = gl.coregister_data('4')\n",
    "        if feat == 'none' and (asc == True or asc == False):\n",
    "            continue\n",
    "        elif feat == 'none' and asc == 'none':\n",
    "            df = df.reset_index().drop('index',axis = 1)\n",
    "            a = 'none'\n",
    "        elif feat == 'shuffle' and asc == 'none':\n",
    "            df = df.sample(frac = 1,random_state = 0)\n",
    "            df = df.reset_index().drop('index', axis = 1)\n",
    "            a = 'none'\n",
    "        elif (feat == 'Thickness' or feat == 'Area') and asc == True:\n",
    "            a = 'ascending'\n",
    "            df = df.sort_values(feat,ascending = asc).reset_index().drop('index',axis = 1)\n",
    "        elif (feat == 'Thickness' or feat == 'Area') and asc == False:\n",
    "            a = 'descending'\n",
    "            df = df.sort_values(feat,ascending = asc).reset_index().drop('index',axis = 1)\n",
    "        elif (feat == 'Thickness' or feat == 'Area') and asc == 'none':\n",
    "            continue\n",
    "        elif (feat != 'none' or feat != 'shuffle') and asc != 'none':\n",
    "            continue\n",
    "\n",
    "\n",
    "        dft = df.copy()\n",
    "\n",
    "        trfeat = {}\n",
    "        trlabs = {}\n",
    "        tefeat = {}\n",
    "        telabs = {}\n",
    "\n",
    "        for n in df.index:\n",
    "            mask = df.index.isin([n])\n",
    "            trfeat[n] = df.loc[~mask].drop(['RGIId','Thickness'], axis = 1)\n",
    "            tefeat[n] = df.loc[mask].drop(['RGIId','Thickness'], axis = 1)\n",
    "            trlabs[n] = df['Thickness'].loc[~mask]\n",
    "            telabs[n] = df['Thickness'].loc[mask]\n",
    "            \n",
    "        model = {}\n",
    "        model_history = {}\n",
    "        normalizer = {}\n",
    "        model_path = os.path.join('/data/fast1/glacierml/models/LOO/',feat,a)\n",
    "        print(model_path)\n",
    "        res_dir = os.path.join(model_path, 'final_results.pkl')\n",
    "        if os.path.isdir(res_dir) == True:\n",
    "            continue\n",
    "            \n",
    "        for n in tqdm(df.index):\n",
    "            isdir = os.path.join(\n",
    "                model_path, str(n)\n",
    "            )\n",
    "            if os.path.isdir(isdir) == True:\n",
    "                model[n] = gl.load_dnn_model(os.path.join(model_path,str(n)))\n",
    "            elif os.path.isdir(isdir) == False:\n",
    "                set_global_determinism(seed=SEED)\n",
    "                run_model(model_path, n)\n",
    "                \n",
    "\n",
    "        if os.path.isdir(res_dir) == False:\n",
    "            fr = find_results(df,model,n)              \n",
    "            fr['unc'] = fr['RMSE'] + fr['Percent Error']\n",
    "            fr = fr.set_index('i')\n",
    "            fr.to_pickle(res_dir)\n",
    "            \n",
    "            \n",
    "        rgi_est_pth = os.path.join(model_path, 'rgi_est_raw.pkl')\n",
    "\n",
    "        if os.path.isdir(rgi_est_pth) == True:\n",
    "            continue\n",
    "        elif os.path.isdir(rgi_est_pth) == False:\n",
    "\n",
    "            RGI = gl.load_RGI()\n",
    "            rfp = RGI[list(df)[:-1]]\n",
    "\n",
    "            for n in tqdm(model.keys()):\n",
    "                preds = pd.Series(\n",
    "                    model[n].predict(rfp.drop('RGIId',axis = 1)).flatten(), name = n\n",
    "                )\n",
    "                RGI = pd.concat([RGI,preds], axis = 1)\n",
    "            RGI.to_pickle(rgi_est_pth)\n",
    "            # RGI = pd.read_pickle('rgi_est_raw.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dedbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8491e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr = pd.read_pickle(model_path + 'final_results_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e604d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr.sort_values('Percent Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ce066",
   "metadata": {},
   "source": [
    "## Looking at LOO first results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3f592",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ls = 12\n",
    "# fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "# x = fr['Thickness']\n",
    "# y = fr['est']\n",
    "# ax[0].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[0].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (x.min(),x.max()),\n",
    "#     '-k'\n",
    "# )\n",
    "# ax[0].set_ylabel('LOO Estimated Thickness',fontsize = ls)\n",
    "\n",
    "# y = fr['Percent Error']\n",
    "# ax[1].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[1].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (0,0),\n",
    "#     '-k'\n",
    "# )\n",
    "# ax[1].set_ylabel('LOO Percent Error',fontsize = ls)\n",
    "# fig.supxlabel('GlaThiDa Thickness', y = 0.05,fontsize = ls)\n",
    "# ax[0].tick_params(axis='both', labelsize=ls)\n",
    "# ax[1].tick_params(axis='both', labelsize=ls)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240700e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ls = 12\n",
    "# fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "# x = fr['Thickness']\n",
    "# y = fr['est']\n",
    "# ax[0].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[0].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (x.min(),x.max()),\n",
    "#     '-k'\n",
    "# )\n",
    "# ax[0].set_ylabel('LOO Estimated Thickness',fontsize = ls)\n",
    "\n",
    "# y = fr['Percent Error']\n",
    "# x = fr['Area']\n",
    "# ax[1].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[1].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (0,0),\n",
    "#     '-k'\n",
    "# )\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_ylabel('LOO Percent Error',fontsize = ls)\n",
    "# fig.supxlabel('GlaThiDa Thickness', y = 0.05,fontsize = ls)\n",
    "# ax[0].tick_params(axis='both', labelsize=ls)\n",
    "# ax[1].tick_params(axis='both', labelsize=ls)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5944377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "# x = fr['Area']\n",
    "# y = fr['est']\n",
    "# ax[0].scatter(\n",
    "#     x,y,alpha = 0.25\n",
    "# )\n",
    "# ax[0].set_xscale('log')\n",
    "\n",
    "# ax[0].set_ylabel('LOO Estimated Thickness', fontsize = ls)\n",
    "\n",
    "# y = fr['Thickness']\n",
    "# ax[1].scatter(\n",
    "#     x,y,alpha = 0.25\n",
    "# )\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_ylabel('GlaThiDa Survey Thickness',fontsize = ls)\n",
    "# fig.supxlabel('Glacier Area (km$^2$)', y = 0.05,fontsize = ls)\n",
    "# ax[0].tick_params(axis='both', labelsize=ls)\n",
    "# ax[1].tick_params(axis='both', labelsize=ls)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fbb2b",
   "metadata": {},
   "source": [
    "### Let's see if a linear model does anything different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_model = {}\n",
    "# lin_model_history = {}\n",
    "# l1 = 16\n",
    "# l2 = 4\n",
    "# normalizer = {}\n",
    "# loss = 'mae'\n",
    "# model_path = '/data/fast1/glacierml/models/LOO_linear/'\n",
    "# for n in tqdm(df.index):\n",
    "#     isdir = os.path.join(\n",
    "#         model_path ,str(n)\n",
    "#     )\n",
    "#     if os.path.isdir(isdir) == True:\n",
    "#         lin_model[n] = gl.load_dnn_model(isdir)\n",
    "#     elif os.path.isdir(isdir) == False:\n",
    "        \n",
    "\n",
    "# #         total_inputs = (len(df.columns)) * (len(df) - 1)\n",
    "# #         dp = int(pr * total_inputs)\n",
    "# #         tp = dp - (len(df.columns) + (len(df.columns)-1) )\n",
    "# #         g = (len(df.columns) + (len(df.columns) - 1))\n",
    "# #         l2[n] = 4\n",
    "# #         l1[n] = int((dp - 1 - g - 2*l2[n]) / (10 + l2[n]))\n",
    "#         normalizer = preprocessing.Normalization(axis=-1)\n",
    "#         normalizer.adapt(np.array(trfeat[n]))\n",
    "\n",
    "#         lin_model[n] = gl.build_linear_model(\n",
    "#             normalizer, learning_rate = 0.01, \n",
    "#             layer_1 = l1, layer_2 = l2\n",
    "#         )\n",
    "\n",
    "#         lin_model_history[n] = model[n].fit(\n",
    "#             trfeat[n],\n",
    "#             trlabs[n],\n",
    "#             validation_split=0.2,\n",
    "#             callbacks = [callback],\n",
    "#             verbose=0, \n",
    "#             epochs=500\n",
    "#         )\n",
    "#         model_filename = isdir\n",
    "#         lin_model[n].save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5de79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# residuals = {}\n",
    "# final_results = pd.DataFrame()\n",
    "# # residuals = pd.DataFrame()\n",
    "# y = {}\n",
    "# for n in tqdm(df.index):\n",
    "#     results[n] = model[n].evaluate(tefeat[n], telabs[n],verbose = 0)\n",
    "#     y[n] = model[n].predict(tefeat[n],verbose = 0).flatten()\n",
    "# #     residuals[n] = y[n] - telabs[n].values[0]\n",
    "# #     p_res = residuals[n] / telabs[n].values[0]\n",
    "#     RMSE = np.sqrt(metrics.mean_squared_error(telabs[n].values, y[n]))\n",
    "#     MAPerror = np.mean((y[n] - (telabs[n].values[0])) / telabs[n].values[0]) * 100 \n",
    "\n",
    "\n",
    "# #     tq75 = np.percentile(residuals[n], 75)\n",
    "# #     tq25 = np.percentile(residuals[n], 25)\n",
    "\n",
    "# #     TIQR = tq75 - tq25\n",
    "\n",
    "#     z = model[n].predict(df.drop(['RGIId','Thickness'],axis = 1),verbose = 0).flatten()\n",
    "#     ver_res = z - df['Thickness']\n",
    "#     ver_res_mean = np.mean(ver_res)\n",
    "#     ver_res_std =  np.std(ver_res)\n",
    "#     vq75 = np.percentile(ver_res,75)\n",
    "#     vq25 = np.percentile(ver_res,25)\n",
    "#     VIQR = vq75 - vq25\n",
    "\n",
    "#     test_res_n = pd.DataFrame(pd.Series(n,name = 'i'))\n",
    "#     test_res = pd.DataFrame(pd.Series((RMSE), name = 'Test Res'))\n",
    "# #     test_res_std = pd.DataFrame(pd.Series(np.std(residuals[n].values),name = 'Val STD'))\n",
    "\n",
    "#     test_res_n['Model Loss'] = results[n]\n",
    "#     test_res_n['RMSE'] = RMSE\n",
    "#     test_res_n['Percent Error'] = MAPerror\n",
    "#     trm = test_res_n.join(test_res)\n",
    "# #     test_res_mean = test_res_mean.join(test_res_std)\n",
    "# #     test_res_mean['TRes Max'] = residuals[n].max()\n",
    "# #     test_res_mean['TRes Min'] = residuals[n].min()\n",
    "# #     test_res_mean['TRes IQR'] = TIQR\n",
    "#     trm['VRes Mean'] = ver_res_mean    \n",
    "#     trm['VRes STD'] = ver_res_std\n",
    "#     trm['VRes Max'] = ver_res.max()\n",
    "#     trm['VRes Min'] = ver_res.min()\n",
    "#     trm['VRes IQR'] = VIQR\n",
    "#     trm['est'] = y[n]\n",
    "#     trm['Thickness'] = telabs[n].values[0]\n",
    "#     trm['Area'] = tefeat[n]['Area'].values[0]\n",
    "#     trm['Lmax'] = tefeat[n]['Lmax'].values[0]\n",
    "#     trm['Slope'] = tefeat[n]['Slope'].values[0]\n",
    "#     trm['Zmin'] = tefeat[n]['Zmin'].values[0]\n",
    "#     trm['Zmed'] = tefeat[n]['Zmed'].values[0]\n",
    "#     trm['Zmax'] = tefeat[n]['Zmax'].values[0]\n",
    "#     trm['CenLat'] = tefeat[n]['CenLat'].values[0]\n",
    "#     trm['CenLon'] = tefeat[n]['CenLon'].values[0]\n",
    "#     trm['Aspect'] = tefeat[n]['Aspect'].values[0]\n",
    "#     final_results = pd.concat([final_results,trm])\n",
    "# fr_lin = final_results\n",
    "# fr_lin['unc'] = fr_lin['RMSE'] + fr_lin['Percent Error']\n",
    "# fr_lin = fr_lin.set_index('i')\n",
    "# fr_lin.to_pickle(model_path + 'final_results_linear.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr_lin = pd.read_pickle(model_path + 'final_results_linear.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr_lin.sort_values('Percent Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ffcaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "# x = fr_lin['Thickness']\n",
    "# y = fr_lin['est']\n",
    "# ax[0].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[0].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (x.min(),x.max()),\n",
    "#     '-k'\n",
    "# )\n",
    "# # ax[0].set_xscale('log')\n",
    "# # ax[0].set_yscale('log')\n",
    "# ax[0].set_ylabel('LOO Estimated Thickness', fontsize = ls)\n",
    "# fig.supxlabel('GlaThiDa Thickness', y = 0.05, fontsize = ls)\n",
    "\n",
    "# y = fr_lin['Percent Error']\n",
    "# ax[1].scatter(\n",
    "#     x,y, alpha = 0.25\n",
    "# )\n",
    "# ax[1].plot(\n",
    "#     (x.min(),x.max()),\n",
    "#     (0,0),\n",
    "#     '-k'\n",
    "# )\n",
    "# ax[1].set_ylabel('LOO Percent Error', fontsize = ls)\n",
    "# ax[0].tick_params(axis='both', labelsize=ls)\n",
    "# ax[1].tick_params(axis='both', labelsize=ls)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799203bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "# x = fr_lin['Area']\n",
    "# y = fr_lin['est']\n",
    "# ax[0].scatter(\n",
    "#     x,y,alpha = 0.25\n",
    "# )\n",
    "# ax[0].set_xscale('log')\n",
    "# ax[0].set_ylabel('LOO Estimated Thickness')\n",
    "\n",
    "# y = fr_lin['Thickness']\n",
    "# ax[1].scatter(\n",
    "#     x,y,alpha = 0.25\n",
    "# )\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_ylabel('GlaThiDa Survey Thickness')\n",
    "# fig.supxlabel('Glacier Area (km$^2$)', y = -.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40388a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(\n",
    "#     fr['est'],\n",
    "#     fr['RMSE'],\n",
    "#     alpha = 0.25\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f7256",
   "metadata": {},
   "source": [
    "## Are residuals and percent residuals normally distributed with features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7e35a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for feat in ['Area','Lmax','Slope','Zmin']:\n",
    "#     plt.scatter(\n",
    "#         fr[feat],\n",
    "#         fr['RMSE']\n",
    "#     )\n",
    "#     if feat == 'Area' or feat == 'Lmax':\n",
    "#         plt.xscale('log')\n",
    "#     plt.xlabel(feat)\n",
    "#     plt.ylabel('LOO RMSE')\n",
    "#     plt.show()\n",
    "\n",
    "# for feat in ['Area','Lmax','Slope','Zmin']:\n",
    "#     plt.scatter(\n",
    "#         fr[feat],\n",
    "#         fr['Percent Error']\n",
    "#     )\n",
    "#     if feat == 'Area' or feat == 'Lmax':\n",
    "#         plt.xscale('log')\n",
    "#     plt.xlabel(feat)\n",
    "#     plt.ylabel('LOO % error')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(\n",
    "#     fr['Area'],\n",
    "#     fr['RMSE']\n",
    "# )\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32731244",
   "metadata": {},
   "source": [
    "### Use each LOO model to predict RGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd18c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = []\n",
    "for i in range(341):\n",
    "    cols.append(i)\n",
    "\n",
    "\n",
    "\n",
    "rgi_list = list(df)[:-1]\n",
    "rgi_list.append('RGIId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d492aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_cols = []\n",
    "for i in range(341):\n",
    "    unc_cols.append(str(i) + '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, RGI, how = 'inner', on = rgi_list)\n",
    "X = np.mean(df[range(341)], axis = 1)\n",
    "se = np.std(df[range(341)], axis = 1) / np.sqrt(341)\n",
    "\n",
    "df['LCI'] = X - (1.96 * se)\n",
    "df['UCI'] = X + (1.96 * se)\n",
    "\n",
    "lb = df['LCI'] / 1e3 * df['Area'] / 1e3\n",
    "ub = df['UCI'] / 1e3 * df['Area'] / 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b94235",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Thickness']\n",
    "# y = np.mean(dfci, axis = 1)\n",
    "# y = df['we']\n",
    "y = np.mean(df[cols],axis = 1)\n",
    "plt.errorbar(\n",
    "    x,y,yerr = df['UCI'] - df['LCI'],\n",
    "        alpha = 0.25,\n",
    "#     label = 'Estimates $\\hat{\\mu}(x)$',\n",
    "    linestyle = 'None',\n",
    "    marker = '.',\n",
    "    capsize = 8,\n",
    "    color = '#1f77b4',\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    (x.min(),x.max()),\n",
    "    (x.min(),x.max()),\n",
    "    '-k'\n",
    ")\n",
    "\n",
    "plt.ylabel('Estimated Thickness')\n",
    "plt.xlabel('GlaThiDa Survey')\n",
    "plt.title('Leave-One-Out X-val 95% CI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd453d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "x = df['Area']\n",
    "y1 = df['UCI']\n",
    "y2 = df['LCI']\n",
    "ax[0].scatter(\n",
    "    x,y1,alpha = 0.25\n",
    ")\n",
    "ax[0].scatter(\n",
    "    x,y2,alpha = 0.25\n",
    ")\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_ylabel('LOO Thickness Upper CI')\n",
    "\n",
    "y = df['Thickness']\n",
    "ax[1].scatter(\n",
    "    x,y,alpha = 0.25\n",
    ")\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_ylabel('GlaThiDa Survey Thickness')\n",
    "fig.supxlabel('Glacier Area (km$^2$)', y = -.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Area']\n",
    "y = df['UCI']\n",
    "plt.scatter(x,y,alpha = 0.25)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pth = '/data/fast1/glacierml/data/reference_thicknesses/'\n",
    "ref = pd.DataFrame()\n",
    "for file in os.listdir(ref_pth):\n",
    "    if 'Farinotti' in file:\n",
    "        file_reader = pd.read_csv('reference_thicknesses/' + file)\n",
    "        ref = pd.concat([ref, file_reader], ignore_index = True) \n",
    "ref = ref.rename(columns = {\n",
    "     'Farinotti Mean Thickness':'FMT',\n",
    "})\n",
    "ref = ref[[\n",
    "     'FMT',\n",
    "     'RGIId',\n",
    "]]\n",
    "\n",
    "df = pd.merge(df, ref, how = 'inner', on = 'RGIId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['est'] = df[['UCI','LCI']].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Thickness']\n",
    "# y = np.mean(dfci, axis = 1)\n",
    "# y = df['we']\n",
    "y = df['est']\n",
    "plt.scatter(\n",
    "    x,y,\n",
    "        alpha = 0.25,\n",
    "#     label = 'Estimates $\\hat{\\mu}(x)$',\n",
    "    marker = '.',\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    (x.min(),x.max()),\n",
    "    (x.min(),x.max()),\n",
    "    '-k'\n",
    ")\n",
    "\n",
    "plt.ylabel('Estimated Thickness')\n",
    "plt.xlabel('GlaThiDa Survey')\n",
    "# plt.title('Leave-One-Out X-val 95% CI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e88963",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df['Thickness']\n",
    "obs_mean = obs.mean()\n",
    "obs_std = obs.std()\n",
    "obs_se = obs_mean / obs_std\n",
    "\n",
    "pred = df['est']\n",
    "pred_mean = pred.mean()\n",
    "pred_std = pred.std()\n",
    "pred_se = pred_mean / pred_std\n",
    "\n",
    "pooled_var = (obs_std**2 + pred_std**2) / 2\n",
    "\n",
    "t = (pred_mean - obs_mean) / 2\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df['Thickness']\n",
    "obs_mean = obs.mean()\n",
    "obs_std = obs.std()\n",
    "obs_se = obs_mean / obs_std\n",
    "\n",
    "pred = df['FMT']\n",
    "pred_mean = pred.mean()\n",
    "pred_std = pred.std()\n",
    "pred_se = pred_mean / pred_std\n",
    "\n",
    "pooled_var = (obs_std**2 + pred_std**2) / 2\n",
    "\n",
    "t = (pred_mean - obs_mean) / 2\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292c92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(df[cols].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = np.cov(df[cols])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72714cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef(df[cols].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180ceee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(13, 12))\n",
    "plt.matshow(\n",
    "    cov, fignum=f.number,cmap = 'seismic',vmin=-1000, vmax=1000\n",
    ")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "# plt.title('Covariance Matrix of Survey Thickness and Model Estimates', fontsize=18)\n",
    "# plt.xlabel('Model Thickness Estimates',fontsize = 14)\n",
    "# plt.ylabel('GlaThiDa Survey Thickness',fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_covs_ind = mean_covs[mean_covs < 0].index\n",
    "zer_covs_ind = mean_covs[mean_covs == 0].index\n",
    "nan_covs_ind = mean_covs[mean_covs == np.nan].index\n",
    "pos_covs_ind = mean_covs[mean_covs > 0].index\n",
    "\n",
    "negs = dft.iloc[neg_covs_ind]\n",
    "zero = dft.iloc[zer_covs_ind]\n",
    "pos = dft.iloc[pos_covs_ind]\n",
    "nans = dft.iloc[nan_covs_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54ed39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_eval = np.linspace(0,700,500)\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    x = df[cols].iloc[i]\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(x_eval, kde(x_eval), '-',alpha = 0.25)\n",
    "plt.xscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4afe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pd.DataFrame(cov)\n",
    "corr = pd.DataFrame(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_d = cov.drop(cov[cov[cols] <= 0].dropna(axis = 0).index)\n",
    "corr_d = corr.drop(corr[corr[cols] <= 0].dropna(axis = 0).index)\n",
    "corr_d = corr.drop(corr[corr[cols] <= 0].dropna(axis = 0).index)\n",
    "\n",
    "cov_d = cov_d.reset_index().drop('index',axis = 1)\n",
    "corr_d = corr_d.reset_index().drop('index',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = dft.drop(cov[cov[cols] <= 0].dropna(axis = 0).index)\n",
    "dftr = dftr.reset_index().drop('index',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d674978",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "p = plt.get_cmap('seismic')\n",
    "n = 0\n",
    "for i in tqdm(\n",
    "    dftr.sort_values('Thickness',ascending = True).index,\n",
    "#     dftr.sort_values('Thickness',ascending = True).reset_index().index\n",
    "):\n",
    "#     print(dft['Thickness'].loc[i])\n",
    "\n",
    "    \n",
    "    x =df[cols].loc[i]\n",
    "\n",
    "    x_eval = np.linspace(x.min(),x.max(),500)\n",
    "\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(\n",
    "        x_eval, kde(x_eval), '-',alpha = 0.75,\n",
    "        c = p(n/(len(dft) - 1))\n",
    "    )\n",
    "    n = n + 1\n",
    "#     c = p(n/(len(pos) - 1))\n",
    "# plt.ylim(0,0.2)\n",
    "# plt.yscale('log')\n",
    "plt.xscale('symlog')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.xlabel('Thickness')\n",
    "plt.title('Leave-One-Out Thickness PDF')\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)    \n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "    ax_cb, cmap=p, orientation='vertical',\n",
    "    ticklocation = 'auto',ticks = [],\n",
    "    label = 'Left-Out Thickness'\n",
    ")\n",
    "cb1.set_ticks(ticks = (0,1),labels = ['Min','Max'])\n",
    "# cb1.set_label('Thickness',x = -0.07)\n",
    "plt.gcf().add_axes(ax_cb)\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e65392",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "p = plt.get_cmap('seismic')\n",
    "n = 0\n",
    "for i in tqdm(\n",
    "    dftr.sort_values('Thickness',ascending = True).index,\n",
    "#     dftr.sort_values('Thickness',ascending = True).reset_index().index\n",
    "):\n",
    "#     print(dft['Thickness'].loc[i])\n",
    "\n",
    "    \n",
    "    x =cov_d.loc[i]\n",
    "\n",
    "    x_eval = np.linspace(x.min(),x.max(),500)\n",
    "\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(\n",
    "        x_eval, kde(x_eval), '-',alpha = 0.25,\n",
    "        c = p(n/(len(dft) - 1))\n",
    "    )\n",
    "    n = n + 1\n",
    "#     c = p(n/(len(pos) - 1))\n",
    "# plt.ylim(0,0.2)\n",
    "plt.yscale('log')\n",
    "plt.xscale('symlog')\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Covariance')\n",
    "plt.title('Leave-One-Out Covariance PDF')\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)    \n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "    ax_cb, cmap=p, orientation='vertical',\n",
    "    ticklocation = 'auto',ticks = [],\n",
    "    label = 'Thickness index'\n",
    ")\n",
    "cb1.set_ticks(ticks = (0,1),labels = ['Min','Max'])\n",
    "# cb1.set_label('Thickness',x = -0.07)\n",
    "plt.gcf().add_axes(ax_cb)\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46495b28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "\n",
    "p = plt.get_cmap('seismic')\n",
    "thickness = dft['Thickness']\n",
    "n = 0\n",
    "for i in tqdm(\n",
    "    dftr.sort_values('Thickness',ascending = True).index,\n",
    "#     dftr.sort_values('Thickness',ascending = True).reset_index().index\n",
    "):\n",
    "#     print(dft['Thickness'].loc[i])\n",
    "    x = df[cols].loc[i]\n",
    "    x_eval = np.linspace(x.min(),x.max(),500)\n",
    "\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(\n",
    "        x_eval, kde(x_eval), '-',alpha = 0.75,\n",
    "        c = p(n/(len(dft) - 1))\n",
    "    )\n",
    "    n = n + 1\n",
    "#     c = p(n/(len(pos) - 1))\n",
    "    \n",
    "plt.xscale('symlog')\n",
    "# plt.yscale('log')\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Covariance')\n",
    "plt.title('Leave-One-Out Covariance PDF')\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "ax_cb = divider.new_horizontal(size=\"5%\", pad=0.05)    \n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "    ax_cb, cmap=p, orientation='vertical',\n",
    "    ticklocation = 'auto',ticks = [],\n",
    "    label = 'Thickness index'\n",
    ")\n",
    "cb1.set_ticks(ticks = (0,1),labels = ['Min','Max'])\n",
    "# cb1.set_label('Thickness',x = -0.07)\n",
    "plt.gcf().add_axes(ax_cb)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "(n/(len(dft) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f966653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.get_cmap('seismic')\n",
    "\n",
    "for i in tqdm(negs.sort_values('Thickness',ascending = True).index):\n",
    "    print(i)\n",
    "    x = df[cols].iloc[i]\n",
    "    x_eval = np.linspace(x.min(),x.max(),500)\n",
    "\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(x_eval, kde(x_eval), '-',alpha = 0.5,c = p(i/(len(pos) - 1)))\n",
    "plt.xscale('symlog')\n",
    "# plt.colorbar(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.get_cmap('seismic')\n",
    "\n",
    "for i in tqdm(zero.sort_values('Thickness',ascending = True).index):\n",
    "    print(i)\n",
    "    x = df[cols].iloc[i]\n",
    "    x_eval = np.linspace(x.min(),x.max(),500)\n",
    "\n",
    "    kde = st.gaussian_kde(np.array(x))\n",
    "    plt.plot(x_eval, kde(x_eval), '-',alpha = 0.5,c = p(i/(len(pos) - 1)))\n",
    "plt.xscale('symlog')\n",
    "# plt.colorbar(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde95d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pd.DataFrame(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d265561",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_covs = np.mean(cov, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(    pos['Zmin'],pos['Thickness'],alpha = 0.25\n",
    ")\n",
    "plt.scatter(\n",
    "    negs['Zmin'],negs['Thickness']\n",
    ")\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530f918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ab13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(np.sum(cov,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = np.array(df[cols].T)\n",
    "plt.scatter(loo[:,65],loo[:,275])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09be853",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[cols].iloc[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee297e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b36873",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pd.DataFrame(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52587f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.iloc[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cov[cols] <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f01810",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(np.where(cov<0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[cov[cols] <= 0].dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[(cov[cov.columns] < 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e08a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.iloc[55].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cov.iloc[np.where(cov<=0)[1]].index).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.iloc[bad_glacs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee474b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.unique(bad_glacs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa968c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ffb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a0955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.unique(np.where(cov[,:]<0)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2301ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea295d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960205dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cov==cov.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    eigenvectors, eigenvectors\n",
    ")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(eigenvalues == np.max(eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b860940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvalues,linestyle = None)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494e290",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x = np.linspace(eigenvectors.min(),eigenvectors.max(),len(eigenvectors))\n",
    "# for i in range(340):\n",
    "plt.plot(\n",
    "    eigenvectors[0],linestyle = None\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f392f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Residual'] = df['est'] - df['Thickness']\n",
    "df['FResidual'] = df['FMT'] - df['Thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74115d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = df['Residual'].mean()\n",
    "std_1 = df['Residual'].std()\n",
    "se_1 = df['Residual'].std() / np.sqrt(341)\n",
    "\n",
    "mean_2 = df['FResidual'].mean()\n",
    "std_2 = df['FResidual'].std()\n",
    "se_2 = df['FResidual'].std() / np.sqrt(341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_1 = (mean_1 - 0) / se_1\n",
    "\n",
    "Z_2 = (mean_2 - 0) / se_2\n",
    "\n",
    "print(Z_1)\n",
    "print(Z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3388ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = df['Residual']\n",
    "x2 = df['FResidual']\n",
    "kde1 = stats.gaussian_kde(np.array(x1))\n",
    "kde2 = stats.gaussian_kde(np.array(x2))\n",
    "#visualize KDE\n",
    "x1_eval = np.linspace(x1.min(),x1.max(), num=200)\n",
    "plt.plot(x1_eval, kde1(x1_eval), '-',color = 'blue',label = 'This study Residual')\n",
    "\n",
    "x2_eval = np.linspace(x2.min(),x2.max(), num=200)\n",
    "plt.plot(x2_eval, kde2(x2_eval),color = 'orange',label = 'Farinotti Residual')\n",
    "\n",
    "plt.plot(\n",
    "    (x1.mean(),x1.mean()),\n",
    "    (0,0.02),'--',color = 'blue',label = 'This Study Mean Residual'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    (x2.mean(),x2.mean()),\n",
    "    (0,0.02),'--',color = 'orange',label = 'Farinotti Mean Residual'\n",
    ")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "print(f'This study mean residual = {x1.mean()}')\n",
    "print(f'Farinotti mean residual = {x2.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b247d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.var(x1))\n",
    "print(np.var(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get probability\n",
    "p1 = kde1.integrate_box_1d(-np.inf, 0)\n",
    "p2 = kde2.integrate_box_1d(-np.inf, 0)\n",
    "print(f'probabiliity of achieving residual of 0 = {p1}')\n",
    "print(f'probabiliity of achieving Fresidual of 0 = {p2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "print(st.norm.pdf(Z_1))\n",
    "print(st.norm.pdf(Z_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9587228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = np.sort(np.random.standard_normal(size=500))\n",
    "kde1 = stats.gaussian_kde(np.array(x1))\n",
    "kde2 = stats.gaussian_kde(np.array(x2_eval))\n",
    "#visualize KDE\n",
    "plt.plot(x1, kde1(x1), '-',color = 'blue',label = 'This study Residual')\n",
    "\n",
    "# x2_eval = np.linspace(x2.min(),x2.max(), num=200)\n",
    "# plt.plot(x2_eval, kde2(x2_eval),color = 'orange',label = 'Farinotti Residual')\n",
    "\n",
    "# plt.plot(\n",
    "#     (x1.mean(),x1.mean()),\n",
    "#     (0,0.02),'--',color = 'blue',label = 'This Study Mean Residual'\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     (x2.mean(),x2.mean()),\n",
    "#     (0,0.02),'--',color = 'orange',label = 'Farinotti Mean Residual'\n",
    "# )\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "print(f'This study mean residual = {x1.mean()}')\n",
    "print(f'Farinotti mean residual = {x2.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87992804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e42b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1a96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c335ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e72e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbafa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc15522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a1aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c196f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(216501):\n",
    "    glac = RGI.iloc[i]\n",
    "    print(sum(glac[cols] / fr['unc']) / sum(1/fr['unc']))\n",
    "    break\n",
    "#     (RGI[cols] /  fr['unc'].T) / (1/fr['unc'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdaf4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.hist(data[range(341)].iloc[random.randint(0,341)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d511c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87660c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'LOO Global Volume Estimate {np.round(sum(lb)), np.round(sum(ub))} * 10^3 km^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfci = df[['LCI','UCI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2274556",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Thickness']\n",
    "y = np.mean(dfci, axis = 1)\n",
    "plt.errorbar(\n",
    "    x,y,yerr = df['UCI'] - df['LCI'],\n",
    "        alpha = 0.25,\n",
    "#     label = 'Estimates $\\hat{\\mu}(x)$',\n",
    "    linestyle = 'None',\n",
    "    marker = 'o',\n",
    "    capsize = 8,\n",
    "    color = '#1f77b4',\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    (x.min(),x.max()),\n",
    "    (y.min(),y.max()),\n",
    "    '-k'\n",
    ")\n",
    "\n",
    "plt.ylabel('Estimated Thickness')\n",
    "plt.xlabel('GlaThiDa Survey')\n",
    "plt.title('Leave-One-Out X-val 95% CI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['we'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8bcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89802ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f98d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b2711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8456a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155afa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e52684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.8.10)",
   "language": "python",
   "name": "new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
