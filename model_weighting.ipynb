{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterization = '4'\n",
    "data = gl.parameterize_data(parameterization)\n",
    "model_statistics = pd.read_pickle('zults/model_statistics_' + parameterization + '.pkl')\n",
    "\n",
    "architecture_weights, residual_model = gl.compute_model_weights(\n",
    "    model_statistics, parameterization, pth = '/data/fast1/glacierml/data'\n",
    ")\n",
    "\n",
    "architecture_weights\n",
    "aw = architecture_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9023f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c73fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "aw['IQR_1'] / 1.34896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d391e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw.aw_1,\n",
    "    label = 'Interpretation 1'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw.aw_2,\n",
    "    label = 'Interpretation 2'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw.aw_3,\n",
    "    label = 'Interpretation 3'\n",
    ")\n",
    "plt.ylabel('Architecture Weight')\n",
    "plt.xlabel('Architecture Index')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(\n",
    "#     aw.index, \n",
    "#     1 / (np.cumsum(1/ architecture_weights['architecture weight']))\n",
    "# )\n",
    "# plt.title('Cumulative Thickness Variance' +  \n",
    "#           r' $\\hat{\\sigma}_{l}^{2} =\\frac{{1}}{{\\sum_{i}1 / \\sigma^{2}_{il}}}$'\n",
    "#          )\n",
    "# plt.xlabel('Architecture Index (i)')\n",
    "# plt.ylabel('Composite Variance $(\\hat{\\sigma}_{l}^{2})$')\n",
    "# plt.grid(visible = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a666279",
   "metadata": {},
   "source": [
    "# Model Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterization = '4'\n",
    "est = pd.read_pickle('model_weights/param' + parameterization + '_weighting_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345672b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e750c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "     '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "     '9', '10', '11', '12', '13', '14', '15', '16',\n",
    "     '17', '18', '19', '20', '21', '22', '23', '24',\n",
    "]\n",
    "pool_list = [\n",
    "     'pr_0', 'pr_1', 'pr_2', 'pr_3', 'pr_4', 'pr_5', 'pr_6', 'pr_7', 'pr_8',\n",
    "     'pr_9', 'pr_10', 'pr_11', 'pr_12', 'pr_13', 'pr_14', 'pr_15', 'pr_16',\n",
    "     'pr_17', 'pr_18', 'pr_19', 'pr_20', 'pr_21', 'pr_22', 'pr_23', 'pr_24',\n",
    "]\n",
    "res_list = [\n",
    "     'r_0', 'r_1', 'r_2', 'r_3', 'r_4', 'r_5', 'r_6', 'r_7', 'r_8',\n",
    "     'r_9', 'r_10', 'r_11', 'r_12', 'r_13', 'r_14', 'r_15', 'r_16',\n",
    "     'r_17', 'r_18', 'r_19', 'r_20', 'r_21', 'r_22', 'r_23', 'r_24',\n",
    "]\n",
    "weight_list = [\n",
    "     'w_0', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6', 'w_7', 'w_8',\n",
    "     'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15', 'w_16',\n",
    "     'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e76fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "est[model_list] = np.round(est[model_list], 0)\n",
    "est[pool_list] = np.round(est[pool_list], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbb693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(0,54901,161)):\n",
    "#     print(i)\n",
    "#     print(i + 161)\n",
    "#     print('')\n",
    "    \n",
    "    dfg = est[model_list].iloc[i:i+161]\n",
    "    y = pd.DataFrame(dfg.var(axis = 0)).astype(float)\n",
    "    x = est[[\n",
    "         'CenLat',\n",
    "         'CenLon',\n",
    "         'Slope',\n",
    "         'Zmin',\n",
    "         'Zmed',\n",
    "         'Zmax',\n",
    "         'Area',\n",
    "         'Aspect',\n",
    "         'Lmax',\n",
    "         'Thickness',\n",
    "    ]].iloc[i:i+25]\n",
    "    \n",
    "    dft = pd.concat([x.reset_index(drop=True),y.reset_index(drop=True)],axis=1)\n",
    "    df = pd.concat([df, dft])\n",
    "#     break\n",
    "for i in list(x):\n",
    "    fig, ax = plt.subplots(1,1,figsize = (10,10))\n",
    "    plt.scatter(\n",
    "        df[i],\n",
    "        df[0]\n",
    "    )\n",
    "    plt.title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.random.normal(1, 2, 7500)\n",
    "# f = np.random.normal(1, 2, 216501)\n",
    "\n",
    "plt.hist((f), 25)\n",
    "# plt.yscale('log')\n",
    "plt.plot(\n",
    "    [np.percentile(f,50),np.percentile(f,50)],\n",
    "    [0,950], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,25),np.percentile(f,25)],\n",
    "    [0,900], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,75),np.percentile(f,75)],\n",
    "    [0,900], 'k--'\n",
    ")\n",
    "plt.text(\n",
    "    \n",
    "    \n",
    "    (f).mean() - 0.5,\n",
    "    955, s = 'Median'\n",
    ")\n",
    "plt.text(\n",
    "    np.percentile(f,75) + .18 ,\n",
    "    900, s = 'Q3'\n",
    ")\n",
    "plt.text(\n",
    "    np.percentile(f, 25) - 0.76,\n",
    "    900, s = 'Q1'\n",
    ")\n",
    "\n",
    "\n",
    "np.percentile(f,75) - np.percentile(f, 25)\n",
    "plt.ylim([0,1150])\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ec266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f84b15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f = est[pool_list].to_numpy().flatten()\n",
    "plt.hist((f), 25)\n",
    "plt.yscale('log')\n",
    "plt.plot(\n",
    "    [f.mean(),f.mean()],\n",
    "    [0,1e7], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,25),np.percentile(f,25)],\n",
    "    [0,1e7], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,75),np.percentile(f,75)],\n",
    "    [0,1e7], 'k--'\n",
    ")\n",
    "# plt.text(\n",
    "    \n",
    "    \n",
    "#     (f).mean() - 0.5,\n",
    "#     1e7, s = 'Median'\n",
    "# )\n",
    "# plt.text(\n",
    "#     np.percentile(f,75) + .18 ,\n",
    "#     4000000, s = 'Q3'\n",
    "# )\n",
    "# plt.text(\n",
    "#     np.percentile(f, 25) - 0.76,\n",
    "#     4000000, s = 'Q1'\n",
    "# )\n",
    "\n",
    "# plt.ylim([0,1150])\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = est[pool_list][est[pool_list].values <2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fake data\n",
    "x = f\n",
    "\n",
    "# setup the figure and axes\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "bpAx = fig.add_axes([0.2, 0.7, 0.7, 0.2])   # left, bottom, width, height:\n",
    "                                            # (adjust as necessary)\n",
    "histAx = fig.add_axes([0.2, 0.2, 0.7, 0.5]) # left specs should match and\n",
    "                                            # bottom + height on this line should\n",
    "                                            # equal bottom on bpAx line\n",
    "# plot stuff\n",
    "bp = bpAx.boxplot(x, notch=True, vert=False)\n",
    "h = histAx.hist(x, bins=25)\n",
    "\n",
    "# confirm that the axes line up \n",
    "xlims = np.array([bpAx.get_xlim(), histAx.get_xlim()])\n",
    "# for ax in [bpAx, histAx]:\n",
    "#     ax.set_xlim([xlims.min(), xlims.max()])\n",
    "\n",
    "bpAx.set_xticklabels([])  # clear out overlapping xlabels\n",
    "bpAx.set_yticks([])  # don't need that 1 tick mark\n",
    "# plt.yscale('log')\n",
    "plt.plot(\n",
    "    [np.percentile(f, 50),np.percentile(f,50)],\n",
    "    [0,120000], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,25),np.percentile(f,25)],\n",
    "    [0,120000], 'k--'\n",
    ")\n",
    "plt.plot(\n",
    "    [np.percentile(f,75),np.percentile(f,75)],\n",
    "    [0,120000], 'k--'\n",
    ")\n",
    "# plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "np.percentile(f,75) - np.percentile(f,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8c4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(est[pool_list].to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c1cb7",
   "metadata": {},
   "source": [
    "# By Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03046f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "est[res_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb031b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = pd.DataFrame()\n",
    "architecture_weights = pd.DataFrame()\n",
    "for i in tqdm(est['layer architecture'].unique()):\n",
    "    dft = est[est['layer architecture'] == str(i)]\n",
    "    \n",
    "    \n",
    "    # simple method\n",
    "    simple_var = np.var(dft[res_list].to_numpy().flatten())\n",
    "    q75, q25 = np.nanpercentile(dft[res_list], [75,25])\n",
    "    sigma_simple = ((q75 - q25) ) / 1.5 \n",
    "    \n",
    "    \n",
    "    # interpretation 1: pooling just the model stuff\n",
    "    bias_1 = np.mean(dft[pool_list].to_numpy()) * np.mean(dft[model_list].to_numpy())\n",
    "    \n",
    "    q75, q25 = np.nanpercentile(dft[pool_list], [75,25])\n",
    "    sigma_1 = ((q75 - q25) * np.mean(dft[model_list].to_numpy())) / 1.5 \n",
    "    \n",
    "    \n",
    "    # interpretation 2: pool model, but take the mean creatively\n",
    "    bias_2 = np.mean(dft[pool_list].to_numpy() * dft[model_list].to_numpy())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # interpretation 3: Take the mean of the pool and scale by model thickness\n",
    "    bias_3 = np.mean(est[pool_list].to_numpy()) * np.mean(dft[model_list].to_numpy())\n",
    "    q75, q25 = np.nanpercentile(est[pool_list], [75,25])\n",
    "    sigma_3 = ((q75 - q25) * np.mean(dft[model_list].to_numpy())) / 1.5 \n",
    "       \n",
    "    var = dft[model_list].values.var()\n",
    "    w = pd.Series(\n",
    "        abs(bias_1) + sigma_1**2, \n",
    "        name = 'weight'\n",
    "    )\n",
    "    \n",
    "    w = pd.Series(\n",
    "        simple_var, \n",
    "        name = 'weight'\n",
    "    )\n",
    "    \n",
    "    w = pd.Series(\n",
    "        abs(bias_1) + sigma_1**2, \n",
    "        name = 'weight'\n",
    "    )\n",
    "#     print(var)\n",
    "#     break\n",
    "    architecture_weights = pd.concat([architecture_weights, w])\n",
    "    architecture_weights = architecture_weights.reset_index()\n",
    "    architecture_weights = architecture_weights.drop('index', axis = 1)\n",
    "    \n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'layer architecture'] = i\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'bias1'] = bias_1\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'bias2'] = bias_2\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'bias3'] = bias_3\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'var_1'] = sigma_1**2\n",
    "#     architecture_weights.loc[architecture_weights.index[-1], 'std'] = sigma\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'var_2'] = sigma_3**2\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'simple var'] = simple_var\n",
    "    architecture_weights.loc[architecture_weights.index[-1], 'simple sig'] = sigma_simple\n",
    "\n",
    "    \n",
    "#     break\n",
    "architecture_weights = architecture_weights.rename(columns = {0:'architecture weight'})\n",
    "aw = architecture_weights\n",
    "aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bd3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fdcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c308ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['layer architecture'].iloc[ticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True)\n",
    "ax.scatter(\n",
    "    data['layer architecture'],\n",
    "    (data['architecture weight'])\n",
    ")\n",
    "# plt.grid(False)\n",
    "# plt.xlabel('layer architecture')\n",
    "# plt.ylabel('architecture weight')\n",
    "ax_upper = ax.twiny() \n",
    "ax_upper.set_xticks(ax.get_xticks(), rotation = 45, \n",
    "                    labels = data['trained parameters'].iloc[ticks]\n",
    ")\n",
    "# ax.grid(False)\n",
    "ax_upper.grid(False)\n",
    "ax_upper.set_xlabel('Model Parameters')\n",
    "ax.set_xlabel('Layer Architecture')\n",
    "ax.set_ylabel('Architecture Weight')\n",
    "fig.subplots_adjust(top=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69807f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# ax1 = fig.add_subplot(111)\n",
    "ax.scatter(\n",
    "    data['layer architecture'],\n",
    "    (data['architecture weight'])\n",
    ")\n",
    "\n",
    "\n",
    "ticks = []\n",
    "for i in range(0,161,20):\n",
    "    print(i)\n",
    "    ticks.append(i)\n",
    "ax.set_xticks(ticks, rotation = 45, labels = data['layer architecture'].iloc[ticks])\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Layer Architecture')\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xticks( ax.get_xticks() )\n",
    "ax2.set_xbound(ax.get_xbound())\n",
    "ax2.set_xticks(ax.get_xticks(), rotation = 45, \n",
    "                    labels = data['trained parameters'].iloc[ticks]\n",
    ")\n",
    "ax2.grid(False)\n",
    "ax2.set_xlabel('Trained Model Parameters')\n",
    "ax.set_ylabel('Architecture Weight')\n",
    "# title = ax1.set_title(\"Upper x-axis ticks are lower x-axis ticks doubled!\")\n",
    "# title.set_y(1.1)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.suptitle('Architecture Weights as a Function of Model Complexity',y = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'zults/'\n",
    "predictions = pd.DataFrame()\n",
    "statistics = pd.DataFrame()\n",
    "file_reader = pd.read_pickle(rootdir + 'model_statistics_' + parameterization + '.pkl')\n",
    "statistics = pd.concat([statistics, file_reader], ignore_index = True)\n",
    "\n",
    "# statistics = statistics.drop('Unnamed: 0', axis = 1)\n",
    "statistics['total parameters'] = statistics['total parameters'].astype(int)\n",
    "statistics['trained parameters'] = statistics['trained parameters'].astype(int)\n",
    "statistics['total inputs'] = statistics['total inputs'].astype(int)\n",
    "statistics['test - train'] = (\n",
    "    abs(statistics['test mae avg'] - statistics['train mae avg']))\n",
    "statistics['paramater ratio'] = statistics['trained parameters'] / statistics['total inputs']\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics[statistics['test mae avg'] == statistics['test mae avg'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(aw, statistics, how = 'inner', on = 'layer architecture')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed40275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(data, est, how = 'inner', on = 'layer architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f669781",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(\n",
    "    (0,5),(0,5)\n",
    ")\n",
    "ax1.set_xlim(0,5)\n",
    "ax1.set_ylim(0,5)\n",
    "# ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "ax2.set_xticks( ax1.get_xticks() )\n",
    "# ax2.set_xbound(ax1.get_xbound())\n",
    "# ax2.set_xticklabels([x * 2 for x in ax1.get_xticks()])\n",
    "\n",
    "title = ax1.set_title(\"Upper x-axis ticks are lower x-axis ticks doubled!\")\n",
    "# title.set_y(1.1)\n",
    "# fig.subplots_adjust(top=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c86f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dfc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247424b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['architecture weight'] == data['architecture weight'].min())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf454596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    aw.index,\n",
    "    (aw['simple sig'])**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfef2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4,1):\n",
    "    plt.scatter(\n",
    "        aw.index,\n",
    "        aw['bias'+str(i)], \n",
    "        label = 'Interpretation '+str(i)\n",
    "    )\n",
    "plt.ylabel('Model Bias')\n",
    "plt.xlabel('Architecture Index')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec11422",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_1'],\n",
    "    label = 'Model Pool Deviation IQR'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_2'],\n",
    "    label = 'Total Pool Deviation IQR'\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_1'] + aw['bias1'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 1'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_1'] + aw['bias2'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 2'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_1'] + aw['bias3'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 3'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_2'] + aw['bias1'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 4'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_2'] + aw['bias2'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 5'\n",
    ")\n",
    "plt.scatter(\n",
    "    aw.index,\n",
    "    aw['var_2'] + aw['bias3'],\n",
    "    alpha = 0.5,\n",
    "    label = 'Weight 6'\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / sum(1/architecture_weights['architecture weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ca753",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(architecture_weights.index, architecture_weights['architecture weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8135541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a471004",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2,1, figsize = (10,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.scatter(\n",
    "    architecture_weights['layer architecture'],\n",
    "    architecture_weights['architecture weight']\n",
    ")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=True)\n",
    "plt.grid(False)\n",
    "plt.xlabel('Layer Architecture')\n",
    "plt.xticks([architecture_weights['layer architecture'].iloc[0], \n",
    "            architecture_weights['layer architecture'].iloc[85],\n",
    "            architecture_weights['layer architecture'].iloc[160]])\n",
    "plt.ylabel('Architecture Weight')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "sum_of_weights = sum(1/architecture_weights['architecture weight'])\n",
    "\n",
    "plt.plot(\n",
    "    np.sort(1/architecture_weights['architecture weight'][::-1] )/ sum_of_weights, 'o'\n",
    "#     marker = '.',\n",
    "#     linestyle = None\n",
    "    \n",
    ")\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=False)\n",
    "plt.ylabel('Fractional Weight')\n",
    "# string = '$w_{i} = \\frac{1}{N_{g}N_{x}} \\sum_{j}^{N_g} \\sum_{k}^{N_x} \\left(R_{ijk} - M_{i}\\right)^2$'\n",
    "plt.suptitle('Simple Residual Variance Weights $ w_i = {}^{R}_{}\\sigma^{2}_{i}$', y = 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    1/np.cumsum(1/aw['architecture weight'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c697c93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2,1, figsize = (10,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.scatter(\n",
    "    architecture_weights['layer architecture'],\n",
    "    architecture_weights['architecture weight']\n",
    ")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=True)\n",
    "plt.grid(False)\n",
    "plt.xlabel('Layer Architecture')\n",
    "plt.xticks([architecture_weights['layer architecture'].iloc[0], \n",
    "            architecture_weights['layer architecture'].iloc[85],\n",
    "            architecture_weights['layer architecture'].iloc[160]])\n",
    "plt.ylabel('Architecture Weight')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "sum_of_weights = sum(1/architecture_weights['architecture weight'])\n",
    "\n",
    "plt.plot(\n",
    "    np.sort(1/architecture_weights['architecture weight'][::-1]) / sum_of_weights, 'o'\n",
    "#     marker = '.',\n",
    "#     linestyle = None\n",
    "    \n",
    ")\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=False)\n",
    "plt.ylabel('Fractional Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2,1, figsize = (10,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.scatter(\n",
    "    architecture_weights['layer architecture'],\n",
    "    architecture_weights['architecture weight']\n",
    ")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=True)\n",
    "plt.grid(False)\n",
    "plt.xlabel('Layer Architecture')\n",
    "plt.xticks([architecture_weights['layer architecture'].iloc[0], \n",
    "            architecture_weights['layer architecture'].iloc[85],\n",
    "            architecture_weights['layer architecture'].iloc[160]])\n",
    "plt.ylabel('Architecture Weight')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "sum_of_weights = sum(1/architecture_weights['architecture weight'])\n",
    "\n",
    "plt.plot(\n",
    "    np.sort(1/architecture_weights['architecture weight'])[::-1] / sum_of_weights, 'o'\n",
    "#     marker = '.',\n",
    "#     linestyle = None\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71403c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Compiling predictions...')\n",
    "arch_list = architecture_weights['layer architecture']\n",
    "df = pd.DataFrame(columns = [\n",
    "        'RGIId','0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24',\n",
    "])\n",
    "for arch in tqdm(arch_list):\n",
    "    df_glob = gl.load_global_predictions(\n",
    "        parameterization = parameterization,\n",
    "        architecture = arch\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df,df_glob])\n",
    "#     break\n",
    "statistics = pd.DataFrame()\n",
    "for file in (os.listdir('zults/')):\n",
    "    if 'statistics_' + parameterization in file:\n",
    "        file_reader = pd.read_pickle('zults/' + file)\n",
    "        statistics = pd.concat([statistics, file_reader], ignore_index = True)\n",
    "\n",
    "# df = pd.merge(df, statistics, on = 'layer architecture')\n",
    "df = df[[\n",
    "        'layer architecture','RGIId','0', '1', '2', '3', '4',\n",
    "        '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\n",
    "    'predicted_thicknesses/compiled_raw_4.h5', key = 'compiled_raw', mode = 'a'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675156cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_raw = df.groupby('RGIId')[[\n",
    "        'layer architecture','0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_D_common_estimator(n, S, X):\n",
    "    mu = sum((n / S)*X) / sum(n / S)\n",
    "    \n",
    "    return mu\n",
    "\n",
    "def unbiased_variance_estimator(n_m, n_x, sigma_m, sigma_x):\n",
    "    \n",
    "    q_1 = 4 / (n_m - 1)\n",
    "    q_2 = (n_m / sigma_m) / sum(n_x/sigma_x)\n",
    "    q_3 = (n_m / sigma_m**2) / sum(n_x/sigma_x)**2\n",
    "    q_4 = sum(n_m / sigma_m)\n",
    "    \n",
    "    var = (\n",
    "        (1 + sum(q_1 * (q_2 - q_3))) / q_4\n",
    "    )\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7198b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dft = pd.DataFrame()\n",
    "for this_rgi_id, obj in tqdm(compiled_raw):\n",
    "#     print(obj['layer architecture'])\n",
    "    rgi_id = pd.Series(this_rgi_id, name = 'RGIId')\n",
    "    print(rgi_id)\n",
    "#     print(rgi_id)\n",
    "#         print(f\"Data associated with RGI_ID = {this_rgi_id}:\")\n",
    "    dft = pd.concat([dft, rgi_id])\n",
    "    dft = dft.reset_index()\n",
    "    dft = dft.drop('index', axis = 1)\n",
    "    obj = obj[[\n",
    "        'layer architecture','0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24',\n",
    "    ]]\n",
    "    \n",
    "#     obj = pd.merge(obj, architecture_weights, how = 'inner', on = 'layer architecture')\n",
    "\n",
    "    \n",
    "#     arch_weight = obj[['architecture weight']]\n",
    "    \n",
    "#     aw = arch_weight.values.flatten()\n",
    "\n",
    "    predictions = obj[[\n",
    "        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24',\n",
    "    ]]\n",
    "    \n",
    "#     arch_weight = obj[['architecture weight']]\n",
    "#     aw = arch_weight.values.flatten()\n",
    "#     pr = np.array(predictions.values)\n",
    "\n",
    "    \n",
    "#     print(pr)\n",
    "#     weighted_mean = 0\n",
    "#     for p, w in zip(pr, aw):\n",
    "#         weighted_mean = weighted_mean + np.nanmean(p/w)\n",
    "#     weighted_mean = weighted_mean / sum(1/aw)\n",
    "    \n",
    "    \n",
    "#     dft.loc[dft.index[-1], 'Weighted Mean Thickness'] = weighted_mean\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\n",
    "#             pr[:][1:5]\n",
    "#     )\n",
    "#     print(\n",
    "#         np.mean(\n",
    "#             pr[:][0:160]\n",
    "#         )\n",
    "#     )\n",
    "#     print(\n",
    "#             np.var(pr[:][0:160])\n",
    "#     )\n",
    "#     print(\n",
    "#             np.sqrt(\n",
    "#                 np.var(pr[:][0:160])\n",
    "#             )\n",
    "#     )    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1d2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dft = pd.DataFrame()\n",
    "for this_rgi_id in tqdm(est['RGIId'].unique()):\n",
    "    dfr = est[est['RGIId'] == this_rgi_id]\n",
    "    rgi_id = pd.Series(this_rgi_id, name = 'RGIId')\n",
    "#     print(rgi_id)\n",
    "#     print(rgi_id)\n",
    "#         print(f\"Data associated with RGI_ID = {this_rgi_id}:\")\n",
    "    dft = pd.concat([dft, rgi_id])\n",
    "    dft = dft.reset_index()\n",
    "    dft = dft.drop('index', axis = 1)\n",
    "    obj = dfr[[\n",
    "        'layer architecture','0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24',\n",
    "    ]]\n",
    "    \n",
    "#     architecture_weights = pd.read_csv('architecture_weights.csv')\n",
    "#     architecture_weights = architecture_weights.drop('Unnamed: 0', axis = 1)\n",
    "    \n",
    "    obj = pd.merge(obj, architecture_weights, how = 'inner', on = 'layer architecture')\n",
    "\n",
    "    \n",
    "#     print(obj)\n",
    "    arch_weight = obj[['architecture weight']]\n",
    "    \n",
    "    aw = arch_weight.values.flatten()\n",
    "\n",
    "#     print(arch_weight)\n",
    "    predictions = obj[[\n",
    "        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','10',\n",
    "        '11','12','13','14','15','16','17','18','19','20','21',\n",
    "        '22','23','24',\n",
    "    ]]\n",
    "    \n",
    "#     std = \n",
    "    \n",
    "    pr = np.array(predictions.values)\n",
    "    variance = pr.var()\n",
    "    weighted_mean = 0\n",
    "    for p, w in zip(pr, aw):\n",
    "        weighted_mean = weighted_mean + (p/w)\n",
    "    weighted_mean = weighted_mean.mean().mean() / sum(1/aw)\n",
    "#     print(weighted_mean)\n",
    "    residual = (weighted_mean - dfr['Thickness'].mean())\n",
    "#     print('plain mean = ' + str(predictions.mean().mean()))\n",
    "#     print('weighted mean = ' + str(\n",
    "#         np.nansum(\n",
    "#             predictions.div(\n",
    "#             arch_weight.values).values) / np.nansum(1/arch_weight.values)\n",
    "#         weighted_mean\n",
    "#     ) \n",
    "#     )\n",
    "\n",
    "#     var = sd**2\n",
    "#     print(pr.flatten().var())\n",
    "#     print(pr.var())\n",
    "    var = pr.var(axis = 1)\n",
    "    var = predictions.values\n",
    "    dft.loc[dft.index[-1], 'Weighted Mean Thickness'] = weighted_mean\n",
    "    dft.loc[dft.index[-1], 'Model Variance'] = variance\n",
    "    dft.loc[dft.index[-1], 'Residual'] = residual\n",
    "    dft.loc[dft.index[-1], 'Thickness'] = dfr['Thickness'].mean()\n",
    "    dft.loc[dft.index[-1], 'Area'] = dfr['Area'].mean()\n",
    "               \n",
    "#     break\n",
    "dft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.8.10)",
   "language": "python",
   "name": "new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
