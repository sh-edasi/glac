{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331c805",
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import glacierml as gl\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tensorflow.python.util import deprecation\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import geopy\n",
    "# display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "RS = range(0,25,1)\n",
    "\n",
    "print('currently running tensorflow version: ' + tf.__version__)\n",
    "# df = df[[\n",
    "#     'area_g',\n",
    "#     'Area'\n",
    "# ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bf1b3",
   "metadata": {
    "code_folding": [
     4,
     13,
     24,
     36,
     48,
     60
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select dataset to analyze\n",
    "\n",
    "selected_dataset = 'df6'\n",
    "\n",
    "if selected_dataset == 'df1':\n",
    "    df1 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'n'\n",
    "    )\n",
    "    module = 'sm1'\n",
    "    res = 'sr1'\n",
    "    dataset = df1\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df2':\n",
    "    df2 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm2'\n",
    "    res = 'sr2'\n",
    "    dataset = df2\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df3':\n",
    "    df3 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 1\n",
    "    )\n",
    "    module = 'sm3'\n",
    "    res = 'sr3'\n",
    "    dataset = df3\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df4':\n",
    "    df4 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 5\n",
    "    )\n",
    "    module = 'sm4'\n",
    "    res = 'sr4'\n",
    "    dataset = df4\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df5':\n",
    "    df5 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    df5 = df5.drop('Zmed', axis = 1)\n",
    "    dataset = df5\n",
    "    dataset.name = selected_dataset\n",
    "    module = 'sm5'\n",
    "    res = 'sr5'\n",
    "if selected_dataset == 'df6':\n",
    "    df6 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'r',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm6'\n",
    "    res = 'sr6'\n",
    "    reg = df6['region'].iloc[-1]\n",
    "    df6 = df6.drop('region', axis=1)\n",
    "    dataset = df6 \n",
    "    dataset.name = str('df6_' + str(reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbd921",
   "metadata": {
    "code_folding": [
     4
    ],
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = 'zults/'\n",
    "predictions = pd.DataFrame()\n",
    "deviations = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    if 'predictions' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        predictions = predictions.append(file_reader, ignore_index = True)\n",
    "    if 'deviations' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        deviations = pd.concat([deviations, file_reader], ignore_index = True)\n",
    "        \n",
    "deviations = deviations.drop('Unnamed: 0', axis = 1)\n",
    "predictions = predictions.drop('Unnamed: 0', axis = 1)\n",
    "deviations['total parameters'] = deviations['total parameters'].astype(int)\n",
    "deviations['trained parameters'] = deviations['trained parameters'].astype(int)\n",
    "deviations['total inputs'] = deviations['total inputs'].astype(int)\n",
    "deviations = deviations[\n",
    "    (deviations['df'].str.contains('df6')) \n",
    "#     &\n",
    "#     (deviations['layer architecture'] == '24-12')\n",
    "#     &\n",
    "#     (deviations['learning rate'] == 0.010)\n",
    "#     &\n",
    "#     (deviations['epochs'] == 100)\n",
    "]\n",
    "deviations['test - train'] = (\n",
    "    abs(deviations['test mae avg'] - deviations['train mae avg'])\n",
    ")\n",
    "deviations = deviations.sort_values(\n",
    "    [\n",
    "#         'test - train',\n",
    "        'test mae avg', \n",
    "#         'test predicted thickness std dev'\n",
    "#         'layer architecture',\n",
    "#         'learning rate',\n",
    "        'df'\n",
    "    ]\n",
    ")\n",
    "deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inputs = (len(dataset) * (len(dataset.columns) -1))\n",
    "print('total inputs = ' + str(total_inputs))\n",
    "\n",
    "non_trainable_parameters = (len(dataset.columns)) + ((len(dataset.columns) - 1))\n",
    "print('non-trainable parameters = ' + str(non_trainable_parameters))\n",
    "\n",
    "layer_1 = 50\n",
    "layer_2 = 25\n",
    "\n",
    "total_parameters = (\n",
    "    layer_1 * (inputs + 1)  + \n",
    "    (layer_2 * (layer_1 + 1)) + \n",
    "    ((1 * (layer_2 + 1))) +\n",
    "    non_trainable_parameters\n",
    ")\n",
    "print('trainable parameters = ' + str(total_parameters - non_trainable_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb87762",
   "metadata": {
    "code_folding": [
     25,
     39
    ],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we load top rated model and look at predicted accuracies of each random state\n",
    "\"\"\"\n",
    "print('Please select index from deviations table to inspect further')\n",
    "\n",
    "selection = int(input())\n",
    "\n",
    "arch = deviations['layer architecture'].loc[selection]\n",
    "top_learning_rate = deviations['learning rate'].loc[selection]\n",
    "epochs = deviations['epochs'].loc[selection]\n",
    "dropout = deviations['dropout'].loc[selection]\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "dnn_model = {}\n",
    "rootdir = 'saved_models/' + module + '/sm_' + arch + '/'\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = gl.data_splitter(dataset)\n",
    "features = pd.concat([train_features, test_features], ignore_index = True)\n",
    "labels = pd.concat([train_labels, test_labels], ignore_index = True)\n",
    "for rs in tqdm(RS):\n",
    "    \n",
    "    model_name = (\n",
    "        str(arch) + \n",
    "        '_' + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )   \n",
    "    \n",
    "    model_path = (\n",
    "        rootdir + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_model[model_name] = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    \n",
    "    y = dnn_model[model_name].predict(features, verbose = 0)\n",
    "    fig,ax=plt.subplots(1,1,figsize=(15,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    plt.plot(labels,y,'.')\n",
    "    plt.plot((0,400),(0,400),'-')\n",
    "    plt.xlabel('True Thickness (m)')\n",
    "    plt.ylabel('Model Thickness (m)')\n",
    "    ax.set_title('Random State ' +str(rs))\n",
    "    plt.xlim((0,400))\n",
    "    plt.ylim((0,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39873db2",
   "metadata": {
    "code_folding": [
     7,
     19,
     21,
     35,
     54
    ],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig_dir = (\n",
    "    'figs/' + \n",
    "    module + \n",
    "    '/'   \n",
    ") \n",
    "isdir = os.path.isdir(fig_dir)\n",
    "if isdir == False:\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "print(fig_dir)\n",
    "rootdir = 'saved_results/' + res + '/sr_' + arch + '/'\n",
    "print(rootdir)\n",
    "dnn_history = {}\n",
    "for rs in RS: \n",
    "    \n",
    "    history_name = (\n",
    "        arch + \n",
    "        '_' +\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    model_name = (\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_history[model_name] = pd.read_csv(rootdir + model_name)\n",
    "\n",
    "    fig,ax=plt.subplots(1,1,figsize=(10,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    ax.set_title(history_name)\n",
    "    gl.plot_loss(dnn_history[model_name])\n",
    "    \n",
    "file_name = (\n",
    "    fig_dir +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) + '_' +\n",
    "    str(rs) + '_' +\n",
    "    '.eps'\n",
    ")\n",
    "\n",
    "print(file_name)\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71abc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccccombo_breaker()\n",
    "# past this point is under construction. \n",
    "# here be monsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cded1b",
   "metadata": {
    "code_folding": [
     0,
     4,
     16,
     26
    ]
   },
   "outputs": [],
   "source": [
    "# compare RGI regional attributes with RGI regions matched with GlaThiDa thicknesses\n",
    "\n",
    "dfs = pd.DataFrame()\n",
    "pth_3 = '/data/fast1/glacierml/data/regional_data/raw/'\n",
    "for file in tqdm(os.listdir(pth_3)):\n",
    "    df = pd.read_csv(pth_3 + file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    region_and_number = file[:-4]\n",
    "    region_number = region_and_number[:2]\n",
    "    region = region_and_number[3:]\n",
    "\n",
    "    df['geographic region'] = region\n",
    "    df['region'] = region_number\n",
    "    dfs = dfs.append(df, ignore_index=True)\n",
    "\n",
    "dfs = dfs.reset_index()\n",
    "\n",
    "dfs = dfs[[\n",
    "    'GlaThiDa_index',\n",
    "    'RGI_index',\n",
    "    'RGIId',\n",
    "    'region',\n",
    "    'geographic region'\n",
    "]]\n",
    "\n",
    "pth = '/data/fast1/glacierml/data/RGI/rgi60-attribs/'\n",
    "RGI_extra = pd.DataFrame()\n",
    "for file in os.listdir(pth):\n",
    "    f = pd.read_csv(pth + file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    RGI_extra = pd.concat([RGI_extra, f], ignore_index = True)\n",
    "\n",
    "    region_and_number = file[:-4]\n",
    "    region_number = region_and_number[:2]\n",
    "    region = region_and_number[9:]\n",
    "    df = dfs[dfs['region'] == region_number]\n",
    "\n",
    "    percent_trainable = (len(df) / len(f)) * 100\n",
    "\n",
    "    print(\n",
    "        'region ' + str(region_number) + ' has ' + str(len(f)) + ' lines of data, ' +\n",
    "        str(len(df)) + ' or ' + str(percent_trainable) + '%'\n",
    "        ' of which are trainable with GlaThiDa thicknesses'    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa3b5f",
   "metadata": {
    "code_folding": [
     53,
     74,
     91,
     108,
     125,
     144,
     163,
     225,
     227,
     229,
     232,
     234,
     236,
     238,
     240,
     242,
     244,
     246
    ],
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load prethicktions\n",
    "tau_b = 10*5\n",
    "rho = 0.9167\n",
    "g = 9.81\n",
    "\n",
    "root_dir = 'zults/'\n",
    "RGI_predicted = pd.DataFrame()\n",
    "\n",
    "# read each prediction file and do stuff to it and append it to a table\n",
    "for file in os.listdir(root_dir):\n",
    "    if 'RGI_predicted' in file:\n",
    "        file_reader = pd.read_csv(root_dir + file)\n",
    "        \n",
    "        file_reader['volume'] = (\n",
    "            file_reader['avg predicted thickness'] / 1e3\n",
    "        ) * file_reader['Area']\n",
    "        \n",
    "        # have to turn something into a series and append it to the df to build it\n",
    "        sum_volume = sum(file_reader['volume'])\n",
    "        total_volume = pd.Series(sum_volume, name = 'total volume')\n",
    "        RGI_predicted = pd.concat([RGI_predicted, total_volume], ignore_index = True)\n",
    "        \n",
    "        # variance\n",
    "        file_reader['variance'] = file_reader['predicted thickness std dev'] **2 \n",
    "        variance = sum(file_reader['variance'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'total variance'\n",
    "        ] = np.sqrt(variance)/1e3\n",
    "\n",
    "        # mean thickness\n",
    "        thickness_mean = file_reader['avg predicted thickness'].mean()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'mean thickness (km)'\n",
    "        ] = thickness_mean/1e3\n",
    "        \n",
    "#         # max thickness\n",
    "#         thickness_max = file_reader['avg predicted thickness'].max()\n",
    "#         RGI_predicted.loc[\n",
    "#             RGI_predicted.index[-1], 'max model thickness (km)'\n",
    "#         ] = thickness_max/1e3\n",
    "        \n",
    "        # area * mean thickness\n",
    "        area = sum(file_reader['Area'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'vol (10**3 km**3)'\n",
    "        ] = (area * (thickness_mean/1e3))/1e3\n",
    "        \n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'area'\n",
    "        ] = area\n",
    "        \n",
    "        \n",
    "# #         df1 has no lmax, so deriving thickness will not work\n",
    "#         if 'df1' not in file:\n",
    "#             file_reader['derived h max'] = (\n",
    "#                 np.sqrt((2 * tau_b) / (rho * g)) * (file_reader['Lmax']/1e3)\n",
    "#             )\n",
    "\n",
    "#             file_reader['derived h avg'] = (\n",
    "#                 (2/3) * file_reader['derived h max']\n",
    "#             )\n",
    "            \n",
    "            \n",
    "#             derived_h_max_sum = sum(file_reader['derived h max'])\n",
    "#             RGI_predicted.loc[\n",
    "#                 RGI_predicted.index[-1], 'derived h max (m)'\n",
    "#             ] = derived_h_max_sum/1e3\n",
    "            \n",
    "            \n",
    "#             derived_h_avg_sum = sum(file_reader['derived h avg'])\n",
    "#             RGI_predicted.loc[\n",
    "#                 RGI_predicted.index[-1], 'derived h avg (m)'\n",
    "#             ] = derived_h_avg_sum/1e3\n",
    "            \n",
    "        if 'df1' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df1'\n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '16-8' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '16-8'\n",
    "            if '24-12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '24-12'\n",
    "        if 'df2' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df2'   \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '50-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-28'\n",
    "            if '64-48' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-48'\n",
    "        if 'df3' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df3'        \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '37-20' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '37-20'\n",
    "            if '59-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '59-28'\n",
    "        if 'df4' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df4'    \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "            if '47-21' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '47-21'\n",
    "                \n",
    "            if '64-36' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-36'\n",
    "        if 'df5' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df5'    \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "            if '50-25' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-25'\n",
    "                \n",
    "            if '64-42' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-42'\n",
    "        if 'df6' in file:\n",
    "            if 'df6_1' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_1'\n",
    "            \n",
    "            if 'df6_2' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_2'\n",
    "                \n",
    "            if 'df6_3' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_3'\n",
    "            \n",
    "            if 'df6_6' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_6'\n",
    "            \n",
    "            \n",
    "            if 'df6_7' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_7'\n",
    "                \n",
    "            if 'df6_8' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_8'\n",
    "                \n",
    "            if 'df6_9' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_9'\n",
    "                \n",
    "            if 'df6_10' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_10'\n",
    "                \n",
    "            if 'df6_11' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_11'\n",
    "                \n",
    "            if 'df6_13' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_13'\n",
    "            if 'df6_19' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_19'\n",
    "                \n",
    "                \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "#         if '0.1' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.100'\n",
    "#         if '0.01' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.010'\n",
    "#         if '0.001' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.001'\n",
    "            \n",
    "#         if '_20' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '20'\n",
    "#         if '_25' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '25'\n",
    "#         if '_50' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '50'\n",
    "#         if '_60' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '60'\n",
    "#         if '_15' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '15'\n",
    "#         if '_30' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '30'\n",
    "#         if '_40' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '40'\n",
    "#         if '_100' in file:\n",
    "#             RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '100'\n",
    "\n",
    "RGI_predicted = RGI_predicted.drop(0, axis=1)\n",
    "\n",
    "RGI_predicted = RGI_predicted[\n",
    "    (RGI_predicted['dataframe'].str.contains('df')) \n",
    "#     &\n",
    "#     (RGI_predicted['layer architecture'] == '24-12')\n",
    "#     &\n",
    "#     (RGI_predicted['learning rate'] == 0.010)\n",
    "#     &\n",
    "#     (RGI_predicted['epochs'] == 100)\n",
    "]\n",
    "\n",
    "RGI_predicted.sort_values([\n",
    "    'mean thickness (km)',\n",
    "#     'architecture',\n",
    "#     'learning rate',\n",
    "#     'dataframe'\n",
    "], ascending = True)\n",
    "\n",
    "RGI_predicted = RGI_predicted[\n",
    "    RGI_predicted['vol (10**3 km**3)'] < 300\n",
    "]\n",
    "RGI_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gl.data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b2c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a density plot of the most recent predictions made. Can easily be modified in a loop\n",
    "to show multiple random states and whatnot\n",
    "\"\"\"\n",
    "sns.set(rc={\"figure.figsize\":(15,10)})\n",
    "sns.kdeplot(x = test_labels, y = y.flatten(),fill = True)\n",
    "plt.plot((0,300),(0,300),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell computes the true average thickness of the glaciers in use\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pth = '/data/fast1/glacierml/T_models/'\n",
    "T_lab = pd.read_csv(pth + 'T.csv', low_memory = False)\n",
    "T_lab = T_lab[[\n",
    "    'GlaThiDa_ID',\n",
    "    'LAT',\n",
    "    'LON',\n",
    "    'AREA',\n",
    "    'MEAN_SLOPE',\n",
    "    'MEAN_THICKNESS'\n",
    "]]\n",
    "T_lab = T_lab.dropna()\n",
    "\n",
    "tru_thickness = np.sum(T_lab['MEAN_THICKNESS']) / len(T_lab['MEAN_THICKNESS'])\n",
    "tru_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43eda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c57d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
