{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3331c805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import glacierml as gl\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tensorflow.python.util import deprecation\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import geopy\n",
    "# display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "RS = range(0,25,1)\n",
    "\n",
    "\n",
    "# df = df[[\n",
    "#     'area_g',\n",
    "#     'Area'\n",
    "# ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2bf1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select dataset to analyze\n",
    "\n",
    "selected_dataset = 'df3'\n",
    "\n",
    "if selected_dataset == 'df1':\n",
    "    df1 = gl.data_loader(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'n'\n",
    "    )\n",
    "    module = 'sm1'\n",
    "    res = 'sr1'\n",
    "    dataset = df1\n",
    "    dataset.name = selected_dataset\n",
    "\n",
    "if selected_dataset == 'df2':\n",
    "    df2 = gl.data_loader(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm2'\n",
    "    res = 'sr2'\n",
    "    dataset = df2\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df3':\n",
    "    df3 = gl.data_loader(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 1\n",
    "    )\n",
    "    module = 'sm3'\n",
    "    res = 'sr3'\n",
    "    dataset = df3\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df4':\n",
    "    df4 = gl.data_loader(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 5\n",
    "    )\n",
    "    module = 'sm4'\n",
    "    res = 'sr4'\n",
    "    dataset = df4\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df5':\n",
    "    df5 = gl.data_loader(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    df5 = df5.drop('Zmed', axis = 1)\n",
    "    dataset = df5\n",
    "    dataset.name = selected_dataset\n",
    "    module = 'sm5'\n",
    "    res = 'sr5'\n",
    "\n",
    "if selected_dataset == 'df6':\n",
    "    df6 = gl.data_loader_6(\n",
    "        root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'r',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm6'\n",
    "    res = 'sr6'\n",
    "    reg = df6['region'].iloc[-1]\n",
    "    df6 = df6.drop('region', axis=1)\n",
    "    dataset = df6 \n",
    "    dataset.name = str('df6_' + str(reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9adbd921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 64.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer architecture</th>\n",
       "      <th>total parameters</th>\n",
       "      <th>trained parameters</th>\n",
       "      <th>total inputs</th>\n",
       "      <th>df</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>validation split</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test mae avg</th>\n",
       "      <th>train mae avg</th>\n",
       "      <th>test mae std dev</th>\n",
       "      <th>train mae std dev</th>\n",
       "      <th>test predicted thickness std dev</th>\n",
       "      <th>train predicted thickness std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>19.463733</td>\n",
       "      <td>19.896410</td>\n",
       "      <td>5.029094</td>\n",
       "      <td>5.228353</td>\n",
       "      <td>7.897105</td>\n",
       "      <td>7.488781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>21.449327</td>\n",
       "      <td>22.103206</td>\n",
       "      <td>5.661338</td>\n",
       "      <td>6.018559</td>\n",
       "      <td>9.576027</td>\n",
       "      <td>9.130507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.596666</td>\n",
       "      <td>12.073150</td>\n",
       "      <td>0.691563</td>\n",
       "      <td>0.323797</td>\n",
       "      <td>1.234832</td>\n",
       "      <td>0.970772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>14.213980</td>\n",
       "      <td>15.401209</td>\n",
       "      <td>5.538965</td>\n",
       "      <td>5.704451</td>\n",
       "      <td>8.227578</td>\n",
       "      <td>8.071252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>14.970777</td>\n",
       "      <td>15.724798</td>\n",
       "      <td>2.021286</td>\n",
       "      <td>1.423612</td>\n",
       "      <td>1.558298</td>\n",
       "      <td>1.612935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>13.127043</td>\n",
       "      <td>14.142470</td>\n",
       "      <td>0.761185</td>\n",
       "      <td>0.428691</td>\n",
       "      <td>1.324266</td>\n",
       "      <td>1.109345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>14.115947</td>\n",
       "      <td>14.337242</td>\n",
       "      <td>6.674276</td>\n",
       "      <td>7.208248</td>\n",
       "      <td>10.735122</td>\n",
       "      <td>10.185328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>14.529549</td>\n",
       "      <td>15.472571</td>\n",
       "      <td>1.641859</td>\n",
       "      <td>1.386993</td>\n",
       "      <td>2.750754</td>\n",
       "      <td>2.639422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.348887</td>\n",
       "      <td>12.209884</td>\n",
       "      <td>1.171828</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>2.449565</td>\n",
       "      <td>2.427974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.141325</td>\n",
       "      <td>11.826714</td>\n",
       "      <td>1.149623</td>\n",
       "      <td>0.772541</td>\n",
       "      <td>2.690788</td>\n",
       "      <td>2.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.713057</td>\n",
       "      <td>13.666648</td>\n",
       "      <td>0.412330</td>\n",
       "      <td>0.184352</td>\n",
       "      <td>0.928019</td>\n",
       "      <td>0.610194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>60</td>\n",
       "      <td>13.942514</td>\n",
       "      <td>15.105990</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.393150</td>\n",
       "      <td>1.122326</td>\n",
       "      <td>0.852249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.876809</td>\n",
       "      <td>13.676324</td>\n",
       "      <td>0.499423</td>\n",
       "      <td>0.186471</td>\n",
       "      <td>1.009025</td>\n",
       "      <td>0.556340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>60</td>\n",
       "      <td>14.133342</td>\n",
       "      <td>15.097299</td>\n",
       "      <td>0.702693</td>\n",
       "      <td>0.472330</td>\n",
       "      <td>1.039605</td>\n",
       "      <td>0.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.678840</td>\n",
       "      <td>11.814951</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>0.236358</td>\n",
       "      <td>1.425158</td>\n",
       "      <td>1.104785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.453192</td>\n",
       "      <td>11.874301</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.256469</td>\n",
       "      <td>1.486899</td>\n",
       "      <td>1.266358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.716009</td>\n",
       "      <td>11.522609</td>\n",
       "      <td>1.776575</td>\n",
       "      <td>1.466182</td>\n",
       "      <td>4.918716</td>\n",
       "      <td>4.703448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>37-20</td>\n",
       "      <td>1170</td>\n",
       "      <td>1151</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>13.101278</td>\n",
       "      <td>11.032169</td>\n",
       "      <td>1.672337</td>\n",
       "      <td>0.863926</td>\n",
       "      <td>3.492012</td>\n",
       "      <td>3.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.988815</td>\n",
       "      <td>13.206024</td>\n",
       "      <td>0.341372</td>\n",
       "      <td>0.158144</td>\n",
       "      <td>0.587072</td>\n",
       "      <td>0.467905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>13.574268</td>\n",
       "      <td>14.823096</td>\n",
       "      <td>0.445639</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>1.027318</td>\n",
       "      <td>0.763328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.883281</td>\n",
       "      <td>13.239868</td>\n",
       "      <td>0.390502</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.536676</td>\n",
       "      <td>0.436681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>13.594459</td>\n",
       "      <td>14.830141</td>\n",
       "      <td>0.438616</td>\n",
       "      <td>0.291943</td>\n",
       "      <td>1.447078</td>\n",
       "      <td>0.952919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.856161</td>\n",
       "      <td>11.781774</td>\n",
       "      <td>0.698291</td>\n",
       "      <td>0.312608</td>\n",
       "      <td>1.972343</td>\n",
       "      <td>1.717855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.775943</td>\n",
       "      <td>11.766212</td>\n",
       "      <td>0.859630</td>\n",
       "      <td>0.437721</td>\n",
       "      <td>2.059283</td>\n",
       "      <td>1.612831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.835482</td>\n",
       "      <td>11.223687</td>\n",
       "      <td>1.505681</td>\n",
       "      <td>1.160402</td>\n",
       "      <td>3.797046</td>\n",
       "      <td>3.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59-28</td>\n",
       "      <td>2318</td>\n",
       "      <td>2299</td>\n",
       "      <td>2304</td>\n",
       "      <td>df3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>12.598944</td>\n",
       "      <td>11.179820</td>\n",
       "      <td>1.556699</td>\n",
       "      <td>1.121669</td>\n",
       "      <td>4.057045</td>\n",
       "      <td>3.543431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer architecture  total parameters  trained parameters  total inputs  \\\n",
       "24               10-5               180                 161          2304   \n",
       "37               10-5               180                 161          2304   \n",
       "13               10-5               180                 161          2304   \n",
       "22               10-5               180                 161          2304   \n",
       "23               10-5               180                 161          2304   \n",
       "32               10-5               180                 161          2304   \n",
       "34               10-5               180                 161          2304   \n",
       "36               10-5               180                 161          2304   \n",
       "12               10-5               180                 161          2304   \n",
       "25               10-5               180                 161          2304   \n",
       "15              37-20              1170                1151          2304   \n",
       "21              37-20              1170                1151          2304   \n",
       "29              37-20              1170                1151          2304   \n",
       "35              37-20              1170                1151          2304   \n",
       "14              37-20              1170                1151          2304   \n",
       "26              37-20              1170                1151          2304   \n",
       "16              37-20              1170                1151          2304   \n",
       "31              37-20              1170                1151          2304   \n",
       "19              59-28              2318                2299          2304   \n",
       "20              59-28              2318                2299          2304   \n",
       "30              59-28              2318                2299          2304   \n",
       "33              59-28              2318                2299          2304   \n",
       "18              59-28              2318                2299          2304   \n",
       "28              59-28              2318                2299          2304   \n",
       "17              59-28              2318                2299          2304   \n",
       "27              59-28              2318                2299          2304   \n",
       "\n",
       "     df  dropout  learning rate  validation split  epochs  test mae avg  \\\n",
       "24  df3        1          0.001               0.2     100     19.463733   \n",
       "37  df3        0          0.001               0.2     100     21.449327   \n",
       "13  df3        1          0.010               0.2     100     12.596666   \n",
       "22  df3        1          0.010               0.2      25     14.213980   \n",
       "23  df3        1          0.010               0.2      20     14.970777   \n",
       "32  df3        0          0.010               0.2      25     13.127043   \n",
       "34  df3        0          0.010               0.2     100     14.115947   \n",
       "36  df3        0          0.010               0.2      20     14.529549   \n",
       "12  df3        1          0.100               0.2     100     12.348887   \n",
       "25  df3        0          0.100               0.2     100     12.141325   \n",
       "15  df3        1          0.001               0.2     100     12.713057   \n",
       "21  df3        1          0.001               0.2      60     13.942514   \n",
       "29  df3        0          0.001               0.2     100     12.876809   \n",
       "35  df3        0          0.001               0.2      60     14.133342   \n",
       "14  df3        1          0.010               0.2     100     12.678840   \n",
       "26  df3        0          0.010               0.2     100     12.453192   \n",
       "16  df3        1          0.100               0.2     100     12.716009   \n",
       "31  df3        0          0.100               0.2     100     13.101278   \n",
       "19  df3        1          0.001               0.2     100     12.988815   \n",
       "20  df3        1          0.001               0.2      50     13.574268   \n",
       "30  df3        0          0.001               0.2     100     12.883281   \n",
       "33  df3        0          0.001               0.2      50     13.594459   \n",
       "18  df3        1          0.010               0.2     100     12.856161   \n",
       "28  df3        0          0.010               0.2     100     12.775943   \n",
       "17  df3        1          0.100               0.2     100     12.835482   \n",
       "27  df3        0          0.100               0.2     100     12.598944   \n",
       "\n",
       "    train mae avg  test mae std dev  train mae std dev  \\\n",
       "24      19.896410          5.029094           5.228353   \n",
       "37      22.103206          5.661338           6.018559   \n",
       "13      12.073150          0.691563           0.323797   \n",
       "22      15.401209          5.538965           5.704451   \n",
       "23      15.724798          2.021286           1.423612   \n",
       "32      14.142470          0.761185           0.428691   \n",
       "34      14.337242          6.674276           7.208248   \n",
       "36      15.472571          1.641859           1.386993   \n",
       "12      12.209884          1.171828           0.735450   \n",
       "25      11.826714          1.149623           0.772541   \n",
       "15      13.666648          0.412330           0.184352   \n",
       "21      15.105990          0.704872           0.393150   \n",
       "29      13.676324          0.499423           0.186471   \n",
       "35      15.097299          0.702693           0.472330   \n",
       "14      11.814951          0.874424           0.236358   \n",
       "26      11.874301          0.712357           0.256469   \n",
       "16      11.522609          1.776575           1.466182   \n",
       "31      11.032169          1.672337           0.863926   \n",
       "19      13.206024          0.341372           0.158144   \n",
       "20      14.823096          0.445639           0.260568   \n",
       "30      13.239868          0.390502           0.163388   \n",
       "33      14.830141          0.438616           0.291943   \n",
       "18      11.781774          0.698291           0.312608   \n",
       "28      11.766212          0.859630           0.437721   \n",
       "17      11.223687          1.505681           1.160402   \n",
       "27      11.179820          1.556699           1.121669   \n",
       "\n",
       "    test predicted thickness std dev  train predicted thickness std dev  \n",
       "24                          7.897105                           7.488781  \n",
       "37                          9.576027                           9.130507  \n",
       "13                          1.234832                           0.970772  \n",
       "22                          8.227578                           8.071252  \n",
       "23                          1.558298                           1.612935  \n",
       "32                          1.324266                           1.109345  \n",
       "34                         10.735122                          10.185328  \n",
       "36                          2.750754                           2.639422  \n",
       "12                          2.449565                           2.427974  \n",
       "25                          2.690788                           2.075081  \n",
       "15                          0.928019                           0.610194  \n",
       "21                          1.122326                           0.852249  \n",
       "29                          1.009025                           0.556340  \n",
       "35                          1.039605                           0.696600  \n",
       "14                          1.425158                           1.104785  \n",
       "26                          1.486899                           1.266358  \n",
       "16                          4.918716                           4.703448  \n",
       "31                          3.492012                           3.000179  \n",
       "19                          0.587072                           0.467905  \n",
       "20                          1.027318                           0.763328  \n",
       "30                          0.536676                           0.436681  \n",
       "33                          1.447078                           0.952919  \n",
       "18                          1.972343                           1.717855  \n",
       "28                          2.059283                           1.612831  \n",
       "17                          3.797046                           3.833652  \n",
       "27                          4.057045                           3.543431  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdir = 'zults/'\n",
    "predictions = pd.DataFrame()\n",
    "deviations = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    if 'predictions' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        predictions = predictions.append(file_reader, ignore_index = True)\n",
    "    \n",
    "    if 'deviations' in file:\n",
    "        \n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        deviations = deviations.append(file_reader, ignore_index = True)\n",
    "        \n",
    "deviations = deviations.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "predictions = predictions.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "deviations['total parameters'] = deviations['total parameters'].astype(int)\n",
    "deviations['trained parameters'] = deviations['trained parameters'].astype(int)\n",
    "deviations['total inputs'] = deviations['total inputs'].astype(int)\n",
    "\n",
    "\n",
    "deviations = deviations[\n",
    "    (deviations['df'] == 'df3') \n",
    "#     &\n",
    "#     (deviations['layer architecture'] == '24-12')\n",
    "#     &\n",
    "#     (deviations['learning rate'] == 0.010)\n",
    "#     &\n",
    "#     (deviations['epochs'] != 100)\n",
    "\n",
    "]\n",
    "\n",
    "# deviations = deviations[deviations['epochs'] == ]\n",
    "\n",
    "deviations = deviations.sort_values(\n",
    "    [\n",
    "#         'test mae avg', \n",
    "#         'test predicted thickness std dev'\n",
    "        'layer architecture',\n",
    "        'learning rate'\n",
    "    ]\n",
    ")\n",
    "deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb87762",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select index from deviations table to inspect further\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-5\n",
      "0.001\n",
      "100\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-5_df3_1_dnn_MULTI_0.001_0.2_100_0\n",
      "saved_models/sm3/sm_10-5/df3_1_dnn_MULTI_0.001_0.2_100_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m model_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     44\u001b[0m     rootdir \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m     45\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mstr\u001b[39m(rs)\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_path)\n\u001b[0;32m---> 57\u001b[0m dnn_model[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m y \u001b[38;5;241m=\u001b[39m dnn_model[hhh]\u001b[38;5;241m.\u001b[39mpredict(features, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     61\u001b[0m fig,ax\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m    211\u001b[0m       loader_impl\u001b[38;5;241m.\u001b[39mparse_saved_model(filepath)\n\u001b[0;32m--> 212\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable) or SavedModel.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:138\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Recreate layers and metrics using the info stored in the metadata.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m keras_loader \u001b[38;5;241m=\u001b[39m KerasObjectLoader(metadata, object_graph_def)\n\u001b[0;32m--> 138\u001b[0m \u001b[43mkeras_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Generate a dictionary of all loaded nodes.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m nodes_to_load \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:374\u001b[0m, in \u001b[0;36mKerasObjectLoader.load_layers\u001b[0;34m(self, compile)\u001b[0m\n\u001b[1;32m    371\u001b[0m     metric_list\u001b[38;5;241m.\u001b[39mappend(node_metadata)\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_nodes[node_metadata\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_metadata \u001b[38;5;129;01min\u001b[39;00m metric_list:\n\u001b[1;32m    379\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/load.py:397\u001b[0m, in \u001b[0;36mKerasObjectLoader._load_layer\u001b[0;34m(self, node_id, identifier, metadata)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id, identifier, metadata):\n\u001b[1;32m    396\u001b[0m   \u001b[38;5;124;03m\"\"\"Load a single layer from a SavedUserObject proto.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m   metadata \u001b[38;5;241m=\u001b[39m \u001b[43mjson_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m   \u001b[38;5;66;03m# If node was already created\u001b[39;00m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py:69\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(json_string):\n\u001b[0;32m---> 69\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_decode_helper\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/prethicktor/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we load top rated model and look at predicted accuracies of each random state\n",
    "\"\"\"\n",
    "print('Please select index from deviations table to inspect further')\n",
    "\n",
    "selection = int(input())\n",
    "\n",
    "arch = deviations['layer architecture'].loc[selection]\n",
    "top_learning_rate = deviations['learning rate'].loc[selection]\n",
    "epochs = deviations['epochs'].loc[selection]\n",
    "dropout = deviations['dropout'].loc[selection]\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "dnn_model = {}\n",
    "rootdir = 'saved_models/' + module + '/sm_' + arch + '/'\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = gl.data_splitter(dataset)\n",
    "features = [train_features, test_features]\n",
    "features = pd.concat(features)\n",
    "labels = [train_labels, test_labels]\n",
    "labels = pd.concat(labels)\n",
    "for rs in tqdm(RS):\n",
    "    \n",
    "    model_name = (\n",
    "        str(arch) + \n",
    "        '_' + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )   \n",
    "    print(model_name)\n",
    "    \n",
    "    model_path = (\n",
    "        rootdir + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    print(model_path)\n",
    "    \n",
    "    dnn_model[model_name] = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    \n",
    "    y = dnn_model[hhh].predict(features, verbose = 0)\n",
    "    fig,ax=plt.subplots(1,1,figsize=(15,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    plt.plot(labels,y,'.')\n",
    "    plt.plot((0,400),(0,400),'-')\n",
    "    plt.xlabel('True Thickness (m)')\n",
    "    plt.ylabel('Model Thickness (m)')\n",
    "    ax.set_title('Random State ' +str(rs))\n",
    "    plt.xlim((0,400))\n",
    "    plt.ylim((0,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39873db2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig_dir = (\n",
    "    'figs/' + \n",
    "    module + \n",
    "    '/'   \n",
    ") \n",
    "isdir = os.path.isdir(fig_dir)\n",
    "if isdir == False:\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "print(fig_dir)\n",
    "rootdir = 'saved_results/' + res + '/sr_' + arch + '/'\n",
    "print(rootdir)\n",
    "dnn_history = {}\n",
    "for rs in RS: \n",
    "    \n",
    "    history_name = (\n",
    "        arch + \n",
    "        '_' +\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    model_name = (\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_history[model_name] = pd.read_csv(rootdir + model_name)\n",
    "\n",
    "    fig,ax=plt.subplots(1,1,figsize=(10,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    ax.set_title(history_name)\n",
    "    gl.plot_loss(dnn_history[model_name])\n",
    "    \n",
    "file_name = (\n",
    "    fig_dir +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) + '_' +\n",
    "    str(rs) + '_' +\n",
    "    '.eps'\n",
    ")\n",
    "\n",
    "print(file_name)\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71abc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccccombo_breaker()\n",
    "# past this point is under construction. \n",
    "# here be monsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa3b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tau_b = 10*5\n",
    "rho = 0.9167\n",
    "g = 9.81\n",
    "\n",
    "root_dir = 'zults/'\n",
    "RGI_predicted = pd.DataFrame(columns = [\n",
    "    'dataframe',\n",
    "    'architecture',\n",
    "    'learning rate',\n",
    "    'epochs'\n",
    "])\n",
    "\n",
    "# read each prediction file and do stuff to it and append it to a table\n",
    "for file in os.listdir(root_dir):\n",
    "    if 'RGI_predicted' in file:\n",
    "        file_reader = pd.read_csv(root_dir + file)\n",
    "        \n",
    "        file_reader['volume'] = (\n",
    "            file_reader['avg predicted thickness'] / 1e3\n",
    "        ) * file_reader['Area']\n",
    "        \n",
    "        # have to turn something into a series and append it to the df to build it\n",
    "        sum_volume = sum(file_reader['volume'])\n",
    "        total_volume = pd.Series(sum_volume, name = 'total volume')\n",
    "        RGI_predicted = pd.concat([RGI_predicted, total_volume], ignore_index = True)\n",
    "        \n",
    "        # RGI_predicted.loc[\n",
    "        #     RGI_predicted.index[-1], 'median predicted thickness'\n",
    "        # ] = sum_3\n",
    "        \n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'sum(thickness) * sum(area)'\n",
    "        ] = (sum(file_reader['avg predicted thickness']/1e3) * sum(file_reader['Area']))\n",
    "\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'sum (area * thickness)'\n",
    "        ] = sum_volume/1e3\n",
    "        \n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'volume mean'\n",
    "        ] = file_reader['volume'].mean()\n",
    "        \n",
    "        \n",
    "        # variance\n",
    "        file_reader['variance'] = file_reader['predicted thickness std dev'] **2 \n",
    "        variance = sum(file_reader['variance'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'total variance'\n",
    "        ] = np.sqrt(variance)/1e3\n",
    "\n",
    "        # mean thickness\n",
    "        thickness_mean = file_reader['avg predicted thickness'].mean()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'mean model thickness (km)'\n",
    "        ] = thickness_mean/1e3\n",
    "        \n",
    "        # median thickness\n",
    "        thickness_median = file_reader['avg predicted thickness'].median()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'median model thickness (km)'\n",
    "        ] = thickness_median/1e3\n",
    "        \n",
    "        # median distance from mean thickness\n",
    "        thickness_median = file_reader['avg predicted thickness'].median()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'median distance from mean'\n",
    "        ] = abs(thickness_mean - thickness_median)/1e3\n",
    "        \n",
    "        # max thickness\n",
    "        thickness_max = file_reader['avg predicted thickness'].max()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'max model thickness (km)'\n",
    "        ] = thickness_max/1e3\n",
    "        \n",
    "        # area * mean thickness\n",
    "        area = sum(file_reader['Area'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'calculated global volume 10*3 km*3'\n",
    "        ] = (area * (thickness_mean/1e3))/1e3\n",
    "        \n",
    "        # df1 has no lmax, so deriving thickness will not work\n",
    "        if 'df1' not in file:\n",
    "            file_reader['derived h max'] = (\n",
    "                np.sqrt((2 * tau_b) / (rho * g)) * (file_reader['Lmax']/1e3)\n",
    "            )\n",
    "\n",
    "            file_reader['derived h avg'] = (\n",
    "                (2/3) * file_reader['derived h max']\n",
    "            )\n",
    "            \n",
    "            \n",
    "            derived_h_max_sum = sum(file_reader['derived h max'])\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'derived h max (m)'\n",
    "            ] = derived_h_max_sum/1e3\n",
    "            \n",
    "            \n",
    "            derived_h_avg_sum = sum(file_reader['derived h avg'])\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'derived h avg (m)'\n",
    "            ] = derived_h_avg_sum/1e3\n",
    "            \n",
    "        if 'df1' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df1'\n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '16-8' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '16-8'\n",
    "            if '24-12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '24-12'\n",
    "        if 'df2' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df2'   \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '50-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-28'\n",
    "            if '64-48' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-48'\n",
    "        if 'df3' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df3'        \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '37-20' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '37-20'\n",
    "            if '59-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '59-28'\n",
    "        if 'df4' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df4'    \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '47-21' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '47-21'\n",
    "            if '64-36' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-36'\n",
    "                \n",
    "        if '0.1' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.100'\n",
    "        if '0.01' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.010'\n",
    "        if '0.001' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.001'\n",
    "            \n",
    "        if '_20' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '20'\n",
    "        if '_25' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '25'\n",
    "        if '_50' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '50'\n",
    "        if '_60' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '60'\n",
    "        if '_15' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '15'\n",
    "        if '_30' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '30'\n",
    "        if '_40' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '40'\n",
    "        if '_100' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '100'\n",
    "\n",
    "# RGI_predicted = RGI_predicted.drop(0, axis=1)\n",
    "RGI_predicted.sort_values([\n",
    "    # 'mean model thickness (km)',\n",
    "    'architecture',\n",
    "    'learning rate',\n",
    "    'dataframe'\n",
    "], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64048a-d27c-4ca5-8867-deb8bad61432",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = len(dataset.columns) -1\n",
    "total_inputs = (len(dataset) * (len(dataset.columns) -1))\n",
    "print('total inputs = ' + str(total_inputs))\n",
    "\n",
    "non_trainable_parameters = (len(dataset.columns)) + ((len(dataset.columns) - 1))\n",
    "print('non-trainable parameters = ' + str(non_trainable_parameters))\n",
    "\n",
    "layer_1 = 10\n",
    "layer_2 = 5\n",
    "\n",
    "total_parameters = (inputs * (layer_1+1)) + ((layer_1 + 1)* (layer_2 + 1)) + (layer_2 + 1)\n",
    "total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90316d27-67fb-4437-878f-cd03b8e7c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9393e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This cell contains code to produce histograms of all the architectures different histories\n",
    "# \"\"\"\n",
    "\n",
    "# for i in deviations.index:\n",
    "# #     print(i)\n",
    "#     df = deviations.iloc[i]\n",
    "#     arch = df['layer architecture']\n",
    "#     top_learn_rate = df['learning rate']\n",
    "#     epochs = df['epochs']\n",
    "\n",
    "#     dfs = predictions[\n",
    "#         (predictions['architecture'] == arch) &\n",
    "#         (predictions['learning rate'] == top_learn_rate) &\n",
    "#         (predictions['epochs'] == epochs)\n",
    "#     ]\n",
    "#     fig,ax = plt.subplots()\n",
    "#     ax.set_title('df:' + str(i) + ' Layer architecture: ' + arch )\n",
    "#     ax.set_ylabel('prediction count')\n",
    "#     ax.set_xlabel('thickness (m)')\n",
    "#     fig.patch.set_facecolor('w')\n",
    "#     plt.hist(dfs['avg test thickness'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254e29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('loading RGI...')\n",
    "rootdir = '/data/fast0/datasets/rgi60-attribs/'\n",
    "RGI_extra = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    f = pd.read_csv(rootdir+file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    RGI_extra = RGI_extra.append(f, ignore_index = True)\n",
    "    \n",
    "\n",
    "RGI = RGI_extra[[\n",
    "    'RGIId',\n",
    "    'CenLat',\n",
    "    'CenLon',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmed',\n",
    "    'Zmax',\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax'\n",
    "]]\n",
    "\n",
    "df1 = RGI_predicted_df1\n",
    "(sum((df1['area'] * df1['avg predicted thickness']) * 10**6) / 10**9)\n",
    "\n",
    "\n",
    "AIC = deviations_df1['model parameters'] - deviations_df1['test mae avg']\n",
    "\n",
    "AIC.sort_values()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.plot(\n",
    "    deviations_df1['test predicted thickness std dev'], \n",
    "    deviations_df1['test mae avg'],\n",
    "    '.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b2c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a density plot of the most recent predictions made. Can easily be modified in a loop\n",
    "to show multiple random states and whatnot\n",
    "\"\"\"\n",
    "sns.set(rc={\"figure.figsize\":(15,10)})\n",
    "sns.kdeplot(x = test_labels, y = y.flatten(),fill = True)\n",
    "plt.plot((0,300),(0,300),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell computes the true average thickness of the glaciers in use\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pth = '/data/fast1/glacierml/T_models/'\n",
    "T_lab = pd.read_csv(pth + 'T.csv', low_memory = False)\n",
    "T_lab = T_lab[[\n",
    "    'GlaThiDa_ID',\n",
    "    'LAT',\n",
    "    'LON',\n",
    "    'AREA',\n",
    "    'MEAN_SLOPE',\n",
    "    'MEAN_THICKNESS'\n",
    "]]\n",
    "T_lab = T_lab.dropna()\n",
    "\n",
    "tru_thickness = np.sum(T_lab['MEAN_THICKNESS']) / len(T_lab['MEAN_THICKNESS'])\n",
    "tru_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43eda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
