{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3331c805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import glacierml as gl\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tensorflow.python.util import deprecation\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import geopy\n",
    "# display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "RS = range(0,25,1)\n",
    "\n",
    "\n",
    "# df = df[[\n",
    "#     'area_g',\n",
    "#     'Area'\n",
    "# ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2bf1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select dataset to analyze\n",
    "\n",
    "selected_dataset = 'df2'\n",
    "\n",
    "\n",
    "if selected_dataset == 'df1':\n",
    "    df1 = gl.data_loader(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'n'\n",
    "    )\n",
    "    module = 'sm1'\n",
    "    res = 'sr1'\n",
    "    dataset = df1\n",
    "    dataset.name = selected_dataset\n",
    "\n",
    "if selected_dataset == 'df2':\n",
    "    df2 = gl.data_loader(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm2'\n",
    "    res = 'sr2'\n",
    "    dataset = df2\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df3':\n",
    "    df3 = gl.data_loader(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 1\n",
    "    )\n",
    "    module = 'sm3'\n",
    "    res = 'sr3'\n",
    "    dataset = df3\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df4':\n",
    "    df4 = gl.data_loader(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 5\n",
    "    )\n",
    "    module = 'sm4'\n",
    "    res = 'sr4'\n",
    "    dataset = df4\n",
    "    dataset.name = selected_dataset\n",
    "    \n",
    "if selected_dataset == 'df5':\n",
    "    df5 = gl.data_loader(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'r',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm5'\n",
    "    res = 'sr5'\n",
    "    reg = df5['region'].iloc[-1]\n",
    "    df5 = df5.drop('region', axis=1)\n",
    "    dataset = df5\n",
    "    dataset.name = str('df5_' + str(reg))\n",
    "\n",
    "if selected_dataset == 'df6':\n",
    "    df6 = gl.data_loader_6(\n",
    "        # pth_1 = '/home/simonhans/data/prethicktor/T_data/',\n",
    "        # pth_2 = '/home/simonhans/data/prethicktor/RGI/rgi60-attribs/',\n",
    "        # pth_3 = '/home/simonhans/data/prethicktor/matched_indexes/',\n",
    "        # pth_4 = '/home/simonhans/data/prethicktor/regional_data/training_data/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'r',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm6'\n",
    "    res = 'sr6'\n",
    "    reg = df6['region'].iloc[-1]\n",
    "    df6 = df6.drop('region', axis=1)\n",
    "    dataset = df6 \n",
    "    dataset.name = str('df6_' + str(reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9adbd921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1653.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer architecture</th>\n",
       "      <th>total parameters</th>\n",
       "      <th>trained parameters</th>\n",
       "      <th>total inputs</th>\n",
       "      <th>df</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>validation split</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test mae avg</th>\n",
       "      <th>train mae avg</th>\n",
       "      <th>test mae std dev</th>\n",
       "      <th>train mae std dev</th>\n",
       "      <th>test predicted thickness std dev</th>\n",
       "      <th>train predicted thickness std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>33.708867</td>\n",
       "      <td>28.946621</td>\n",
       "      <td>7.315369</td>\n",
       "      <td>7.274568</td>\n",
       "      <td>10.355960</td>\n",
       "      <td>10.696787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>33.080288</td>\n",
       "      <td>28.433623</td>\n",
       "      <td>2.241167</td>\n",
       "      <td>2.065054</td>\n",
       "      <td>2.911484</td>\n",
       "      <td>3.326176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.465352</td>\n",
       "      <td>21.216063</td>\n",
       "      <td>0.547645</td>\n",
       "      <td>0.346056</td>\n",
       "      <td>0.656038</td>\n",
       "      <td>0.644445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.498946</td>\n",
       "      <td>21.287111</td>\n",
       "      <td>0.697538</td>\n",
       "      <td>0.343267</td>\n",
       "      <td>0.954383</td>\n",
       "      <td>1.117548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.186652</td>\n",
       "      <td>21.048274</td>\n",
       "      <td>2.767640</td>\n",
       "      <td>2.805026</td>\n",
       "      <td>4.646422</td>\n",
       "      <td>5.144084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>30.053667</td>\n",
       "      <td>22.517166</td>\n",
       "      <td>3.229234</td>\n",
       "      <td>3.306296</td>\n",
       "      <td>5.619617</td>\n",
       "      <td>6.280653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.428805</td>\n",
       "      <td>20.532520</td>\n",
       "      <td>1.196918</td>\n",
       "      <td>1.084505</td>\n",
       "      <td>3.831624</td>\n",
       "      <td>4.151211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>28.902645</td>\n",
       "      <td>22.339623</td>\n",
       "      <td>3.454076</td>\n",
       "      <td>3.414215</td>\n",
       "      <td>5.655355</td>\n",
       "      <td>6.578225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.915888</td>\n",
       "      <td>22.607363</td>\n",
       "      <td>0.373358</td>\n",
       "      <td>0.180296</td>\n",
       "      <td>0.579332</td>\n",
       "      <td>0.436626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.855653</td>\n",
       "      <td>22.634018</td>\n",
       "      <td>0.298559</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>0.460799</td>\n",
       "      <td>0.377349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.466164</td>\n",
       "      <td>19.944484</td>\n",
       "      <td>0.887194</td>\n",
       "      <td>0.512407</td>\n",
       "      <td>2.035047</td>\n",
       "      <td>2.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.642390</td>\n",
       "      <td>20.116601</td>\n",
       "      <td>0.946821</td>\n",
       "      <td>0.527895</td>\n",
       "      <td>2.188003</td>\n",
       "      <td>2.154898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.036429</td>\n",
       "      <td>17.598920</td>\n",
       "      <td>1.959888</td>\n",
       "      <td>1.237259</td>\n",
       "      <td>5.330947</td>\n",
       "      <td>5.211396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>30.067681</td>\n",
       "      <td>22.205002</td>\n",
       "      <td>2.011223</td>\n",
       "      <td>1.589722</td>\n",
       "      <td>5.732232</td>\n",
       "      <td>6.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.930323</td>\n",
       "      <td>17.815458</td>\n",
       "      <td>1.758347</td>\n",
       "      <td>1.533301</td>\n",
       "      <td>5.272952</td>\n",
       "      <td>5.523705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>29.162731</td>\n",
       "      <td>22.367485</td>\n",
       "      <td>2.517031</td>\n",
       "      <td>2.121965</td>\n",
       "      <td>7.552489</td>\n",
       "      <td>7.847710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.793043</td>\n",
       "      <td>22.143649</td>\n",
       "      <td>0.304285</td>\n",
       "      <td>0.117507</td>\n",
       "      <td>0.607531</td>\n",
       "      <td>0.471396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.779113</td>\n",
       "      <td>22.117119</td>\n",
       "      <td>0.254514</td>\n",
       "      <td>0.132706</td>\n",
       "      <td>0.425619</td>\n",
       "      <td>0.403463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>26.970608</td>\n",
       "      <td>19.739647</td>\n",
       "      <td>0.814670</td>\n",
       "      <td>0.502382</td>\n",
       "      <td>2.147713</td>\n",
       "      <td>2.355644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>28.255510</td>\n",
       "      <td>21.230657</td>\n",
       "      <td>0.968974</td>\n",
       "      <td>0.248895</td>\n",
       "      <td>1.529182</td>\n",
       "      <td>1.694263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.481571</td>\n",
       "      <td>19.670500</td>\n",
       "      <td>0.710250</td>\n",
       "      <td>0.558147</td>\n",
       "      <td>2.496856</td>\n",
       "      <td>2.596855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>28.257741</td>\n",
       "      <td>21.316389</td>\n",
       "      <td>0.931476</td>\n",
       "      <td>0.302427</td>\n",
       "      <td>1.737502</td>\n",
       "      <td>1.919714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>27.842596</td>\n",
       "      <td>17.169107</td>\n",
       "      <td>1.441292</td>\n",
       "      <td>0.932547</td>\n",
       "      <td>4.467426</td>\n",
       "      <td>5.026119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>28.255742</td>\n",
       "      <td>17.680918</td>\n",
       "      <td>1.703902</td>\n",
       "      <td>1.843259</td>\n",
       "      <td>6.265198</td>\n",
       "      <td>5.953822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer architecture  total parameters  trained parameters  total inputs  \\\n",
       "73               10-5               180                 161          3834   \n",
       "85               10-5               180                 161          3834   \n",
       "68               10-5               180                 161          3834   \n",
       "80               10-5               180                 161          3834   \n",
       "66               10-5               180                 161          3834   \n",
       "71               10-5               180                 161          3834   \n",
       "74               10-5               180                 161          3834   \n",
       "83               10-5               180                 161          3834   \n",
       "70              50-28              1976                1957          3834   \n",
       "82              50-28              1976                1957          3834   \n",
       "63              50-28              1976                1957          3834   \n",
       "76              50-28              1976                1957          3834   \n",
       "65              50-28              1976                1957          3834   \n",
       "72              50-28              1976                1957          3834   \n",
       "77              50-28              1976                1957          3834   \n",
       "84              50-28              1976                1957          3834   \n",
       "69              64-48              3828                3809          3834   \n",
       "81              64-48              3828                3809          3834   \n",
       "62              64-48              3828                3809          3834   \n",
       "67              64-48              3828                3809          3834   \n",
       "75              64-48              3828                3809          3834   \n",
       "79              64-48              3828                3809          3834   \n",
       "64              64-48              3828                3809          3834   \n",
       "78              64-48              3828                3809          3834   \n",
       "\n",
       "     df  dropout  learning rate  validation split  epochs  test mae avg  \\\n",
       "73  df2        1          0.001               0.2     100     33.708867   \n",
       "85  df2        0          0.001               0.2     100     33.080288   \n",
       "68  df2        1          0.010               0.2     100     28.465352   \n",
       "80  df2        0          0.010               0.2     100     28.498946   \n",
       "66  df2        1          0.100               0.2     100     28.186652   \n",
       "71  df2        1          0.100               0.2      40     30.053667   \n",
       "74  df2        0          0.100               0.2     100     27.428805   \n",
       "83  df2        0          0.100               0.2      40     28.902645   \n",
       "70  df2        1          0.001               0.2     100     28.915888   \n",
       "82  df2        0          0.001               0.2     100     28.855653   \n",
       "63  df2        1          0.010               0.2     100     27.466164   \n",
       "76  df2        0          0.010               0.2     100     27.642390   \n",
       "65  df2        1          0.100               0.2     100     28.036429   \n",
       "72  df2        1          0.100               0.2      40     30.067681   \n",
       "77  df2        0          0.100               0.2     100     27.930323   \n",
       "84  df2        0          0.100               0.2      40     29.162731   \n",
       "69  df2        1          0.001               0.2     100     28.793043   \n",
       "81  df2        0          0.001               0.2     100     28.779113   \n",
       "62  df2        1          0.010               0.2     100     26.970608   \n",
       "67  df2        1          0.010               0.2      40     28.255510   \n",
       "75  df2        0          0.010               0.2     100     27.481571   \n",
       "79  df2        0          0.010               0.2      40     28.257741   \n",
       "64  df2        1          0.100               0.2     100     27.842596   \n",
       "78  df2        0          0.100               0.2     100     28.255742   \n",
       "\n",
       "    train mae avg  test mae std dev  train mae std dev  \\\n",
       "73      28.946621          7.315369           7.274568   \n",
       "85      28.433623          2.241167           2.065054   \n",
       "68      21.216063          0.547645           0.346056   \n",
       "80      21.287111          0.697538           0.343267   \n",
       "66      21.048274          2.767640           2.805026   \n",
       "71      22.517166          3.229234           3.306296   \n",
       "74      20.532520          1.196918           1.084505   \n",
       "83      22.339623          3.454076           3.414215   \n",
       "70      22.607363          0.373358           0.180296   \n",
       "82      22.634018          0.298559           0.193317   \n",
       "63      19.944484          0.887194           0.512407   \n",
       "76      20.116601          0.946821           0.527895   \n",
       "65      17.598920          1.959888           1.237259   \n",
       "72      22.205002          2.011223           1.589722   \n",
       "77      17.815458          1.758347           1.533301   \n",
       "84      22.367485          2.517031           2.121965   \n",
       "69      22.143649          0.304285           0.117507   \n",
       "81      22.117119          0.254514           0.132706   \n",
       "62      19.739647          0.814670           0.502382   \n",
       "67      21.230657          0.968974           0.248895   \n",
       "75      19.670500          0.710250           0.558147   \n",
       "79      21.316389          0.931476           0.302427   \n",
       "64      17.169107          1.441292           0.932547   \n",
       "78      17.680918          1.703902           1.843259   \n",
       "\n",
       "    test predicted thickness std dev  train predicted thickness std dev  \n",
       "73                         10.355960                          10.696787  \n",
       "85                          2.911484                           3.326176  \n",
       "68                          0.656038                           0.644445  \n",
       "80                          0.954383                           1.117548  \n",
       "66                          4.646422                           5.144084  \n",
       "71                          5.619617                           6.280653  \n",
       "74                          3.831624                           4.151211  \n",
       "83                          5.655355                           6.578225  \n",
       "70                          0.579332                           0.436626  \n",
       "82                          0.460799                           0.377349  \n",
       "63                          2.035047                           2.028302  \n",
       "76                          2.188003                           2.154898  \n",
       "65                          5.330947                           5.211396  \n",
       "72                          5.732232                           6.325581  \n",
       "77                          5.272952                           5.523705  \n",
       "84                          7.552489                           7.847710  \n",
       "69                          0.607531                           0.471396  \n",
       "81                          0.425619                           0.403463  \n",
       "62                          2.147713                           2.355644  \n",
       "67                          1.529182                           1.694263  \n",
       "75                          2.496856                           2.596855  \n",
       "79                          1.737502                           1.919714  \n",
       "64                          4.467426                           5.026119  \n",
       "78                          6.265198                           5.953822  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdir = 'zults/'\n",
    "predictions = pd.DataFrame()\n",
    "deviations = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    if 'predictions' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        predictions = predictions.append(file_reader, ignore_index = True)\n",
    "    \n",
    "    if 'deviations' in file:\n",
    "        \n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        deviations = deviations.append(file_reader, ignore_index = True)\n",
    "        \n",
    "deviations = deviations.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "predictions = predictions.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "deviations['total parameters'] = deviations['total parameters'].astype(int)\n",
    "deviations['trained parameters'] = deviations['trained parameters'].astype(int)\n",
    "deviations['total inputs'] = deviations['total inputs'].astype(int)\n",
    "\n",
    "\n",
    "deviations = deviations[\n",
    "    (deviations['df'] == 'df2') \n",
    "#     &\n",
    "#     (deviations['layer architecture'] == '24-12')\n",
    "#     &\n",
    "#     (deviations['learning rate'] == 0.010)\n",
    "#     &\n",
    "#     (deviations['epochs'] != 100)\n",
    "\n",
    "]\n",
    "\n",
    "# deviations = deviations[deviations['epochs'] == ]\n",
    "\n",
    "deviations = deviations.sort_values(\n",
    "    [\n",
    "#         'test mae avg', \n",
    "#         'test predicted thickness std dev'\n",
    "        'layer architecture',\n",
    "        'learning rate'\n",
    "    ]\n",
    ")\n",
    "deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb87762",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select index from deviations table to inspect further\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we load top rated model and look at predicted accuracies of each random state\n",
    "\"\"\"\n",
    "print('Please select index from deviations table to inspect further')\n",
    "\n",
    "selection = int(input())\n",
    "\n",
    "arch = deviations['layer architecture'].loc[selection]\n",
    "top_learning_rate = deviations['learning rate'].loc[selection]\n",
    "epochs = deviations['epochs'].loc[selection]\n",
    "dropout = deviations['dropout'].loc[selection]\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "dnn_model = {}\n",
    "rootdir = 'saved_models/' + module + '/sm_' + arch + '/'\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = gl.data_splitter(dataset)\n",
    "features = [train_features, test_features]\n",
    "features = pd.concat(features)\n",
    "labels = [train_labels, test_labels]\n",
    "labels = pd.concat(labels)\n",
    "for rs in tqdm(RS):\n",
    "    \n",
    "    hhh = (\n",
    "        str(arch) + \n",
    "        '_' + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )   \n",
    "    \n",
    "    dnn_model[hhh] = tf.keras.models.load_model(\n",
    "        rootdir + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    y = dnn_model[hhh].predict(features, verbose = 0)\n",
    "    fig,ax=plt.subplots(1,1,figsize=(15,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    plt.plot(labels,y,'.')\n",
    "    plt.plot((0,400),(0,400),'-')\n",
    "    plt.xlabel('True Thickness (m)')\n",
    "    plt.ylabel('Model Thickness (m)')\n",
    "    ax.set_title('Random State ' +str(rs))\n",
    "    plt.xlim((0,400))\n",
    "    plt.ylim((0,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39873db2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig_dir = (\n",
    "    'figs/' + \n",
    "    module + \n",
    "    '/'   \n",
    ") \n",
    "isdir = os.path.isdir(fig_dir)\n",
    "if isdir == False:\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "print(fig_dir)\n",
    "rootdir = 'saved_results/' + res + '/sr_' + arch + '/'\n",
    "print(rootdir)\n",
    "dnn_history = {}\n",
    "for rs in RS: \n",
    "    \n",
    "    history_name = (\n",
    "        arch + \n",
    "        '_' +\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    model_name = (\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_history[model_name] = pd.read_csv(rootdir + model_name)\n",
    "\n",
    "    fig,ax=plt.subplots(1,1,figsize=(10,10))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    ax.set_title(history_name)\n",
    "    gl.plot_loss(dnn_history[model_name])\n",
    "    \n",
    "file_name = (\n",
    "    fig_dir +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) + '_' +\n",
    "    str(rs) + '_' +\n",
    "    '.eps'\n",
    ")\n",
    "\n",
    "print(file_name)\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71abc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccccombo_breaker()\n",
    "# past this point is under construction. \n",
    "# here be monsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aa3b5f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9.81\u001b[39m\n\u001b[1;32m      5\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzults/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m RGI_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning rate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# read each prediction file and do stuff to it and append it to a table\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(root_dir):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tau_b = 10*5\n",
    "rho = 0.9167\n",
    "g = 9.81\n",
    "\n",
    "root_dir = 'zults/'\n",
    "RGI_predicted = pd.DataFrame(columns = [\n",
    "    'dataframe',\n",
    "    'architecture',\n",
    "    'learning rate',\n",
    "    'epochs'\n",
    "])\n",
    "\n",
    "# read each prediction file and do stuff to it and append it to a table\n",
    "for file in os.listdir(root_dir):\n",
    "    if 'RGI_predicted' in file:\n",
    "        file_reader = pd.read_csv(root_dir + file)\n",
    "#         print(file)\n",
    "        \n",
    "        # volume = area * predicted mean thickness\n",
    "        file_reader['volume'] = (\n",
    "            file_reader['avg predicted thickness'] / 10**3\n",
    "        ) * file_reader['Area']\n",
    "\n",
    "        # have to turn something into a series and append it to the df to build it\n",
    "        sum_volume = sum(file_reader['volume'])\n",
    "        total_volume = pd.Series(sum_volume, name = 'total volume')\n",
    "        RGI_predicted = RGI_predicted.append(total_volume, ignore_index = True)\n",
    "\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'sum predicted volume (km*3)'\n",
    "        ] = sum_volume/1e3\n",
    "        \n",
    "        # variance\n",
    "        file_reader['variance'] = file_reader['predicted thickness std dev'] **2 \n",
    "        variance = sum(file_reader['variance'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'total variance'\n",
    "        ] = np.sqrt(variance)/1e3\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # mean thickness\n",
    "        thickness_mean = file_reader['avg predicted thickness'].mean()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'mean model thickness (km)'\n",
    "        ] = thickness_mean/1e3\n",
    "        \n",
    "        # max thickness\n",
    "        thickness_max = file_reader['avg predicted thickness'].max()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'max model thickness (km)'\n",
    "        ] = thickness_max/1e3\n",
    "        \n",
    "        # area * mean thickness\n",
    "        \n",
    "        area = sum(file_reader['Area'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'calculated global volume 10*3 km*3'\n",
    "        ] = (area * (thickness_mean/1e3))/1e3\n",
    "        \n",
    "        \n",
    "        # df1 has no lmax, so deriving thickness will not work\n",
    "        if 'df1' not in file:\n",
    "            file_reader['derived h max'] = (\n",
    "                np.sqrt((2 * tau_b) / (rho * g)) * (file_reader['Lmax']/1e3)\n",
    "            )\n",
    "\n",
    "            file_reader['derived h avg'] = (\n",
    "                (2/3) * file_reader['derived h max']\n",
    "            )\n",
    "            \n",
    "            \n",
    "            derived_h_max_sum = sum(file_reader['derived h max'])\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'derived h max (m)'\n",
    "            ] = derived_h_max_sum/1e3\n",
    "            \n",
    "            \n",
    "            derived_h_avg_sum = sum(file_reader['derived h avg'])\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'derived h avg (m)'\n",
    "            ] = derived_h_avg_sum/1e3\n",
    "            \n",
    "        if 'df1' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df1'\n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '16-8' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '16-8'\n",
    "            if '24-12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '24-12'\n",
    "        if 'df2' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df2'   \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '50-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '37-20'\n",
    "            if '64-48' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '24-12'\n",
    "        if 'df3' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df3'        \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '37-20' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '37-20'\n",
    "            if '59-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '59-28'\n",
    "        if 'df4' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df4'    \n",
    "            \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '47-21' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '47-21'\n",
    "            if '64-36' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-36'\n",
    "                \n",
    "        if '0.1' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.100'\n",
    "        if '0.01' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.010'\n",
    "        if '0.001' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.001'\n",
    "            \n",
    "        if '20' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '20'\n",
    "        if '25' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '25'\n",
    "        if '50' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '50'\n",
    "        if '60' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '60'\n",
    "        if '15' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '15'\n",
    "        if '30' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '30'\n",
    "        if '40' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '40'\n",
    "        if '100' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '100'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "RGI_predicted = RGI_predicted.drop(0, axis=1)\n",
    "RGI_predicted.sort_values('mean model thickness (km)', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9393e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This cell contains code to produce histograms of all the architectures different histories\n",
    "# \"\"\"\n",
    "\n",
    "# for i in deviations.index:\n",
    "# #     print(i)\n",
    "#     df = deviations.iloc[i]\n",
    "#     arch = df['layer architecture']\n",
    "#     top_learn_rate = df['learning rate']\n",
    "#     epochs = df['epochs']\n",
    "\n",
    "#     dfs = predictions[\n",
    "#         (predictions['architecture'] == arch) &\n",
    "#         (predictions['learning rate'] == top_learn_rate) &\n",
    "#         (predictions['epochs'] == epochs)\n",
    "#     ]\n",
    "#     fig,ax = plt.subplots()\n",
    "#     ax.set_title('df:' + str(i) + ' Layer architecture: ' + arch )\n",
    "#     ax.set_ylabel('prediction count')\n",
    "#     ax.set_xlabel('thickness (m)')\n",
    "#     fig.patch.set_facecolor('w')\n",
    "#     plt.hist(dfs['avg test thickness'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254e29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('loading RGI...')\n",
    "rootdir = '/data/fast0/datasets/rgi60-attribs/'\n",
    "RGI_extra = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    f = pd.read_csv(rootdir+file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    RGI_extra = RGI_extra.append(f, ignore_index = True)\n",
    "    \n",
    "\n",
    "RGI = RGI_extra[[\n",
    "    'RGIId',\n",
    "    'CenLat',\n",
    "    'CenLon',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmed',\n",
    "    'Zmax',\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax'\n",
    "]]\n",
    "\n",
    "df1 = RGI_predicted_df1\n",
    "(sum((df1['area'] * df1['avg predicted thickness']) * 10**6) / 10**9)\n",
    "\n",
    "\n",
    "AIC = deviations_df1['model parameters'] - deviations_df1['test mae avg']\n",
    "\n",
    "AIC.sort_values()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.plot(\n",
    "    deviations_df1['test predicted thickness std dev'], \n",
    "    deviations_df1['test mae avg'],\n",
    "    '.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b2c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a density plot of the most recent predictions made. Can easily be modified in a loop\n",
    "to show multiple random states and whatnot\n",
    "\"\"\"\n",
    "sns.set(rc={\"figure.figsize\":(15,10)})\n",
    "sns.kdeplot(x = test_labels, y = y.flatten(),fill = True)\n",
    "plt.plot((0,300),(0,300),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell computes the true average thickness of the glaciers in use\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pth = '/data/fast1/glacierml/T_models/'\n",
    "T_lab = pd.read_csv(pth + 'T.csv', low_memory = False)\n",
    "T_lab = T_lab[[\n",
    "    'GlaThiDa_ID',\n",
    "    'LAT',\n",
    "    'LON',\n",
    "    'AREA',\n",
    "    'MEAN_SLOPE',\n",
    "    'MEAN_THICKNESS'\n",
    "]]\n",
    "T_lab = T_lab.dropna()\n",
    "\n",
    "tru_thickness = np.sum(T_lab['MEAN_THICKNESS']) / len(T_lab['MEAN_THICKNESS'])\n",
    "tru_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43eda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
