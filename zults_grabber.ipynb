{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37428ee",
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import glacierml as gl\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tensorflow.python.util import deprecation\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import geopy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "RS = range(0,25,1)\n",
    "\n",
    "print('currently running tensorflow version: ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444ea44",
   "metadata": {},
   "source": [
    "# ML Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736d479e",
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select dataset to analyze\n",
    "\n",
    "selected_dataset = 'df8'\n",
    "\n",
    "if selected_dataset == 'df1':\n",
    "    df1 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'n'\n",
    "    )\n",
    "    module = 'sm1'\n",
    "    res = 'sr1'\n",
    "    dataset = df1\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df2':\n",
    "    df2 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm2'\n",
    "    res = 'sr2'\n",
    "    dataset = df2\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df3':\n",
    "    df3 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 1\n",
    "    )\n",
    "    module = 'sm3'\n",
    "    res = 'sr3'\n",
    "    dataset = df3\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df4':\n",
    "    df4 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'on',\n",
    "        anomaly_input = 5\n",
    "    )\n",
    "    module = 'sm4'\n",
    "    res = 'sr4'\n",
    "    dataset = df4\n",
    "    dataset.name = selected_dataset\n",
    "if selected_dataset == 'df5':\n",
    "    df5 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'g',\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    df5 = df5.drop('Zmed', axis = 1)\n",
    "    dataset = df5\n",
    "    dataset.name = selected_dataset\n",
    "    module = 'sm5'\n",
    "    res = 'sr5'\n",
    "if selected_dataset == 'df6':\n",
    "    df6 = gl.data_loader(\n",
    "#         root_dir = '/home/simonhans/data/prethicktor/',\n",
    "        RGI_input = 'y',\n",
    "        scale = 'r',\n",
    "        region_selection = 1,\n",
    "        area_scrubber = 'off'\n",
    "    )\n",
    "    module = 'sm6'\n",
    "    res = 'sr6'\n",
    "    reg = df6['region'].iloc[-1]\n",
    "    df6 = df6.drop('region', axis=1)\n",
    "    dataset = df6 \n",
    "    dataset.name = str('df6_' + str(reg))\n",
    "if selected_dataset == 'df7':\n",
    "    df7 = gl.data_loader()\n",
    "    module = 'sm7'\n",
    "    res = 'sr7'\n",
    "    dataset = df7 \n",
    "    dataset.name = 'df7'\n",
    "    \n",
    "if selected_dataset == 'df8':\n",
    "    df8 = gl.data_loader()\n",
    "    df8 = df8.drop('Zmed', axis = 1)\n",
    "    module = 'sm8'\n",
    "    res = 'sr8'\n",
    "    dataset = df8 \n",
    "    dataset.name = 'df8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56fcf77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CenLat</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.91500</td>\n",
       "      <td>18.56400</td>\n",
       "      <td>1.438</td>\n",
       "      <td>1204</td>\n",
       "      <td>1698</td>\n",
       "      <td>16.9</td>\n",
       "      <td>98</td>\n",
       "      <td>1941</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.91000</td>\n",
       "      <td>18.49600</td>\n",
       "      <td>3.696</td>\n",
       "      <td>1207</td>\n",
       "      <td>2070</td>\n",
       "      <td>15.9</td>\n",
       "      <td>282</td>\n",
       "      <td>3954</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.90300</td>\n",
       "      <td>18.56900</td>\n",
       "      <td>3.405</td>\n",
       "      <td>1143</td>\n",
       "      <td>1797</td>\n",
       "      <td>13.2</td>\n",
       "      <td>102</td>\n",
       "      <td>3636</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.35698</td>\n",
       "      <td>-121.05735</td>\n",
       "      <td>2.924</td>\n",
       "      <td>1613</td>\n",
       "      <td>2196</td>\n",
       "      <td>12.8</td>\n",
       "      <td>350</td>\n",
       "      <td>3338</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.17540</td>\n",
       "      <td>-117.28400</td>\n",
       "      <td>16.154</td>\n",
       "      <td>1982</td>\n",
       "      <td>3448</td>\n",
       "      <td>12.6</td>\n",
       "      <td>93</td>\n",
       "      <td>10396</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-3.05715</td>\n",
       "      <td>37.35070</td>\n",
       "      <td>0.616</td>\n",
       "      <td>5663</td>\n",
       "      <td>5794</td>\n",
       "      <td>9.9</td>\n",
       "      <td>355</td>\n",
       "      <td>905</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>77.02720</td>\n",
       "      <td>15.48540</td>\n",
       "      <td>0.418</td>\n",
       "      <td>323</td>\n",
       "      <td>587</td>\n",
       "      <td>18.8</td>\n",
       "      <td>144</td>\n",
       "      <td>1084</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>78.87100</td>\n",
       "      <td>12.16140</td>\n",
       "      <td>5.016</td>\n",
       "      <td>123</td>\n",
       "      <td>684</td>\n",
       "      <td>13.8</td>\n",
       "      <td>350</td>\n",
       "      <td>4111</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>46.21184</td>\n",
       "      <td>-121.49584</td>\n",
       "      <td>0.027</td>\n",
       "      <td>3396</td>\n",
       "      <td>3529</td>\n",
       "      <td>35.5</td>\n",
       "      <td>307</td>\n",
       "      <td>214</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>47.08510</td>\n",
       "      <td>12.37840</td>\n",
       "      <td>2.939</td>\n",
       "      <td>2650</td>\n",
       "      <td>3409</td>\n",
       "      <td>16.3</td>\n",
       "      <td>207</td>\n",
       "      <td>2760</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CenLat     CenLon    Area  Zmin  Zmax  Slope  Aspect   Lmax  Thickness\n",
       "0    67.91500   18.56400   1.438  1204  1698   16.9      98   1941       72.0\n",
       "1    67.91000   18.49600   3.696  1207  2070   15.9     282   3954       84.0\n",
       "2    67.90300   18.56900   3.405  1143  1797   13.2     102   3636       99.0\n",
       "3    48.35698 -121.05735   2.924  1613  2196   12.8     350   3338       99.0\n",
       "4    52.17540 -117.28400  16.154  1982  3448   12.6      93  10396      150.0\n",
       "..        ...        ...     ...   ...   ...    ...     ...    ...        ...\n",
       "440  -3.05715   37.35070   0.616  5663  5794    9.9     355    905       23.0\n",
       "441  77.02720   15.48540   0.418   323   587   18.8     144   1084       27.0\n",
       "442  78.87100   12.16140   5.016   123   684   13.8     350   4111       76.0\n",
       "443  46.21184 -121.49584   0.027  3396  3529   35.5     307    214       57.0\n",
       "444  47.08510   12.37840   2.939  2650  3409   16.3     207   2760       39.0\n",
       "\n",
       "[426 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1811df69",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total inputs = 3408\n",
      "non-trainable parameters = 17\n",
      "trainable parameters = 3393\n"
     ]
    }
   ],
   "source": [
    "# calculate model parameters \n",
    "total_inputs = (len(dataset) * (len(dataset.columns) -1))\n",
    "inputs = len(dataset.columns) - 1\n",
    "print('total inputs = ' + str(total_inputs))\n",
    "\n",
    "non_trainable_parameters = (len(dataset.columns)) + ((len(dataset.columns) - 1))\n",
    "print('non-trainable parameters = ' + str(non_trainable_parameters))\n",
    "\n",
    "layer_1 = 60\n",
    "layer_2 = 46\n",
    "\n",
    "total_parameters = (\n",
    "    layer_1 * (inputs + 1)  + \n",
    "    (layer_2 * (layer_1 + 1)) + \n",
    "    ((1 * (layer_2 + 1))) +\n",
    "    non_trainable_parameters\n",
    ")\n",
    "print('trainable parameters = ' + str(total_parameters - non_trainable_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2a2166",
   "metadata": {
    "code_folding": [
     4,
     5
    ],
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 275/275 [00:00<00:00, 1593.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer architecture</th>\n",
       "      <th>total parameters</th>\n",
       "      <th>trained parameters</th>\n",
       "      <th>total inputs</th>\n",
       "      <th>df</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>validation split</th>\n",
       "      <th>epochs</th>\n",
       "      <th>test mae avg</th>\n",
       "      <th>train mae avg</th>\n",
       "      <th>test mae std dev</th>\n",
       "      <th>train mae std dev</th>\n",
       "      <th>test predicted thickness std dev</th>\n",
       "      <th>train predicted thickness std dev</th>\n",
       "      <th>test - train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>19.618951</td>\n",
       "      <td>18.981482</td>\n",
       "      <td>3.454822</td>\n",
       "      <td>1.395948</td>\n",
       "      <td>6.849141</td>\n",
       "      <td>4.450141</td>\n",
       "      <td>0.637469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.028465</td>\n",
       "      <td>19.527148</td>\n",
       "      <td>3.338884</td>\n",
       "      <td>1.291159</td>\n",
       "      <td>7.229381</td>\n",
       "      <td>5.083309</td>\n",
       "      <td>0.501317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.059461</td>\n",
       "      <td>19.628291</td>\n",
       "      <td>2.549977</td>\n",
       "      <td>1.251391</td>\n",
       "      <td>8.163460</td>\n",
       "      <td>5.486979</td>\n",
       "      <td>0.431170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.696209</td>\n",
       "      <td>20.214970</td>\n",
       "      <td>2.694641</td>\n",
       "      <td>1.677756</td>\n",
       "      <td>8.642095</td>\n",
       "      <td>5.592713</td>\n",
       "      <td>0.481239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>22.561178</td>\n",
       "      <td>21.071632</td>\n",
       "      <td>3.331436</td>\n",
       "      <td>0.922440</td>\n",
       "      <td>4.072864</td>\n",
       "      <td>2.156377</td>\n",
       "      <td>1.489545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>22.611158</td>\n",
       "      <td>20.974647</td>\n",
       "      <td>3.235544</td>\n",
       "      <td>0.937583</td>\n",
       "      <td>4.880827</td>\n",
       "      <td>2.390968</td>\n",
       "      <td>1.636512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>22.648749</td>\n",
       "      <td>20.791936</td>\n",
       "      <td>3.469679</td>\n",
       "      <td>0.908162</td>\n",
       "      <td>4.394150</td>\n",
       "      <td>2.198093</td>\n",
       "      <td>1.856813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>22.925221</td>\n",
       "      <td>21.113651</td>\n",
       "      <td>3.606206</td>\n",
       "      <td>1.024825</td>\n",
       "      <td>3.937835</td>\n",
       "      <td>2.152602</td>\n",
       "      <td>1.811569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>23.132563</td>\n",
       "      <td>22.146909</td>\n",
       "      <td>3.610950</td>\n",
       "      <td>1.574109</td>\n",
       "      <td>7.137610</td>\n",
       "      <td>5.599342</td>\n",
       "      <td>0.985654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>23.236795</td>\n",
       "      <td>21.930665</td>\n",
       "      <td>3.544364</td>\n",
       "      <td>1.420382</td>\n",
       "      <td>6.380354</td>\n",
       "      <td>5.019096</td>\n",
       "      <td>1.306131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>23.347840</td>\n",
       "      <td>21.566725</td>\n",
       "      <td>3.222072</td>\n",
       "      <td>1.173026</td>\n",
       "      <td>5.091355</td>\n",
       "      <td>4.755342</td>\n",
       "      <td>1.781115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>23.563866</td>\n",
       "      <td>22.289110</td>\n",
       "      <td>3.102034</td>\n",
       "      <td>1.376429</td>\n",
       "      <td>6.120010</td>\n",
       "      <td>6.682120</td>\n",
       "      <td>1.274756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>23.724025</td>\n",
       "      <td>22.074015</td>\n",
       "      <td>3.185868</td>\n",
       "      <td>0.900757</td>\n",
       "      <td>3.557835</td>\n",
       "      <td>2.357717</td>\n",
       "      <td>1.650010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>23.815812</td>\n",
       "      <td>22.100874</td>\n",
       "      <td>3.604020</td>\n",
       "      <td>0.908872</td>\n",
       "      <td>4.230496</td>\n",
       "      <td>2.596175</td>\n",
       "      <td>1.714937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>23.850120</td>\n",
       "      <td>22.291565</td>\n",
       "      <td>3.497346</td>\n",
       "      <td>0.806518</td>\n",
       "      <td>4.294350</td>\n",
       "      <td>1.137611</td>\n",
       "      <td>1.558556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>24.024015</td>\n",
       "      <td>22.356847</td>\n",
       "      <td>3.268711</td>\n",
       "      <td>1.013194</td>\n",
       "      <td>4.057677</td>\n",
       "      <td>1.715672</td>\n",
       "      <td>1.667169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>24.068329</td>\n",
       "      <td>22.188080</td>\n",
       "      <td>3.448562</td>\n",
       "      <td>0.833040</td>\n",
       "      <td>3.812346</td>\n",
       "      <td>1.939547</td>\n",
       "      <td>1.880248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>24.876549</td>\n",
       "      <td>23.097362</td>\n",
       "      <td>3.406596</td>\n",
       "      <td>0.886186</td>\n",
       "      <td>3.461220</td>\n",
       "      <td>1.008168</td>\n",
       "      <td>1.779187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>64-48</td>\n",
       "      <td>3828</td>\n",
       "      <td>3809</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>24.885821</td>\n",
       "      <td>23.137816</td>\n",
       "      <td>3.411332</td>\n",
       "      <td>0.871044</td>\n",
       "      <td>3.557214</td>\n",
       "      <td>1.055048</td>\n",
       "      <td>1.748005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>25.032291</td>\n",
       "      <td>23.662723</td>\n",
       "      <td>6.528711</td>\n",
       "      <td>7.191763</td>\n",
       "      <td>10.160369</td>\n",
       "      <td>9.642501</td>\n",
       "      <td>1.369568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>25.115203</td>\n",
       "      <td>23.628682</td>\n",
       "      <td>3.610810</td>\n",
       "      <td>0.890388</td>\n",
       "      <td>3.661848</td>\n",
       "      <td>0.875135</td>\n",
       "      <td>1.486521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>50-28</td>\n",
       "      <td>1976</td>\n",
       "      <td>1957</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>25.135846</td>\n",
       "      <td>23.584326</td>\n",
       "      <td>3.495164</td>\n",
       "      <td>0.893550</td>\n",
       "      <td>3.440218</td>\n",
       "      <td>1.071702</td>\n",
       "      <td>1.551520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>29.647513</td>\n",
       "      <td>28.616721</td>\n",
       "      <td>5.724535</td>\n",
       "      <td>2.069665</td>\n",
       "      <td>4.931937</td>\n",
       "      <td>4.138678</td>\n",
       "      <td>1.030792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10-5</td>\n",
       "      <td>180</td>\n",
       "      <td>161</td>\n",
       "      <td>3834</td>\n",
       "      <td>df7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>30.719780</td>\n",
       "      <td>29.889716</td>\n",
       "      <td>6.529498</td>\n",
       "      <td>7.942136</td>\n",
       "      <td>11.394197</td>\n",
       "      <td>10.913125</td>\n",
       "      <td>0.830064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer architecture  total parameters  trained parameters  total inputs  \\\n",
       "134              64-48              3828                3809          3834   \n",
       "131              50-28              1976                1957          3834   \n",
       "146              64-48              3828                3809          3834   \n",
       "143              50-28              1976                1957          3834   \n",
       "132              50-28              1976                1957          3834   \n",
       "147              64-48              3828                3809          3834   \n",
       "135              64-48              3828                3809          3834   \n",
       "144              50-28              1976                1957          3834   \n",
       "149              50-28              1976                1957          3834   \n",
       "129               10-5               180                 161          3834   \n",
       "141               10-5               180                 161          3834   \n",
       "137              50-28              1976                1957          3834   \n",
       "151              64-48              3828                3809          3834   \n",
       "139              64-48              3828                3809          3834   \n",
       "128               10-5               180                 161          3834   \n",
       "150              50-28              1976                1957          3834   \n",
       "138              50-28              1976                1957          3834   \n",
       "136              64-48              3828                3809          3834   \n",
       "148              64-48              3828                3809          3834   \n",
       "140               10-5               180                 161          3834   \n",
       "145              50-28              1976                1957          3834   \n",
       "133              50-28              1976                1957          3834   \n",
       "130               10-5               180                 161          3834   \n",
       "142               10-5               180                 161          3834   \n",
       "\n",
       "      df  dropout  learning rate  validation split  epochs  test mae avg  \\\n",
       "134  df7        1          0.100               0.2     100     19.618951   \n",
       "131  df7        1          0.100               0.2     100     20.028465   \n",
       "146  df7        0          0.100               0.2     100     20.059461   \n",
       "143  df7        0          0.100               0.2     100     20.696209   \n",
       "132  df7        1          0.010               0.2     100     22.561178   \n",
       "147  df7        0          0.010               0.2     100     22.611158   \n",
       "135  df7        1          0.010               0.2     100     22.648749   \n",
       "144  df7        0          0.010               0.2     100     22.925221   \n",
       "149  df7        0          0.100               0.2      50     23.132563   \n",
       "129  df7        1          0.100               0.2     100     23.236795   \n",
       "141  df7        0          0.100               0.2     100     23.347840   \n",
       "137  df7        1          0.100               0.2      50     23.563866   \n",
       "151  df7        0          0.010               0.2      50     23.724025   \n",
       "139  df7        1          0.010               0.2      50     23.815812   \n",
       "128  df7        1          0.010               0.2     100     23.850120   \n",
       "150  df7        0          0.010               0.2      50     24.024015   \n",
       "138  df7        1          0.010               0.2      50     24.068329   \n",
       "136  df7        1          0.001               0.2     100     24.876549   \n",
       "148  df7        0          0.001               0.2     100     24.885821   \n",
       "140  df7        0          0.010               0.2     100     25.032291   \n",
       "145  df7        0          0.001               0.2     100     25.115203   \n",
       "133  df7        1          0.001               0.2     100     25.135846   \n",
       "130  df7        1          0.001               0.2     100     29.647513   \n",
       "142  df7        0          0.001               0.2     100     30.719780   \n",
       "\n",
       "     train mae avg  test mae std dev  train mae std dev  \\\n",
       "134      18.981482          3.454822           1.395948   \n",
       "131      19.527148          3.338884           1.291159   \n",
       "146      19.628291          2.549977           1.251391   \n",
       "143      20.214970          2.694641           1.677756   \n",
       "132      21.071632          3.331436           0.922440   \n",
       "147      20.974647          3.235544           0.937583   \n",
       "135      20.791936          3.469679           0.908162   \n",
       "144      21.113651          3.606206           1.024825   \n",
       "149      22.146909          3.610950           1.574109   \n",
       "129      21.930665          3.544364           1.420382   \n",
       "141      21.566725          3.222072           1.173026   \n",
       "137      22.289110          3.102034           1.376429   \n",
       "151      22.074015          3.185868           0.900757   \n",
       "139      22.100874          3.604020           0.908872   \n",
       "128      22.291565          3.497346           0.806518   \n",
       "150      22.356847          3.268711           1.013194   \n",
       "138      22.188080          3.448562           0.833040   \n",
       "136      23.097362          3.406596           0.886186   \n",
       "148      23.137816          3.411332           0.871044   \n",
       "140      23.662723          6.528711           7.191763   \n",
       "145      23.628682          3.610810           0.890388   \n",
       "133      23.584326          3.495164           0.893550   \n",
       "130      28.616721          5.724535           2.069665   \n",
       "142      29.889716          6.529498           7.942136   \n",
       "\n",
       "     test predicted thickness std dev  train predicted thickness std dev  \\\n",
       "134                          6.849141                           4.450141   \n",
       "131                          7.229381                           5.083309   \n",
       "146                          8.163460                           5.486979   \n",
       "143                          8.642095                           5.592713   \n",
       "132                          4.072864                           2.156377   \n",
       "147                          4.880827                           2.390968   \n",
       "135                          4.394150                           2.198093   \n",
       "144                          3.937835                           2.152602   \n",
       "149                          7.137610                           5.599342   \n",
       "129                          6.380354                           5.019096   \n",
       "141                          5.091355                           4.755342   \n",
       "137                          6.120010                           6.682120   \n",
       "151                          3.557835                           2.357717   \n",
       "139                          4.230496                           2.596175   \n",
       "128                          4.294350                           1.137611   \n",
       "150                          4.057677                           1.715672   \n",
       "138                          3.812346                           1.939547   \n",
       "136                          3.461220                           1.008168   \n",
       "148                          3.557214                           1.055048   \n",
       "140                         10.160369                           9.642501   \n",
       "145                          3.661848                           0.875135   \n",
       "133                          3.440218                           1.071702   \n",
       "130                          4.931937                           4.138678   \n",
       "142                         11.394197                          10.913125   \n",
       "\n",
       "     test - train  \n",
       "134      0.637469  \n",
       "131      0.501317  \n",
       "146      0.431170  \n",
       "143      0.481239  \n",
       "132      1.489545  \n",
       "147      1.636512  \n",
       "135      1.856813  \n",
       "144      1.811569  \n",
       "149      0.985654  \n",
       "129      1.306131  \n",
       "141      1.781115  \n",
       "137      1.274756  \n",
       "151      1.650010  \n",
       "139      1.714937  \n",
       "128      1.558556  \n",
       "150      1.667169  \n",
       "138      1.880248  \n",
       "136      1.779187  \n",
       "148      1.748005  \n",
       "140      1.369568  \n",
       "145      1.486521  \n",
       "133      1.551520  \n",
       "130      1.030792  \n",
       "142      0.830064  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load deviations table \n",
    "rootdir = 'zults/'\n",
    "predictions = pd.DataFrame()\n",
    "deviations = pd.DataFrame()\n",
    "for file in tqdm(os.listdir(rootdir)):\n",
    "    if 'predictions' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        predictions = predictions.append(file_reader, ignore_index = True)\n",
    "    if 'deviations' in file:\n",
    "        file_reader = pd.read_csv(rootdir + file)\n",
    "        deviations = pd.concat([deviations, file_reader], ignore_index = True)\n",
    "        \n",
    "deviations = deviations.drop('Unnamed: 0', axis = 1)\n",
    "predictions = predictions.drop('Unnamed: 0', axis = 1)\n",
    "deviations['total parameters'] = deviations['total parameters'].astype(int)\n",
    "deviations['trained parameters'] = deviations['trained parameters'].astype(int)\n",
    "deviations['total inputs'] = deviations['total inputs'].astype(int)\n",
    "deviations = deviations[\n",
    "    (deviations['df'].str.contains(selected_dataset)) \n",
    "#     &\n",
    "#     (deviations['layer architecture'] == '10-5')\n",
    "#     &\n",
    "#     (deviations['learning rate'] == 0.100)\n",
    "#     &\n",
    "#     (deviations['epochs'] == 50)\n",
    "]\n",
    "deviations['test - train'] = (\n",
    "    abs(deviations['test mae avg'] - deviations['train mae avg'])\n",
    ")\n",
    "deviations = deviations.sort_values(\n",
    "    [\n",
    "#         'layer architecture',\n",
    "#         'test - train',\n",
    "#         'epochs',\n",
    "        'test mae avg', \n",
    "        \n",
    "#         'test predicted thickness std dev'\n",
    "#         'layer architecture',\n",
    "#         'learning rate',\n",
    "#         'df',\n",
    "#         'layer architecture'\n",
    "    ]\n",
    ")\n",
    "deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1213618",
   "metadata": {
    "code_folding": [
     0,
     33,
     47
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load selected model and look at predicted accuracies of each random state\n",
    "print('Please select index from deviations table to inspect further')\n",
    "\n",
    "selection = int(input())\n",
    "\n",
    "arch = deviations['layer architecture'].loc[selection]\n",
    "top_learning_rate = deviations['learning rate'].loc[selection]\n",
    "epochs = deviations['epochs'].loc[selection]\n",
    "dropout = deviations['dropout'].loc[selection]\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "dnn_model = {}\n",
    "rootdir = 'saved_models/' + module + '/sm_' + arch + '/'\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = gl.data_splitter(dataset)\n",
    "features = pd.concat([train_features, test_features], ignore_index = True)\n",
    "labels = pd.concat([train_labels, test_labels], ignore_index = True)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle(\n",
    "    'Volume estimates using layer architecture ' + arch +\n",
    "    ', learning rate: ' + str(top_learning_rate) + ', epochs: ' + str(epochs)\n",
    "             , fontsize=18, y=1\n",
    "            )\n",
    "fig.patch.set_facecolor('w')\n",
    "\n",
    "for n, rs in tqdm(enumerate(RS)):\n",
    "    ax = plt.subplot(5, 5, n + 1)\n",
    "    model_name = (\n",
    "        str(arch) + \n",
    "        '_' + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )   \n",
    "    \n",
    "    model_path = (\n",
    "        rootdir + \n",
    "        dataset.name +\n",
    "        '_' + \n",
    "        str(dropout) +\n",
    "        '_dnn_MULTI_' + \n",
    "        str(top_learning_rate) + \n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_model[model_name] = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    \n",
    "    y = dnn_model[model_name].predict(features, verbose = 0)\n",
    "    plt.plot(labels,y,'.')\n",
    "    plt.plot((0,400),(0,400),'-')\n",
    "    plt.xlabel('True Thickness (m)')\n",
    "    plt.ylabel('Model Thickness (m)')\n",
    "    ax.set_title('Random State ' +str(rs))\n",
    "    plt.xlim((0,400))\n",
    "    plt.ylim((0,400))\n",
    "# plt.tight_layout()\n",
    "\n",
    "fig_dir = (\n",
    "    'figs/' + \n",
    "    module + \n",
    "    '/'   \n",
    ") \n",
    "isdir = os.path.isdir(fig_dir)\n",
    "if isdir == False:\n",
    "    os.makedirs(fig_dir)\n",
    "file_name_1 = (\n",
    "    fig_dir +\n",
    "    'predictions_' +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) +\n",
    "    '.eps'\n",
    ")\n",
    "\n",
    "\n",
    "file_name_2 = (\n",
    "    fig_dir +\n",
    "    'predictions_' +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) +\n",
    "    '.png'\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(file_name_1)\n",
    "# fig.savefig(file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e21e8",
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load selected model loss curves\n",
    "\n",
    "fig_dir = (\n",
    "    'figs/' + \n",
    "    module + \n",
    "    '/'   \n",
    ") \n",
    "isdir = os.path.isdir(fig_dir)\n",
    "if isdir == False:\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "print(arch)\n",
    "print(top_learning_rate)\n",
    "print(epochs)\n",
    "print(dropout)\n",
    "\n",
    "print(fig_dir)\n",
    "rootdir = 'saved_results/' + res + '/sr_' + arch + '/'\n",
    "print(rootdir)\n",
    "dnn_history = {}\n",
    "fig,ax=plt.subplots(1,1,figsize=(15,15))\n",
    "fig.patch.set_facecolor('w')\n",
    "fig.suptitle('Loss curves for layer architecture ' + \n",
    "             arch + ', learning rate: ' + str(top_learning_rate) + ', epochs: ' + str(epochs) \n",
    "             )\n",
    "for n, rs in enumerate(RS): \n",
    "    ax = plt.subplot(5,5,n+1)\n",
    "    history_name = (\n",
    "        arch + \n",
    "        '_' +\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    model_name = (\n",
    "        dataset.name +\n",
    "        '_' +\n",
    "        str(dropout) +\n",
    "        '_dnn_history_MULTI_' +\n",
    "        str(top_learning_rate) +\n",
    "        '_0.2_' +\n",
    "        str(epochs) + \n",
    "        '_' + \n",
    "        str(rs)\n",
    "    )\n",
    "    \n",
    "    dnn_history[model_name] = pd.read_csv(rootdir + model_name)\n",
    "\n",
    "\n",
    "    ax.set_title('Random State: ' + str(rs))\n",
    "    gl.plot_loss(dnn_history[model_name])\n",
    "    \n",
    "file_name_1 = (\n",
    "    fig_dir +\n",
    "    'loss_' +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) +\n",
    "    '.eps'\n",
    ")\n",
    "\n",
    "file_name_2 = (\n",
    "    fig_dir +\n",
    "    'loss_' +\n",
    "    arch + '_' +\n",
    "    dataset.name + '_' +\n",
    "    str(dropout) + '_' +\n",
    "    str(top_learning_rate) + '_' +\n",
    "    str(epochs) +\n",
    "    '.png'\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(file_name_1)\n",
    "# fig.savefig(file_name_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017ded8",
   "metadata": {},
   "source": [
    "# LOAD AND SELECT PRETHICKTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da728a6",
   "metadata": {
    "code_folding": [
     84,
     112,
     141,
     170,
     201,
     232,
     561,
     899,
     901,
     903,
     905,
     907,
     909,
     911,
     913,
     915,
     917,
     919
    ],
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 275/275 [00:09<00:00, 28.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# load prethicktions\n",
    "\n",
    "root_dir = 'zults/'\n",
    "RGI_predicted = pd.DataFrame()\n",
    "\n",
    "# read each prediction file and do stuff to it and append it to a table\n",
    "for file in tqdm(os.listdir(root_dir)):\n",
    "    \n",
    "    if 'RGI_predicted' in file:\n",
    "        file_reader = pd.read_csv(root_dir + file)\n",
    "        file_reader['volume'] = (\n",
    "            file_reader['avg predicted thickness'] / 1e3\n",
    "        ) * file_reader['Area']\n",
    "        \n",
    "        # have to turn something into a series and append it to the df to build it\n",
    "        sum_volume = sum(file_reader['volume'])\n",
    "        total_volume = pd.Series(sum_volume, name = 'total volume')\n",
    "        RGI_predicted = pd.concat([RGI_predicted, total_volume], ignore_index = True)\n",
    "        \n",
    "        # stick RGI attribute statistics into df\n",
    "        if 'df1' not in file:\n",
    "            att_list = [\n",
    "                'Area',\n",
    "                'Aspect',\n",
    "                'Lmax',\n",
    "                'Slope',\n",
    "                'Zmin',\n",
    "                'Zmax'\n",
    "            ]\n",
    "            \n",
    "            for att in att_list:\n",
    "                mean = file_reader[att].mean()\n",
    "                median = file_reader[att].median()\n",
    "                std = file_reader[att].std()\n",
    "                q3 = np.quantile(file_reader[att], 0.75)\n",
    "                q1 = np.quantile(file_reader[att], 0.25)\n",
    "                iqr = q3 - q1  \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], att + '_RGI_mean'\n",
    "                ] = mean\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], att + '_RGI_median'\n",
    "                ] = median\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], att + '_RGI_std'\n",
    "                ] = std\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], att + '_RGI_iqr'\n",
    "                ] = iqr\n",
    "                               \n",
    "        # variance\n",
    "        file_reader['variance'] = file_reader['predicted thickness std dev'] **2 \n",
    "        variance = sum(file_reader['variance'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'total variance'\n",
    "        ] = np.sqrt(variance)/1e3\n",
    "\n",
    "        # mean thickness\n",
    "        thickness_mean = file_reader['avg predicted thickness'].mean()\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'mean thickness'\n",
    "        ] = thickness_mean/1e3\n",
    "        \n",
    "#         # max thickness\n",
    "#         thickness_max = file_reader['avg predicted thickness'].max()\n",
    "#         RGI_predicted.loc[\n",
    "#             RGI_predicted.index[-1], 'max model thickness (km)'\n",
    "#         ] = thickness_max/1e3\n",
    "        \n",
    "        # area * mean thickness\n",
    "        area = sum(file_reader['Area'])\n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'vol'\n",
    "        ] = (area * (thickness_mean/1e3))/1e3\n",
    "        \n",
    "        RGI_predicted.loc[\n",
    "            RGI_predicted.index[-1], 'area'\n",
    "        ] = area\n",
    "\n",
    "            \n",
    "        if 'df1' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df1'\n",
    "            \n",
    "            RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "            ] = 158.17\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'tolerance'\n",
    "            ] = 41.0\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'h mean f'\n",
    "            ] = 224\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '16-8' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '16-8'\n",
    "            if '24-12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '24-12'\n",
    "        if 'df2' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df2'   \n",
    "            \n",
    "            RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "            ] = 158.17\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'tolerance'\n",
    "            ] = 41.0\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'h mean f'\n",
    "            ] = 224\n",
    "\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '50-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-28'\n",
    "            if '64-48' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-48'\n",
    "        if 'df3' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df3'        \n",
    "             \n",
    "            \n",
    "            RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "            ] = 158.17\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'tolerance'\n",
    "            ] = 41.0\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'h mean f'\n",
    "            ] = 224\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "            if '37-20' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '37-20'\n",
    "            if '59-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '59-28'\n",
    "        if 'df4' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df4'    \n",
    "             \n",
    "            \n",
    "            RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "            ] = 158.17\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'tolerance'\n",
    "            ] = 41.0\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'h mean f'\n",
    "            ] = 224\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "            if '47-21' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '47-21'\n",
    "                \n",
    "            if '64-36' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-36'\n",
    "        if 'df5' in file:\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'dataframe'\n",
    "            ] = 'df5'    \n",
    "             \n",
    "            \n",
    "            RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "            ] = 158.17\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'tolerance'\n",
    "            ] = 41.0\n",
    "\n",
    "            RGI_predicted.loc[\n",
    "                RGI_predicted.index[-1], 'h mean f'\n",
    "            ] = 224\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "            if '50-25' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-25'\n",
    "                \n",
    "            if '64-42' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-42'\n",
    "        if 'df6' in file:\n",
    "            if 'df6_01' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_01'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 18.98\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 4.92\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 218\n",
    "                \n",
    "            if 'df6_02' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_02'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 1.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.27\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 72\n",
    "                \n",
    "            if 'df6_03' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_03'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 28.33\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 7.35\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 270\n",
    "                \n",
    "            if 'df6_04' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_04'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 8.61\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 2.23\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 210\n",
    "                \n",
    "            if 'df6_05' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_05'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 15.69\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 4.07\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 175\n",
    "                \n",
    "            if 'df6_06' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_06'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  3.77\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  0.98 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  341 \n",
    "                \n",
    "            if 'df6_07' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_07'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  7.47 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  1.94 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  220 \n",
    "                \n",
    "            if 'df6_08' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_08'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  0.30 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  0.08 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  101 \n",
    "                \n",
    "            if 'df6_09' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_09'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 14.64\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 3.80\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 283\n",
    "                \n",
    "            if 'df6_10' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_10'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.14\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.04\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 56\n",
    "                \n",
    "            if 'df6_11' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_11'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.13\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.03\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 61\n",
    "                \n",
    "            if 'df6_12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_12'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.02\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 48\n",
    "                \n",
    "            if 'df6_13' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_13'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 3.27\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.85\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 66\n",
    "                \n",
    "            if 'df6_14' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_14'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 2.87\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.74\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 85\n",
    "                \n",
    "            if 'df6_15' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_15'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.88\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.23\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 59\n",
    "                \n",
    "            if 'df6_16' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_16'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.10\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.03\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 42\n",
    "                \n",
    "            if 'df6_17' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_17'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 5.34\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 1.39\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 181\n",
    "                \n",
    "            if 'df6_18' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_18'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.07\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.02\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 63\n",
    "                \n",
    "            if 'df6_19' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df6_19'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 46.47\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 12.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 349\n",
    "                \n",
    "                \n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "        if 'df7' in file:\n",
    "            if '10-5' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '10-5'\n",
    "                \n",
    "            if '50-28' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '50-28'\n",
    "                \n",
    "            if '64-48' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'architecture'\n",
    "                ] = '64-48'\n",
    "                \n",
    "            if 'df7_01' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_01'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 18.98\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 4.92\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 218\n",
    "                \n",
    "            if 'df7_02' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_02'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 1.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.27\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 72\n",
    "                \n",
    "            if 'df7_03' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_03'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 28.33\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 7.35\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 270\n",
    "                \n",
    "            if 'df7_04' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_04'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 8.61\n",
    "            \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 2.23\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 210\n",
    "                \n",
    "            if 'df7_05' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_05'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 15.69\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 4.07\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 175\n",
    "                \n",
    "            if 'df7_06' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_06'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  3.77\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  0.98 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  341 \n",
    "                \n",
    "            if 'df7_07' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_07'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  7.47 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  1.94 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  220 \n",
    "                \n",
    "            if 'df7_08' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_08'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] =  0.30 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] =  0.08 \n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] =  101 \n",
    "                \n",
    "            if 'df7_09' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_09'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 14.64\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 3.80\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 283\n",
    "                \n",
    "            if 'df7_10' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_10'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.14\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.04\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 56\n",
    "                \n",
    "            if 'df7_11' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_11'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.13\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.03\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 61\n",
    "                \n",
    "            if 'df7_12' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_12'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.02\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 48\n",
    "                \n",
    "            if 'df7_13' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_13'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 3.27\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.85\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 66\n",
    "                \n",
    "            if 'df7_14' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_14'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 2.87\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.74\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 85\n",
    "                \n",
    "            if 'df7_15' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_15'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.88\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.23\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 59\n",
    "                \n",
    "            if 'df7_16' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_16'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.10\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.03\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 42\n",
    "                \n",
    "            if 'df7_17' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_17'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 5.34\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 1.39\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 181\n",
    "                \n",
    "            if 'df7_18' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_18'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 0.07\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 0.02\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 63\n",
    "                \n",
    "            if 'df7_19' in file:\n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'dataframe'\n",
    "                ] = 'df7_19'\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'volf'\n",
    "                ] = 46.47\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'tolerance'\n",
    "                ] = 12.06\n",
    "                \n",
    "                RGI_predicted.loc[\n",
    "                    RGI_predicted.index[-1], 'h mean f'\n",
    "                ] = 349\n",
    "        if '0.1' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.100'\n",
    "        if '0.01' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.010'\n",
    "        if '0.001' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'learning rate']= '0.001'\n",
    "        if '_20' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '20'\n",
    "        if '_25' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '25'\n",
    "        if '_50' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '50'\n",
    "        if '_60' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '60'\n",
    "        if '_15' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '15'\n",
    "        if '_30' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '30'\n",
    "        if '_40' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '40'\n",
    "        if '_100' in file:\n",
    "            RGI_predicted.loc[RGI_predicted.index[-1], 'epochs']= '100'\n",
    "\n",
    "\n",
    "\n",
    "# Select prethicktions\n",
    "\n",
    "# RGI_predicted = RGI_predicted.drop(0, axis=1)\n",
    "RGI_predicted = RGI_predicted[\n",
    "    (RGI_predicted['dataframe'].str.contains('df7')) \n",
    "    &\n",
    "    (RGI_predicted['architecture'] == '64-48')\n",
    "    &\n",
    "    (RGI_predicted['learning rate'] == '0.100')\n",
    "    &\n",
    "    (RGI_predicted['epochs'] == '100')\n",
    "]\n",
    "\n",
    "RGI_predicted['mean thickness'] = RGI_predicted['mean thickness'] * 1e3\n",
    "RGI_predicted['voldiff'] = RGI_predicted['vol'] - RGI_predicted['volf'] \n",
    "\n",
    "\n",
    "RGI_predicted = RGI_predicted.sort_values([\n",
    "#     'mean thickness (km)',\n",
    "#     'architecture',\n",
    "#     'learning rate',\n",
    "    'dataframe'\n",
    "], ascending = True)\n",
    "\n",
    "RGI_predicted = RGI_predicted.reset_index()\n",
    "\n",
    "RGI_predicted = RGI_predicted.drop('index', axis = 1)\n",
    "# RGI_predicted = RGI_predicted[\n",
    "#     RGI_predicted['vol'] < 300\n",
    "# ]\n",
    "RGI = RGI_predicted.copy()\n",
    "df = RGI.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b00b708",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 362.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# finish building df\n",
    "\n",
    "dfa = pd.DataFrame()\n",
    "pth_3 = '/data/fast1/glacierml/data/regional_data/raw/'\n",
    "for file in tqdm(os.listdir(pth_3)):\n",
    "    dfb = pd.read_csv(pth_3 + file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    region_and_number = file[:-4]\n",
    "    region_number = region_and_number[:2]\n",
    "    region = region_and_number[3:]\n",
    "\n",
    "    dfb['geographic region'] = region\n",
    "    dfb['region'] = region_number\n",
    "    dfa = dfa.append(dfb, ignore_index=True)\n",
    "\n",
    "dfa = dfa.reset_index()\n",
    "\n",
    "dfa = dfa[[\n",
    "    'GlaThiDa_index',\n",
    "    'RGI_index',\n",
    "    'RGIId',\n",
    "    'region',\n",
    "    'geographic region'\n",
    "]]\n",
    "\n",
    "pth = '/data/fast1/glacierml/data/RGI/rgi60-attribs/'\n",
    "pth_2 = '/data/fast1/glacierml/data/regional_data/training_data/'\n",
    "RGI_extra = pd.DataFrame()\n",
    "for file in os.listdir(pth):\n",
    "    f = pd.read_csv(pth + file, encoding_errors = 'replace', on_bad_lines = 'skip')\n",
    "    RGI_extra = pd.concat([RGI_extra, f], ignore_index = True)\n",
    "\n",
    "    region_and_number = file[:-4]\n",
    "    region_number = region_and_number[:2]\n",
    "    region = region_and_number[9:]\n",
    "    dfc = dfa[dfa['region'] == region_number]\n",
    "    \n",
    "    for file in os.listdir(pth_2):\n",
    "        if file[:2] == region_number:\n",
    "            glathida_regional = pd.read_csv(pth_2 + file)\n",
    "\n",
    "    GlaThiDa_mean_area = glathida_regional['Area'].mean()\n",
    "    GlaThiDa_mean_aspect = glathida_regional['Aspect'].mean()\n",
    "    GlaThiDa_mean_lmax = glathida_regional['Lmax'].mean()\n",
    "    GlaThiDa_mean_slope = glathida_regional['Slope'].mean()\n",
    "    GlaThiDa_mean_zmin = glathida_regional['Zmin'].mean()\n",
    "    GlaThiDa_mean_zmax = glathida_regional['Zmax'].mean()\n",
    "    \n",
    "    GlaThiDa_median_area = glathida_regional['Area'].median()\n",
    "    GlaThiDa_median_aspect = glathida_regional['Aspect'].median()\n",
    "    GlaThiDa_median_lmax = glathida_regional['Lmax'].median()\n",
    "    GlaThiDa_median_slope = glathida_regional['Slope'].median()\n",
    "    GlaThiDa_median_zmin = glathida_regional['Zmin'].median()\n",
    "    GlaThiDa_median_zmax = glathida_regional['Zmax'].median()\n",
    "    \n",
    "    GlaThiDa_std_area = glathida_regional['Area'].std(ddof=0)\n",
    "    GlaThiDa_std_aspect = glathida_regional['Aspect'].std(ddof=0)\n",
    "    GlaThiDa_std_lmax = glathida_regional['Lmax'].std(ddof=0)\n",
    "    GlaThiDa_std_slope = glathida_regional['Slope'].std(ddof=0)\n",
    "    GlaThiDa_std_zmin = glathida_regional['Zmin'].std(ddof=0)\n",
    "    GlaThiDa_std_zmax = glathida_regional['Zmax'].std(ddof=0)\n",
    "    \n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Area_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_area\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Aspect_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_aspect\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Lmax_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_lmax\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Slope_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_slope\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmin_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_zmin\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmax_GlaThiDa_mean'\n",
    "    ] = GlaThiDa_mean_zmax\n",
    "    \n",
    "    \n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Area_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_area\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Aspect_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_aspect\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Lmax_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_lmax\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Slope_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_slope\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmin_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_zmin\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmax_GlaThiDa_median'\n",
    "    ] = GlaThiDa_median_zmax\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Area_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_area\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Aspect_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_aspect\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Lmax_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_lmax\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Slope_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_slope\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmin_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_zmin\n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'Zmax_GlaThiDa_std'\n",
    "    ] = GlaThiDa_std_zmax\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    trainable_ratio = (len(dfc) / len(f))\n",
    "    percent_trainable = trainable_ratio * 100\n",
    "    \n",
    "    df.loc[\n",
    "        df[df['dataframe'].str[4:] == region_number].index, 'ratio trainable'\n",
    "    ] = trainable_ratio\n",
    "\n",
    "#     print(df['dataframe'].str[4:][df['dataframe'].str[4:] == region_number])   \n",
    "    \n",
    "#     if reg == region_number:\n",
    "        \n",
    "#         print(df['dataframe'])\n",
    "#     index = df[df['dataframe'][3:] == region_number].index\n",
    "#     df['dataframe'].loc[index]\n",
    "#     print(df['dataframe'].loc[index])\n",
    "    \n",
    "#     print(\n",
    "#         'region ' + str(region_number) + ' has ' + str(len(f)) + ' lines of data, ' +\n",
    "#         str(len(dfc)) + ' or ' + str(percent_trainable) +\n",
    "#         '% of which are trainable with GlaThiDa thicknesses'    \n",
    "#     )\n",
    "df['vol_ratio'] = df['vol'] / df['volf']\n",
    "df['vol_from_zero'] = abs(1 - df['vol_ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b110a07a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute residuals\n",
    "residuals = df[[\n",
    "    'dataframe',\n",
    "    'vol_ratio',\n",
    "    'vol_from_zero',\n",
    "    'voldiff',\n",
    "]]\n",
    "\n",
    "residuals['percent error'] = abs(\n",
    "   ( 1 - residuals['vol_ratio']) * 100\n",
    ")\n",
    "residuals['region'] = residuals['dataframe'].str[4:]\n",
    "residuals = residuals.drop('dataframe', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf4888d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_ratio</th>\n",
       "      <th>vol_from_zero</th>\n",
       "      <th>voldiff</th>\n",
       "      <th>percent error</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.915383</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>-0.025385</td>\n",
       "      <td>8.461743</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.108275</td>\n",
       "      <td>0.108275</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>10.827470</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.870392</td>\n",
       "      <td>0.129608</td>\n",
       "      <td>-0.371974</td>\n",
       "      <td>12.960753</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.143490</td>\n",
       "      <td>0.143490</td>\n",
       "      <td>0.469211</td>\n",
       "      <td>14.348968</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.244751</td>\n",
       "      <td>0.244751</td>\n",
       "      <td>0.215381</td>\n",
       "      <td>24.475104</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734985</td>\n",
       "      <td>0.265015</td>\n",
       "      <td>-4.158086</td>\n",
       "      <td>26.501503</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.377485</td>\n",
       "      <td>0.377485</td>\n",
       "      <td>17.541723</td>\n",
       "      <td>37.748490</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.563052</td>\n",
       "      <td>0.436948</td>\n",
       "      <td>-8.293267</td>\n",
       "      <td>43.694769</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448177</td>\n",
       "      <td>0.551823</td>\n",
       "      <td>-4.751198</td>\n",
       "      <td>55.182317</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.427405</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>-4.277286</td>\n",
       "      <td>57.259515</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.609075</td>\n",
       "      <td>-8.916857</td>\n",
       "      <td>60.907495</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.624738</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.037484</td>\n",
       "      <td>62.473777</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343993</td>\n",
       "      <td>0.656007</td>\n",
       "      <td>-18.584680</td>\n",
       "      <td>65.600707</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.696012</td>\n",
       "      <td>0.696012</td>\n",
       "      <td>0.737773</td>\n",
       "      <td>69.601241</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.268093</td>\n",
       "      <td>0.731907</td>\n",
       "      <td>-2.759289</td>\n",
       "      <td>73.190682</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.014216</td>\n",
       "      <td>1.014216</td>\n",
       "      <td>0.141990</td>\n",
       "      <td>101.421553</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.044256</td>\n",
       "      <td>1.044256</td>\n",
       "      <td>5.576325</td>\n",
       "      <td>104.425564</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.355288</td>\n",
       "      <td>1.355288</td>\n",
       "      <td>0.135529</td>\n",
       "      <td>135.528772</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.509542</td>\n",
       "      <td>5.509542</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>550.954227</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vol_ratio  vol_from_zero    voldiff  percent error region\n",
       "7    0.915383       0.084617  -0.025385       8.461743     08\n",
       "10   1.108275       0.108275   0.014076      10.827470     11\n",
       "13   0.870392       0.129608  -0.371974      12.960753     14\n",
       "12   1.143490       0.143490   0.469211      14.348968     13\n",
       "14   1.244751       0.244751   0.215381      24.475104     15\n",
       "4    0.734985       0.265015  -4.158086      26.501503     05\n",
       "18   1.377485       0.377485  17.541723      37.748490     19\n",
       "0    0.563052       0.436948  -8.293267      43.694769     01\n",
       "3    0.448177       0.551823  -4.751198      55.182317     04\n",
       "6    0.427405       0.572595  -4.277286      57.259515     07\n",
       "8    0.390925       0.609075  -8.916857      60.907495     09\n",
       "11   1.624738       0.624738   0.037484      62.473777     12\n",
       "2    0.343993       0.656007 -18.584680      65.600707     03\n",
       "1    1.696012       0.696012   0.737773      69.601241     02\n",
       "5    0.268093       0.731907  -2.759289      73.190682     06\n",
       "9    2.014216       1.014216   0.141990     101.421553     10\n",
       "16   2.044256       1.044256   5.576325     104.425564     17\n",
       "15   2.355288       1.355288   0.135529     135.528772     16\n",
       "17   6.509542       5.509542   0.385668     550.954227     18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.sort_values('percent error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94039c",
   "metadata": {},
   "source": [
    "# VOLUME ESTIMATE SCATTER PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b72b1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# volume comparisons by RGI region\n",
    "dfq = df[[\n",
    "    'dataframe',\n",
    "    'vol',\n",
    "    'volf',\n",
    "    'ratio trainable'\n",
    "]]\n",
    "ratio = dfq.vol / dfq.volf\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (15,10))\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "\n",
    "ax.fill_between(\n",
    "    x = (-10,30),\n",
    "    y1 = 1.25,\n",
    "    y2 = 0.75,\n",
    "    facecolor = 'gray',\n",
    "    alpha = 0.2\n",
    ")\n",
    "\n",
    "\n",
    "arch = df['architecture'].iloc[-1]\n",
    "learningrate = df['learning rate'].iloc[-1]\n",
    "epochs = df['epochs'].iloc[-1]\n",
    "plt.suptitle(\n",
    "    'Comparison of volume estimates by RGI region.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "    ', Epochs: ' + df['epochs'].iloc[-1],\n",
    "    fontsize=18, y=0.95\n",
    ")\n",
    "ax.set(ylabel = 'V_Edasi / V_Farinotti', xlabel = 'RGI region')\n",
    "plt.scatter(x = dfq['dataframe'].str[4:], y = ratio)\n",
    "for i in dfq['dataframe'].index:\n",
    "    plt.text(\n",
    "        x = int(df['dataframe'].str[4:].loc[i]) - 1,\n",
    "        y = (\n",
    "            ratio.loc[i]\n",
    "        ) + 0.02,\n",
    "        s = df['dataframe'].str[4:].loc[i]\n",
    "    )\n",
    "\n",
    "# fig.savefig('figs/Vcomparison_region_' + arch + '_' + learningrate + '_' + epochs + '.png')\n",
    "# fig.savefig('figs/Vcomparison_region_' + arch + '_' + learningrate + '_' + epochs + '.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1cbea",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# volume estimates by region and trainable inputs\n",
    "\n",
    "dfq = df[[\n",
    "    'dataframe',\n",
    "    'vol',\n",
    "    'volf',\n",
    "    'ratio trainable'\n",
    "]]\n",
    "ratio = dfq.vol / dfq.volf\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (15,10))\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "plt.suptitle('Comparison of volume estimates by trainable inputs using layer architecture ' + \n",
    "    df['architecture'].iloc[-1], fontsize=18, y=0.95)\n",
    "ax.set(ylabel = 'V_Edasi / V_Farinotti', xlabel = 'Ratio of GlaThiDa glaciers in RGI')\n",
    "plt.scatter(x = dfq['ratio trainable'], y = ratio)\n",
    "\n",
    "ax.fill_between(\n",
    "    x = (\n",
    "        dfq['ratio trainable'].min(), dfq['ratio trainable'].max()\n",
    "    ),\n",
    "    y1 = 1.25,\n",
    "    y2 = 0.75,\n",
    "    facecolor = 'gray',\n",
    "    alpha = 0.2\n",
    ")\n",
    "# ax.set_xscale('log')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in dfq['dataframe'].index:\n",
    "#     plt.text(\n",
    "#         x = dfq['ratio trainable'].loc[i],\n",
    "#         y = (\n",
    "#             dfq['vol'] / dfq['volf'].loc[i]\n",
    "#         ) + 0.02,\n",
    "#         s = df['dataframe'].str[4:].loc[i]\n",
    "#     )\n",
    "# plt.semilogx()\n",
    "\n",
    "# fig.savefig('figs/Vcomparison_trainable.png')\n",
    "# fig.savefig('figs/Vcomparison_trainable.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e783b0c",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# volume estimates of RGI regions by RGI attribute mean value \n",
    "dfr = df[[\n",
    "    'Area_RGI_mean',\n",
    "    'Aspect_RGI_mean',\n",
    "    'Lmax_RGI_mean',\n",
    "    'Slope_RGI_mean',\n",
    "    'Zmax_RGI_mean',\n",
    "    'Zmin_RGI_mean'\n",
    "]]\n",
    "\n",
    "ratio = df.vol / df.volf\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Volume estimates by RGI attribute mean value.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] + \n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "for n, col in enumerate(dfr.columns):\n",
    "    ax = plt.subplot(3, 2, n + 1)\n",
    "    dfr[dfr[col] == col].plot(ax=ax)\n",
    "    \n",
    "    plt.scatter(x = dfr[col], y = ratio)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        x = (\n",
    "            dfr[col].min(), dfr[col].max()\n",
    "        ),\n",
    "        y1 = 1.25,\n",
    "        y2 = 0.75,\n",
    "        facecolor = 'gray',\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "    plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "    \n",
    "    ax.set_title(col[:-9].upper())\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_xlabel('RGI Mean ' + col[:-9])\n",
    "    ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "    \n",
    "    \n",
    "#     for i in dfr[col].index:\n",
    "#         plt.text(\n",
    "#             x = dfr[col].loc[i],\n",
    "#             y = (\n",
    "#                 df['vol'].loc[i] / df['volf'].loc[i]\n",
    "#             ) + 0.02,\n",
    "#             s = df['dataframe'].str[4:].loc[i]\n",
    "#         )\n",
    "# fig.savefig(\n",
    "#     'figs/Vcomparison_RGI_attribute_mean_' + \n",
    "#     arch + '_' + learningrate + '_' + epochs + '.png'\n",
    "# )\n",
    "# fig.savefig(\n",
    "#     'figs/Vcomparison_RGI_attribute_mean_' + \n",
    "#     arch + '_' + learningrate + '_' + epochs + '.eps'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639767b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# volume estimates of RGI regions by RGI median attribute value \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_RGI_median',\n",
    "    'Aspect_RGI_median',\n",
    "    'Lmax_RGI_median',\n",
    "    'Slope_RGI_median',\n",
    "    'Zmax_RGI_median',\n",
    "    'Zmin_RGI_median'\n",
    "]]\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Volume estimates by RGI attribute median value.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "    # add a new subplot iteratively\n",
    "    ax = plt.subplot(3, 2, n + 1)\n",
    "#     fig = plt.figure()\n",
    "    # filter df and plot ticker on the new subplot axis\n",
    "    dfr[dfr[col] == col].plot(ax=ax)\n",
    "    plt.scatter(x = dfr[col], y = ratio)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        x = (\n",
    "            dfr[col].min(), dfr[col].max()\n",
    "        ),\n",
    "        y1 = 1.25,\n",
    "        y2 = 0.75,\n",
    "        facecolor = 'gray',\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "    plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "    \n",
    "    # chart formatting\n",
    "    ax.set_title(col[:-11].upper())\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_xlabel('RGI median ' + col[:-11])\n",
    "    ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "#     plt.xscale('log')\n",
    "\n",
    "# fig.savefig('figs/Vcomparison_RGI_attribute_median_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.png'\n",
    "#            )\n",
    "# fig.savefig('figs/Vcomparison_RGI_attribute_median_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.eps'\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a824c86",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# volume estimates by GlaThiDa mean value for each attribute   \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_GlaThiDa_mean',\n",
    "    'Aspect_GlaThiDa_mean',\n",
    "    'Lmax_GlaThiDa_mean',\n",
    "    'Slope_GlaThiDa_mean',\n",
    "    'Zmax_GlaThiDa_mean',\n",
    "    'Zmin_GlaThiDa_mean'\n",
    "]]\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Volume estimates by GlaThiDa attribute mean value.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] + \n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "    # add a new subplot iteratively\n",
    "    ax = plt.subplot(3, 2, n + 1)\n",
    "#     fig = plt.figure()\n",
    "    # filter df and plot ticker on the new subplot axis\n",
    "    dfr[dfr[col] == col].plot(ax=ax)\n",
    "    plt.scatter(x = dfr[col], y = ratio)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        x = (\n",
    "            dfr[col].min(), dfr[col].max()\n",
    "        ),\n",
    "        y1 = 1.25,\n",
    "        y2 = 0.75,\n",
    "        facecolor = 'gray',\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "    plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "    \n",
    "    # chart formatting\n",
    "    ax.set_title(col[:-14].upper())\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_xlabel('GlaThiDa Mean ' + col[:-14])\n",
    "    ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "    if col == 'Area_GlaThiDa_mean':\n",
    "        plt.xscale('log')\n",
    "        \n",
    "\n",
    "# fig.savefig('figs/Vcomparison_GlaThiDa_attribute_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.png'\n",
    "#            )\n",
    "# fig.savefig('figs/Vcomparison_GlaThiDa_attribute_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.eps'\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea41747",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# volume estimates by GlaThiDa median value for each attribute\n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_GlaThiDa_median',\n",
    "    'Aspect_GlaThiDa_median',\n",
    "    'Lmax_GlaThiDa_median',\n",
    "    'Slope_GlaThiDa_median',\n",
    "    'Zmax_GlaThiDa_median',\n",
    "    'Zmin_GlaThiDa_median'\n",
    "]]\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Volume estimates by GlaThiDa attribute median value.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "    # add a new subplot iteratively\n",
    "    ax = plt.subplot(3, 2, n + 1)\n",
    "#     fig = plt.figure()\n",
    "    # filter df and plot ticker on the new subplot axis\n",
    "    dfr[dfr[col] == col].plot(ax=ax)\n",
    "    plt.scatter(x = dfr[col], y = ratio)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        x = (\n",
    "            dfr[col].min(), dfr[col].max()\n",
    "        ),\n",
    "        y1 = 1.25,\n",
    "        y2 = 0.75,\n",
    "        facecolor = 'gray',\n",
    "        alpha = 0.2\n",
    "    )\n",
    "    \n",
    "    plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "    \n",
    "    # chart formatting\n",
    "    ax.set_title(col[:-16].upper())\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_xlabel('GlaThiDa median ' + col[:-16])\n",
    "    ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "    if col[:-16] == 'Area':\n",
    "        \n",
    "        plt.xscale('log')\n",
    "\n",
    "# fig.savefig('figs/Vcomparison_GlaThiDa_median_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.png'\n",
    "#            )\n",
    "# fig.savefig('figs/Vcomparison_GlaThida_median_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.eps'\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2622498",
   "metadata": {},
   "source": [
    "# DATASET COMPARISON SCATTER PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91280aee",
   "metadata": {
    "code_folding": [
     0,
     2,
     6,
     14,
     23,
     31
    ]
   },
   "outputs": [],
   "source": [
    "# volume estimates against ratio of trainable glaciers in each region \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_RGI_mean',\n",
    "    'Aspect_RGI_mean',\n",
    "    'Lmax_RGI_mean',\n",
    "    'Slope_RGI_mean',\n",
    "    'Zmax_RGI_mean',\n",
    "    'Zmin_RGI_mean'\n",
    "]]\n",
    "dfr = dfr.rename(columns = {\n",
    "    'Area_RGI_mean':'Area',\n",
    "    'Aspect_RGI_mean':'Aspect',\n",
    "    'Lmax_RGI_mean':'Lmax',\n",
    "    'Slope_RGI_mean':'Slope',\n",
    "    'Zmax_RGI_mean':'Zmax',\n",
    "    'Zmin_RGI_mean':'Zmin'\n",
    "})\n",
    "\n",
    "dfg = df[[\n",
    "    'Area_GlaThiDa_mean',\n",
    "    'Aspect_GlaThiDa_mean',\n",
    "    'Lmax_GlaThiDa_mean',\n",
    "    'Slope_GlaThiDa_mean',\n",
    "    'Zmax_GlaThiDa_mean',\n",
    "    'Zmin_GlaThiDa_mean'\n",
    "]]\n",
    "dfg = dfg.rename(columns = {\n",
    "    'Area_GlaThiDa_mean':'Area',\n",
    "    'Aspect_GlaThiDa_mean':'Aspect',\n",
    "    'Lmax_GlaThiDa_mean':'Lmax',\n",
    "    'Slope_GlaThiDa_mean':'Slope',\n",
    "    'Zmax_GlaThiDa_mean':'Zmax',\n",
    "    'Zmin_GlaThiDa_mean':'Zmin'\n",
    "})\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Attribute comparison between GlaThiDa and RGI.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "#     print(list(dfg.columns.str[:-14]))\n",
    "    if col in list(dfg.columns):\n",
    "        \n",
    "        \n",
    "    # add a new subplot iteratively\n",
    "        ax = plt.subplot(3, 2, n + 1)\n",
    "        dfr[dfr[col] == col].plot(ax=ax)\n",
    "        plt.scatter(x = dfg[col] / dfr[col], y = ratio)\n",
    "        \n",
    "        ax.fill_between(\n",
    "            x = (\n",
    "                (dfg[col] / dfr[col]).min(), (dfg[col] / dfr[col]).max()\n",
    "            ),\n",
    "            y1 = 1.25,\n",
    "            y2 = 0.75,\n",
    "            facecolor = 'gray',\n",
    "            alpha = 0.2\n",
    "        )\n",
    "\n",
    "        plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "\n",
    "        # chart formatting\n",
    "        ax.set_title(col.upper())\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_xlabel('GlaThiDa mean / RGI mean ')\n",
    "        ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "        if col == 'Area':\n",
    "            plt.xscale('log')\n",
    "\n",
    "#         plt.semilogx()\n",
    "# fig.savefig('figs/Vcomparison_GandR_attribute_mean_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.png'\n",
    "#            )\n",
    "# fig.savefig('figs/Vcomparison_GandR_attribute_mean_' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.eps'\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ade807",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# volume estimates against median ratio of trainable glaciers by region \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_RGI_median',\n",
    "    'Aspect_RGI_median',\n",
    "    'Lmax_RGI_median',\n",
    "    'Slope_RGI_median',\n",
    "    'Zmax_RGI_median',\n",
    "    'Zmin_RGI_median'\n",
    "]]\n",
    "dfr = dfr.rename(columns = {\n",
    "    'Area_RGI_median':'Area',\n",
    "    'Aspect_RGI_median':'Aspect',\n",
    "    'Lmax_RGI_median':'Lmax',\n",
    "    'Slope_RGI_median':'Slope',\n",
    "    'Zmax_RGI_median':'Zmax',\n",
    "    'Zmin_RGI_median':'Zmin'\n",
    "})\n",
    "\n",
    "dfg = df[[\n",
    "    'Area_GlaThiDa_median',\n",
    "    'Aspect_GlaThiDa_median',\n",
    "    'Lmax_GlaThiDa_median',\n",
    "    'Slope_GlaThiDa_median',\n",
    "    'Zmax_GlaThiDa_median',\n",
    "    'Zmin_GlaThiDa_median'\n",
    "]]\n",
    "dfg = dfg.rename(columns = {\n",
    "    'Area_GlaThiDa_median':'Area',\n",
    "    'Aspect_GlaThiDa_median':'Aspect',\n",
    "    'Lmax_GlaThiDa_median':'Lmax',\n",
    "    'Slope_GlaThiDa_median':'Slope',\n",
    "    'Zmax_GlaThiDa_median':'Zmax',\n",
    "    'Zmin_GlaThiDa_median':'Zmin'\n",
    "})\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Attribute comparison between GlaThiDa and RGI.' + \n",
    "    '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "    ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "    ', Epochs: ' + df['epochs'].iloc[-1], fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "#     print(list(dfg.columns.str[:-14]))\n",
    "    if col in list(dfg.columns):\n",
    "        \n",
    "        \n",
    "    # add a new subplot iteratively\n",
    "        ax = plt.subplot(3, 2, n + 1)\n",
    "        dfr[dfr[col] == col].plot(ax=ax)\n",
    "        plt.scatter(x = dfg[col] / dfr[col], y = ratio)\n",
    "        \n",
    "        ax.fill_between(\n",
    "            x = (\n",
    "                (dfg[col] / dfr[col]).min(), (dfg[col] / dfr[col]).max()\n",
    "            ),\n",
    "            y1 = 1.25,\n",
    "            y2 = 0.75,\n",
    "            facecolor = 'gray',\n",
    "            alpha = 0.2\n",
    "        )\n",
    "\n",
    "        plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "\n",
    "        # chart formatting\n",
    "        ax.set_title(col.upper())\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_xlabel('GlaThiDa median / RGI median ')\n",
    "        ax.set_ylabel('V_Edasi / V_Farinotti')\n",
    "        if col == 'Area':\n",
    "            plt.xscale('log')\n",
    "\n",
    "#         plt.semilogx()\n",
    "# fig.savefig('figs/Vcomparison_GandR_attribute_median' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.png')\n",
    "# fig.savefig('figs/Vcomparison_GandR_attribute_median' + \n",
    "#             arch + '_' + learningrate + '_' + epochs + '.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b654bc",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GlaThiDa mean value against RGI mean value by attribute \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_RGI_mean',\n",
    "    'Aspect_RGI_mean',\n",
    "    'Lmax_RGI_mean',\n",
    "    'Slope_RGI_mean',\n",
    "    'Zmax_RGI_mean',\n",
    "    'Zmin_RGI_mean'\n",
    "]]\n",
    "dfr = dfr.rename(columns = {\n",
    "    'Area_RGI_mean':'Area',\n",
    "    'Aspect_RGI_mean':'Aspect',\n",
    "    'Lmax_RGI_mean':'Lmax',\n",
    "    'Slope_RGI_mean':'Slope',\n",
    "    'Zmax_RGI_mean':'Zmax',\n",
    "    'Zmin_RGI_mean':'Zmin'\n",
    "})\n",
    "\n",
    "dfg = df[[\n",
    "    'Area_GlaThiDa_mean',\n",
    "    'Aspect_GlaThiDa_mean',\n",
    "    'Lmax_GlaThiDa_mean',\n",
    "    'Slope_GlaThiDa_mean',\n",
    "    'Zmax_GlaThiDa_mean',\n",
    "    'Zmin_GlaThiDa_mean'\n",
    "]]\n",
    "dfg = dfg.rename(columns = {\n",
    "    'Area_GlaThiDa_mean':'Area',\n",
    "    'Aspect_GlaThiDa_mean':'Aspect',\n",
    "    'Lmax_GlaThiDa_mean':'Lmax',\n",
    "    'Slope_GlaThiDa_mean':'Slope',\n",
    "    'Zmax_GlaThiDa_mean':'Zmax',\n",
    "    'Zmin_GlaThiDa_mean':'Zmin'\n",
    "})\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "# Area = dfr['Area_GlaThiDa_mean'] / dfr['Area_RGI_mean']\n",
    "# Aspect = dfr['Aspect_GlaThiDa_mean'] / dfr['Aspect_RGI_mean']\n",
    "# Lmax = dfr['Lmax_GlaThiDa_mean'] / dfr['Lmax_RGI_mean']\n",
    "# Slope = dfr['Slope_GlaThiDa_mean'] / dfr['Slope_RGI_mean']\n",
    "# Zmax = dfr['Zmax_GlaThiDa_mean'] / dfr['Zmax_RGI_mean']\n",
    "# Zmin = dfr['Zmin_GlaThiDa_mean'] / dfr['Zmin_RGI_mean']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Attribute comparison between GlaThiDa and RGI mean', fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "#     print(list(dfg.columns.str[:-14]))\n",
    "    if col in list(dfg.columns):\n",
    "        \n",
    "        \n",
    "    # add a new subplot iteratively\n",
    "        ax = plt.subplot(3, 2, n + 1)\n",
    "        dfr[dfr[col] == col].plot(ax=ax)\n",
    "        plt.scatter(x = dfr[col], y = dfg[col])\n",
    "\n",
    "#         plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "        plt.plot(\n",
    "            (dfr[col].min(), dfr[col].max()),\n",
    "            (dfr[col].min(), dfr[col].max()),\n",
    "            '-'\n",
    "        )\n",
    "        # chart formatting\n",
    "        ax.set_title(col.upper())\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_xlabel('RGI mean ' + col)\n",
    "        ax.set_ylabel('GlaThiDa mean ' + col)\n",
    "        if col == 'Area' or col == 'Lmax':\n",
    "#             plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "# fig.savefig('figs/GlaThiDa_RGI_attribute_mean.png')\n",
    "# fig.savefig('figs/GlaThiDa_RGI_attribute_mean.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ba5d2",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GlaThiDa median value against RGI median value by attribute \n",
    "\n",
    "dfs = df[[\n",
    "    'vol',\n",
    "    'volf'\n",
    "]]\n",
    "dfr = df[[\n",
    "    'Area_RGI_median',\n",
    "    'Aspect_RGI_median',\n",
    "    'Lmax_RGI_median',\n",
    "    'Slope_RGI_median',\n",
    "    'Zmax_RGI_median',\n",
    "    'Zmin_RGI_median'\n",
    "]]\n",
    "dfr = dfr.rename(columns = {\n",
    "    'Area_RGI_median':'Area',\n",
    "    'Aspect_RGI_median':'Aspect',\n",
    "    'Lmax_RGI_median':'Lmax',\n",
    "    'Slope_RGI_median':'Slope',\n",
    "    'Zmax_RGI_median':'Zmax',\n",
    "    'Zmin_RGI_median':'Zmin'\n",
    "})\n",
    "\n",
    "dfg = df[[\n",
    "    'Area_GlaThiDa_median',\n",
    "    'Aspect_GlaThiDa_median',\n",
    "    'Lmax_GlaThiDa_median',\n",
    "    'Slope_GlaThiDa_median',\n",
    "    'Zmax_GlaThiDa_median',\n",
    "    'Zmin_GlaThiDa_median'\n",
    "]]\n",
    "dfg = dfg.rename(columns = {\n",
    "    'Area_GlaThiDa_median':'Area',\n",
    "    'Aspect_GlaThiDa_median':'Aspect',\n",
    "    'Lmax_GlaThiDa_median':'Lmax',\n",
    "    'Slope_GlaThiDa_median':'Slope',\n",
    "    'Zmax_GlaThiDa_median':'Zmax',\n",
    "    'Zmin_GlaThiDa_median':'Zmin'\n",
    "})\n",
    "ratio = dfs.vol / dfs.volf\n",
    "\n",
    "# Area = dfr['Area_GlaThiDa_median'] / dfr['Area_RGI_median']\n",
    "# Aspect = dfr['Aspect_GlaThiDa_median'] / dfr['Aspect_RGI_median']\n",
    "# Lmax = dfr['Lmax_GlaThiDa_median'] / dfr['Lmax_RGI_median']\n",
    "# Slope = dfr['Slope_GlaThiDa_median'] / dfr['Slope_RGI_median']\n",
    "# Zmax = dfr['Zmax_GlaThiDa_median'] / dfr['Zmax_RGI_median']\n",
    "# Zmin = dfr['Zmin_GlaThiDa_median'] / dfr['Zmin_RGI_median']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle('Attribute comparison between GlaThiDa and RGI median', fontsize=18, y=0.95)\n",
    "fig.patch.set_facecolor('w')\n",
    "# fig.patch.set_facecolor('w')\n",
    "# loop through the length of tickers and keep track of index\n",
    "for n, col in enumerate(dfr.columns):\n",
    "#     print(list(dfg.columns.str[:-14]))\n",
    "    if col in list(dfg.columns):\n",
    "        \n",
    "        \n",
    "    # add a new subplot iteratively\n",
    "        ax = plt.subplot(3, 2, n + 1)\n",
    "        dfr[dfr[col] == col].plot(ax=ax)\n",
    "        plt.scatter(x = dfr[col], y = dfg[col])\n",
    "\n",
    "#         plt.axhline(y = 1.00, color = 'red', linestyle = '--')\n",
    "        plt.plot(\n",
    "            (dfr[col].min(), dfr[col].max()),\n",
    "            (dfr[col].min(), dfr[col].max()),\n",
    "            '-'\n",
    "        )\n",
    "        # chart formatting\n",
    "        ax.set_title(col.upper())\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_xlabel('RGI median ' + col)\n",
    "        ax.set_ylabel('GlaThiDa median ' + col)\n",
    "        if col == 'Area' or col == 'Lmax':\n",
    "#             plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "# fig.savefig('figs/GlaThiDa_RGI_attribute_median.png')\n",
    "# fig.savefig('figs/GlaThiDa_RGI_attribute_median.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127b6ca",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# iqr against median plots for each reagion\n",
    "training_data = gl.data_loader()\n",
    "training_data = training_data[[\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmax'\n",
    "    \n",
    "]]\n",
    "arch = df['architecture'].iloc[-1]\n",
    "\n",
    "q3, q1 = np.percentile(training_data,[75, 25], axis = 0)\n",
    "iqr = q3 - q1\n",
    "medians = np.median(training_data,axis=0)\n",
    "iqr.shape\n",
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.suptitle(\n",
    "    'Comparisons of medians and IQR using architecture using architecture ' + arch,\n",
    "    fontsize=18, y=0.95\n",
    ")\n",
    "for n, i in enumerate(range(0, 6)):\n",
    "    ax = plt.subplot(3, 2, n + 1)\n",
    "    col_name = training_data.columns[i]\n",
    "    \n",
    "    plt.plot(iqr[i],medians[i],'*')\n",
    "    plt.scatter(\n",
    "        df[col_name + '_RGI_iqr'],\n",
    "        df[col_name + '_RGI_median'],\n",
    "        marker = 's',\n",
    "        c = df['voldiff'],\n",
    "        cmap = 'viridis'\n",
    "    )\n",
    "    ax.set_xlabel(col_name + ' IQR')\n",
    "    ax.set_ylabel(col_name + ' Median')\n",
    "    ax.set_title(col_name + ' IQR against Median ' + col_name)\n",
    "    plt.plot((df[col_name + '_RGI_iqr'].min(),df[col_name + '_RGI_iqr'].max()),np.median(\n",
    "        df[col_name + '_RGI_iqr']) * np.array((1,1))\n",
    "    )\n",
    "    \n",
    "    plt.plot(\n",
    "        np.median(df[col_name + '_RGI_iqr']) * np.array((1,1)),\n",
    "        (df[col_name + '_RGI_iqr'].min(),df[col_name + '_RGI_median'].max())\n",
    "    )\n",
    "    for i in df.index:\n",
    "        plt.text(\n",
    "            x = df[col_name + '_RGI_iqr'].loc[i] + 0.02,\n",
    "            y = (\n",
    "                df[col_name + '_RGI_median'].loc[i]) + 0.02,\n",
    "            s = df['dataframe'].str[4:].loc[i] \n",
    "        )\n",
    "# plt.savefig(\n",
    "#     'figs/iqr_median' + \n",
    "#     arch + '.eps'\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.savefig(\n",
    "#     'figs/iqr_median_' + \n",
    "#     arch + '.png'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811fc2f",
   "metadata": {},
   "source": [
    "# HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16be54",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# histogram of each RGI region with GlaThiDa overlay but with diff order and statistics \n",
    "\n",
    "\n",
    "arch = df['architecture'].iloc[-1]\n",
    "\n",
    "pth = '/data/fast1/glacierml/data/RGI/rgi60-attribs/'\n",
    "pth_2 = '/data/fast1/glacierml/data/regional_data/raw/'\n",
    "# Plot RGI areas first\n",
    "\n",
    "attribute_list = [\n",
    "    'Area',\n",
    "#     'Aspect',\n",
    "    'Lmax',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmax'\n",
    "]\n",
    "for attribute in attribute_list:\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    # plt.suptitle('Attribute comparison between GlaThiDa and RGI', fontsize=18, y=0.95)\n",
    "    fig.patch.set_facecolor('w')\n",
    "    plt.suptitle(\n",
    "        'Histograms of ' + attribute + \n",
    "        ' in GlaThiDa and RGI by region.' + \n",
    "        '\\nLayer Architecture: ' + df['architecture'].iloc[-1] +\n",
    "        ', Learning Rate: ' + df['learning rate'].iloc[-1] +\n",
    "        ', Epochs: ' + df['epochs'].iloc[-1], \n",
    "        fontsize=18, y=0.95\n",
    "    )    \n",
    "    for n, index in (enumerate(df['voldiff'].sort_values(ascending = True).index )):\n",
    "    #     print(index)\n",
    "    #     print(df['dataframe'].loc[index])\n",
    "\n",
    "        for rgi_file in (os.listdir(pth)):\n",
    "            region_number = rgi_file[:2]\n",
    "\n",
    "            if region_number == df['dataframe'].str[4:].loc[index]:\n",
    "\n",
    "                file_reader = pd.read_csv(\n",
    "                    pth + rgi_file, \n",
    "                    encoding_errors = 'replace', \n",
    "                    on_bad_lines = 'skip'\n",
    "                )\n",
    "                file_reader.dropna()\n",
    "                file_reader[file_reader[attribute] == 0 ] = 0.0001\n",
    "                ax = plt.subplot(4, 5, n + 1)\n",
    "\n",
    "                vol_index = df[df['dataframe'].str[4:] == region_number].index\n",
    "                vol_edasi = df['vol'].loc[vol_index].values\n",
    "                vol_farinotti = df['volf'].loc[vol_index].values\n",
    "\n",
    "                vol_ratio = vol_edasi / vol_farinotti\n",
    "\n",
    "                plt.hist(\n",
    "                            np.log10(file_reader[attribute]), \n",
    "                            bins = 25,\n",
    "                            label = 'RGI ' + attribute, \n",
    "                            alpha = 0.5, \n",
    "                            color = 'red',\n",
    "                            density = True,\n",
    "                            edgecolor = 'black'\n",
    "            #                 log = True\n",
    "                )\n",
    "\n",
    "                ax.set_title('RGI region ' + region_number + \n",
    "                             '\\n V_E / V_F: ' + \n",
    "                             str(vol_ratio) +\n",
    "                             '\\n V_E - V_F: ' +\n",
    "                             str(df['voldiff'].loc[index])\n",
    "                )\n",
    "\n",
    "                # open up matching GlaThiDa file and plot those areas\n",
    "                for glathida_file in os.listdir(pth_2):\n",
    "                    if glathida_file[:2] == region_number:\n",
    "\n",
    "                        g_reg = pd.read_csv(pth_2 + glathida_file)\n",
    "                        g_reg.dropna()\n",
    "                        g_reg[g_reg[attribute] == 0 ] = 0.0001\n",
    "                        q1 = g_reg[attribute].quantile(q = 0.25)\n",
    "                        q3 = g_reg[attribute].quantile(q = 0.75)\n",
    "                        iqr = q3 - q1\n",
    "\n",
    "                        if len(g_reg) == 1:\n",
    "                            bin_width = 1\n",
    "                            bin_count = 1\n",
    "            #                 print('bin width = ' + bin_width.type())\n",
    "\n",
    "                        elif len(g_reg) > 1:\n",
    "                            bin_width = (2 * iqr) / (len(g_reg) ** (1 / 3))\n",
    "    #                         print(bin_width)\n",
    "    #                         bin_width = min(bin_width, 50)\n",
    "            #                 print('bin count = ' + bin_count)\n",
    "                            bin_count = int(\n",
    "                                    np.ceil(\n",
    "                                        (\n",
    "                                            g_reg[attribute].max() - g_reg[attribute].min()\n",
    "                                        ) / bin_width\n",
    "                                    )\n",
    "                            )\n",
    "                        plt.hist(\n",
    "                            np.log10(g_reg[attribute]), \n",
    "                            bins = bin_count,\n",
    "                            label = 'GlaThiDa ' + attribute, \n",
    "                            alpha = 0.5, \n",
    "                            color = 'green',\n",
    "                            density = True,\n",
    "                            edgecolor = 'black'\n",
    "            #                 log = True\n",
    "                        )\n",
    "\n",
    "            #             ax.set_xlabel('xlabel')\n",
    "            #             ax.set_ylabel('ylabel')\n",
    "#     plt.savefig('figs/histogram_' + attribute + '_' + \n",
    "#                 arch + '_' + learningrate + '_' + epochs + '.png')\n",
    "#     plt.savefig('figs/histogram_' + attribute + '_' + \n",
    "#                 arch + '_' + learningrate + '_' + epochs + '.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1e499",
   "metadata": {},
   "source": [
    "# CLUSTER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c52a8",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### KMeans elbow plot for RGI at fegion scale \n",
    "\n",
    "\n",
    "stat_list = [\n",
    "    'mean',\n",
    "    'median',\n",
    "    'std',\n",
    "    'iqr'\n",
    "]\n",
    "for statistic in stat_list:\n",
    "    stat = statistic\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,20))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    fig.patch.set_facecolor('w')\n",
    "    dft = df[[\n",
    "        'Area_RGI_' + stat,\n",
    "        'Aspect_RGI_' + stat,\n",
    "        'Lmax_RGI_' + stat,\n",
    "        'Slope_RGI_'+ stat,\n",
    "        'Zmin_RGI_' + stat,\n",
    "        'Zmax_RGI_' + stat\n",
    "    ]]   \n",
    "\n",
    "    dft = dft.rename(columns = {\n",
    "        'Area_RGI_' + stat:'Area',\n",
    "        'Aspect_RGI_' + stat:'Aspect',\n",
    "        'Lmax_RGI_' + stat:'Lmax',\n",
    "        'Slope_RGI_' + stat:'Slope',\n",
    "        'Zmin_RGI_' + stat:'Zmin',\n",
    "        'Zmax_RGI_' + stat:'Zmax'\n",
    "    })\n",
    "    # ELBOW PLOT START\n",
    "\n",
    "    x = dft.iloc[:,[0,1]]\n",
    "    distortions = []\n",
    "    K = range(1,10)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters = k)\n",
    "        kmeanModel.fit(x)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.suptitle(\n",
    "        'The Elbow Method showing the optimal clusters for ' + stat, \n",
    "        fontsize=18, y=0.95)\n",
    "\n",
    "# ELBOW PLOT END\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05959cba",
   "metadata": {
    "code_folding": [
     0,
     3,
     11
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot Kmeans for RGI regions by statstical value comparing attributes \n",
    "# cannot show centroids because it won't work for reasons I do not know just yet\n",
    "\n",
    "dft_list = [\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmax'\n",
    "]\n",
    "stat_list = [\n",
    "    'mean',\n",
    "    'median',\n",
    "    'std',\n",
    "    'iqr'\n",
    "]\n",
    "\n",
    "for statistic in tqdm(stat_list):\n",
    "    stat = statistic\n",
    "\n",
    "\n",
    "\n",
    "    dft = df[[\n",
    "        'Area_RGI_' + stat,\n",
    "        'Aspect_RGI_' + stat,\n",
    "        'Lmax_RGI_' + stat,\n",
    "        'Slope_RGI_'+ stat,\n",
    "        'Zmin_RGI_' + stat,\n",
    "        'Zmax_RGI_' + stat\n",
    "    ]]   \n",
    "\n",
    "    dft = dft.rename(columns = {\n",
    "        'Area_RGI_' + stat:'Area',\n",
    "        'Aspect_RGI_' + stat:'Aspect',\n",
    "        'Lmax_RGI_' + stat:'Lmax',\n",
    "        'Slope_RGI_' + stat:'Slope',\n",
    "        'Zmin_RGI_' + stat:'Zmin',\n",
    "        'Zmax_RGI_' + stat:'Zmax'\n",
    "    })\n",
    "\n",
    "    if statistic == 'mean':\n",
    "        chosen_n = 7\n",
    "    if statistic == 'median':\n",
    "        chosen_n = 4\n",
    "    if statistic == 'std':\n",
    "        chosen_n = 5\n",
    "    if statistic == 'iqr':\n",
    "        chosen_n = 3\n",
    "        \n",
    "    kmeans = KMeans(n_clusters = chosen_n, random_state = 0)\n",
    "    dft[stat] = kmeans.fit_predict(dft)\n",
    "    residuals[stat] = dft[stat]\n",
    "\n",
    "\n",
    "    for attribute in dft_list:\n",
    "    \n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize = (20,20))\n",
    "        fig.patch.set_facecolor('w')\n",
    "        plt.suptitle(\n",
    "            'Cluster Analysis of RGI ' + attribute + ' ' + stat + \n",
    "            ' against RGI Attribute ' + stat, \n",
    "            fontsize=18, y=0.95\n",
    "        )\n",
    "\n",
    "        for n, att in enumerate(dft_list):\n",
    "            ax = plt.subplot(3,2,n+1)\n",
    "\n",
    "            plt.scatter(\n",
    "                dft[attribute],\n",
    "                dft[att],\n",
    "                c = dft[stat], \n",
    "                cmap = 'viridis',\n",
    "                alpha = 1, \n",
    "                marker = 'o'\n",
    "\n",
    "            )\n",
    "            ax.set_xlabel('RGI ' + stat + ' ' + attribute)\n",
    "            ax.set_ylabel('RGI ' + stat + ' ' + att)\n",
    "            ax.set_title('RGI ' + stat + ' ' + attribute + ' against ' + stat + ' '+ att )\n",
    "\n",
    "\n",
    "            for i in df.index:\n",
    "                plt.text(\n",
    "                    x = dft[attribute].loc[i] + 0.02,\n",
    "                    y = (\n",
    "                        dft[att].loc[i]) + 0.02,\n",
    "                    s = df['dataframe'].str[4:].loc[i] + '-' + str(dft[stat].loc[i])\n",
    "                )\n",
    "#             plt.savefig(\n",
    "#                 'figs/cluster_analysis_' + \n",
    "#                 attribute + '_' + stat + '.eps'\n",
    "#             )\n",
    "            \n",
    "            \n",
    "#             plt.savefig(\n",
    "#                 'figs/cluster_analysis_' + \n",
    "#                 attribute + '_' + stat + '.png'\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71fd5b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#### KMeans elbow plot for RGI statistiscs at region scale comparing statistics\n",
    "\n",
    "\n",
    "att_list = [\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmax'\n",
    "]\n",
    "for attribute in att_list:\n",
    "    dft = df[[\n",
    "        attribute + '_RGI_mean',\n",
    "        attribute + '_RGI_median',\n",
    "        attribute + '_RGI_std',\n",
    "        attribute + '_RGI_iqr',\n",
    "        \n",
    "    ]]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,20))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    fig.patch.set_facecolor('w')\n",
    "    \n",
    "    # ELBOW PLOT START\n",
    "\n",
    "    x = dft.iloc[:,[0,1]]\n",
    "    distortions = []\n",
    "    K = range(1,10)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters = k)\n",
    "        kmeanModel.fit(x)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.suptitle(\n",
    "        'The Elbow Method showing the optimal clusters for ' + attribute, \n",
    "        fontsize=18, y=0.95)\n",
    "\n",
    "# ELBOW PLOT END\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12714f2",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot Kmeans for RGI regions by attribute comparing statistics \n",
    "# cannot show centroids because it won't work for reasons I do not know just yet\n",
    "stat_list = [\n",
    "    'mean',\n",
    "    'median',\n",
    "    'std',\n",
    "    'iqr'\n",
    "]\n",
    "\n",
    "att_list = [\n",
    "    'Area',\n",
    "    'Aspect',\n",
    "    'Lmax',\n",
    "    'Slope',\n",
    "    'Zmin',\n",
    "    'Zmax'\n",
    "]\n",
    "for i in att_list:\n",
    "    dft = df[[\n",
    "        i + '_RGI_mean',\n",
    "        i + '_RGI_median',\n",
    "        i + '_RGI_std',\n",
    "        i + '_RGI_iqr',\n",
    "        \n",
    "    ]]\n",
    "    \n",
    "    dft = dft.rename(columns = {\n",
    "        i + '_RGI_mean':'mean',\n",
    "        i + '_RGI_median':'median',\n",
    "        i + '_RGI_std':'std',\n",
    "        i + '_RGI_iqr':'iqr',\n",
    "    })\n",
    "    if i == 'Area':\n",
    "        chosen_n =  3\n",
    "    if i == 'Aspect':\n",
    "        chosen_n =  4\n",
    "    if i == 'Lmax':\n",
    "        chosen_n =  4\n",
    "    if i == 'Slope':\n",
    "        chosen_n =  6\n",
    "    if i == 'Zmin':\n",
    "        chosen_n = 4                      \n",
    "    if i == 'Zmax':\n",
    "        chosen_n =  4\n",
    "                     \n",
    "                     \n",
    "    kmeans = KMeans(n_clusters = chosen_n, random_state = 0)\n",
    "    dft['cluster'] = kmeans.fit_predict(dft)\n",
    "#     residuals[i] = dft[i]\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,20))\n",
    "    fig.patch.set_facecolor('w')\n",
    "    plt.suptitle(\n",
    "        'Cluster Analysis of RGI ' + i + ' statistics', \n",
    "        fontsize=18, y=0.95\n",
    "    )\n",
    "\n",
    "    for n, stat in enumerate(stat_list):\n",
    "        ax = plt.subplot(2,2,n+1)\n",
    "\n",
    "        plt.scatter(\n",
    "            dft['mean'],\n",
    "            dft[stat],\n",
    "            c = dft['cluster'], \n",
    "            cmap = 'viridis',\n",
    "            alpha = 1, \n",
    "            marker = 'o'\n",
    "\n",
    "        )\n",
    "        ax.set_xlabel('RGI mean ' + ' ' + i)\n",
    "        ax.set_ylabel('RGI ' + stat + ' ' + i)\n",
    "        ax.set_title('RGI mean ' + i + ' against ' + stat + ' '+ i )\n",
    "#         print(dft['cluster'])\n",
    "\n",
    "        for j in (df.index):\n",
    "            plt.text(\n",
    "                x = dft['mean'].loc[j] + 0.02,\n",
    "                y = (\n",
    "                    dft[stat].loc[j]) + 0.02,\n",
    "                s = df['dataframe'].str[4:].loc[j] +\n",
    "                 '-' + str(dft['cluster'].loc[j])\n",
    "            )\n",
    "#         plt.savefig(\n",
    "#             'figs/cluster_analysis_' + \n",
    "#             i + '_' + 'statistics' + '.eps'\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         plt.savefig(\n",
    "#             'figs/cluster_analysis_' + \n",
    "#             i + '_' + 'statistics' + '.png'\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30912c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccccombo_breaker()\n",
    "# past this point is under construction. \n",
    "# here be monsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee561925",
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns density plot\n",
    "sns.set(rc={\"figure.figsize\":(15,10)})\n",
    "sns.kdeplot(x = test_labels, y = y.flatten(),fill = True)\n",
    "plt.plot((0,300),(0,300),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cb050",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# not enough data to verify physical models from just data perspective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
