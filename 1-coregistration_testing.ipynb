{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563ee1f5",
   "metadata": {},
   "source": [
    "## Import dependancies and set environment determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4b08c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 21:32:18.214843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "#     tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    0\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEED = 378\n",
    "# SEED = 123\n",
    "print(SEED)\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ec4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfc7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isdir(res_dir) == False:\n",
    "\n",
    "def run_model(model_path,l1,l2,loss = 'mae'):\n",
    "            \n",
    "    normalizer = preprocessing.Normalization(axis=-1)\n",
    "    normalizer.adapt(np.array(trfeat))\n",
    "\n",
    "    model = gl.build_dnn_model(\n",
    "        normalizer, learning_rate = 0.01, \n",
    "        layer_1 = l1, layer_2 = l2,loss = loss\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        trfeat,\n",
    "        trlabs,\n",
    "        validation_split=0.2,\n",
    "        callbacks = [callback],\n",
    "        verbose=0, \n",
    "        epochs=500\n",
    "    )\n",
    "    model_filename = os.path.join(model_path)\n",
    "    model.save(model_filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6765b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.001,\n",
    "    patience = 10,\n",
    "    verbose = 0,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda3181e-594b-4cad-a8ea-30147ee85f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home_path = '/home/simonhans/glacierml'\n",
    "[\n",
    "        data_path, RGI_path, glathida_path, \n",
    "        coregistration_testing_path, \n",
    "        arch_test_path, LOO_path\n",
    "] = gl.set_paths(home_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f7b832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 21:32:20.825604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-22 21:32:20.825627: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-22 21:32:23.628009: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coregistration 1 predicted RGI\n",
      "Coregistration 2 predicted RGI\n",
      "Coregistration 3 predicted RGI\n",
      "Coregistration 4 predicted RGI\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5,1):\n",
    "#     l1 = 8\n",
    "#     l2 = 5\n",
    "    if i == 1:\n",
    "        l1 = 10\n",
    "        l2 = 5\n",
    "        \n",
    "    if i == 2:\n",
    "        l1 = 8\n",
    "        l2 = 2\n",
    "        \n",
    "    if i == 3:\n",
    "        l1 = 9\n",
    "        l2 = 5\n",
    "        \n",
    "    if i == 4:\n",
    "        l1 = 6\n",
    "        l2 = 2\n",
    "    set_global_determinism(seed=SEED)\n",
    "    df = gl.coregister_data(data_path,str(i))\n",
    "    df = df[[\n",
    "        'RGIId','CenLon','CenLat','Area','Zmin','Zmed','Zmax',\n",
    "        'Slope','Aspect','Lmax','Thickness'\n",
    "    ]]\n",
    "    df = df.sample(frac = 1,random_state = 0)\n",
    "    df = df.reset_index().drop('index', axis = 1)\n",
    "    # df = df[list(df)[:-7]]\n",
    "    trfeat, tefeat, trlabs, telabs = gl.split_data(df)\n",
    "    \n",
    "\n",
    "    model = {}\n",
    "    model_history = {}\n",
    "    normalizer = {}\n",
    "    model_path = os.path.join(\n",
    "        coregistration_testing_path, str(i)\n",
    "    )\n",
    "    model = run_model(model_path,l1,l2)\n",
    "    \n",
    "    rgi_est_pth = os.path.join(model_path, 'rgi_est_raw.pkl')\n",
    "\n",
    "    if os.path.isdir(rgi_est_pth) == False:\n",
    "\n",
    "        RGI = gl.load_RGI(RGI_path)\n",
    "#         RGI['Lmax'] = RGI['Lmax'] / 1e3\n",
    "        rfp = RGI[list(df)[:-1]]\n",
    "\n",
    "        preds = pd.Series(\n",
    "            model.predict(rfp.drop('RGIId',axis = 1)).flatten(), name = i\n",
    "        )\n",
    "        RGI = pd.concat([RGI,preds], axis = 1)\n",
    "        RGI.to_pickle(rgi_est_pth)\n",
    "        print(f'Coregistration {i} predicted RGI')\n",
    "                # RGI = pd.read_pickle('rgi_est_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2bd15-4482-4dce-8394-66ca7ec8329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7.11",
   "language": "python",
   "name": "prethicktor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
