{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install ing_theme_matplotlib\n",
    "# import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import qbstyles\n",
    "from ing_theme_matplotlib import mpl_style\n",
    "# import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Organize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load and organize the Glathida dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GlaThiDa_ID',\n",
       " 'POLITICAL_UNIT',\n",
       " 'GLACIER_NAME',\n",
       " 'SURVEY_DATE',\n",
       " 'PROFILE_ID',\n",
       " 'POINT_ID',\n",
       " 'POINT_LAT',\n",
       " 'POINT_LON',\n",
       " 'ELEVATION',\n",
       " 'THICKNESS',\n",
       " 'THICKNESS_UNCERTAINTY',\n",
       " 'DATA_FLAG',\n",
       " 'REMARKS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(TTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = pd.read_csv('/data/fast0/datasets/glathida-3.1.0/data/T.csv')\n",
    "TTT = pd.read_csv('/home/sa42/data/glac/T_models/TTT.csv')\n",
    "TTT = TTT[[\n",
    "    'POINT_LAT',\n",
    "    'POINT_LON',\n",
    "    'ELEVATION',\n",
    "    'THICKNESS'\n",
    "]]\n",
    "glathida = TTT\n",
    "glathida = glathida.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate out features - what will be trained to predict desired attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POINT_LAT</th>\n",
       "      <td>47.477816</td>\n",
       "      <td>53.238428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POINT_LON</th>\n",
       "      <td>-46.458083</td>\n",
       "      <td>45.484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATION</th>\n",
       "      <td>1175.033891</td>\n",
       "      <td>937.446613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean         std\n",
       "POINT_LAT    47.477816   53.238428\n",
       "POINT_LON   -46.458083   45.484560\n",
       "ELEVATION  1175.033891  937.446613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = glathida.sample(frac=0.8, random_state=0)\n",
    "test_dataset = glathida.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "#define label - attribute training to be picked\n",
    "train_labels = train_features.pop(\"THICKNESS\")\n",
    "test_labels = test_features.pop(\"THICKNESS\")\n",
    "\n",
    "train_features.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Setup the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 15:43:05.649166: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-18 15:43:05.649359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sermeq.ess.washington.edu): /proc/driver/nvidia/version does not exist\n",
      "2022-03-18 15:43:05.649991: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "normalizer = {}\n",
    "variable_list = list(train_features)\n",
    "for variable_name in variable_list:\n",
    "\n",
    "    normalizer[variable_name] = preprocessing.Normalization(input_shape=[1,], axis=None)\n",
    "    normalizer[variable_name].adapt(np.array(train_features[variable_name]))\n",
    "    \n",
    "    \n",
    "normalizer['ALL'] = preprocessing.Normalization(axis=-1)\n",
    "normalizer['ALL'].adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single variable linear regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glacierml\n",
    "\n",
    "def build_linear_model(normalizer):\n",
    "    model = tf.keras.Sequential([\n",
    "        normalizer,\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "        loss='mean_absolute_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_single_model_variable(x, y,feature_name):\n",
    "    plt.scatter(train_features[feature_name], train_labels, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Avg Thickness (m)')\n",
    "#     plt.xlim((0,20))\n",
    "    plt.legend()\n",
    "      \n",
    "def plot_loss(history):\n",
    "#     plt.subplots(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #   plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "linear_model = {}\n",
    "linear_history = {}\n",
    "linear_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for variable_name in variable_list:\n",
    "\n",
    "    linear_model[variable_name] = build_linear_model(normalizer[variable_name])\n",
    "    linear_history[variable_name] = linear_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=1000,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    \n",
    "    \n",
    "    linear_results[variable_name] = linear_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)\n",
    "\n",
    "linear_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:    \n",
    "    df = pd.DataFrame(linear_history[variable_name].history)\n",
    "    dfs = df.loc[[df.last_valid_index()]]\n",
    "    dfs.insert(0, 'Variable', [variable_name])\n",
    "    \n",
    "    print(dfs)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ing_theme_matplotlib import mpl_style\n",
    " \n",
    "def plot(dark):\n",
    "  mpl_style(dark)\n",
    "  plt.plot([1, 3, 9, 5, 2, 1, 1], marker='o')\n",
    "  plt.plot([4, 5, 5, 7, 9, 8, 6], marker='o')\n",
    " \n",
    "  plt.show()\n",
    " \n",
    "plot(dark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,6,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    mpl_style(\"dark\")\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plot_loss(linear_history[variable_name])\n",
    "    ax.set_title(variable_name)\n",
    "#     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = build_linear_model(normalizer['ALL'])\n",
    "\n",
    "history_full = linear_model.fit(\n",
    "train_features, train_labels,        \n",
    "   epochs=1000,\n",
    "   verbose=0,\n",
    "   validation_split = 0.2)\n",
    "\n",
    "test_results['MULTI'] = linear_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history_full.history)\n",
    "dfs = df.loc[[df.last_valid_index()]]\n",
    "dfs.insert(0, 'Variable', 'Multi-Variable')\n",
    "    \n",
    "print(dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_full)\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_full_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model(norm):\n",
    "    model = keras.Sequential([\n",
    "              norm,\n",
    "              layers.Dense(64, activation='relu'),\n",
    "              layers.Dense(64, activation='relu'),\n",
    "              layers.Dense(1) ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def dnn_test_results(feature_name):\n",
    "    dnn_test_results[feature_name] = dnn_model.evaluate(\n",
    "        test_features[feature_name],\n",
    "        test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "dnn_model = {}\n",
    "dnn_history = {}\n",
    "dnn_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:\n",
    "\n",
    "    dnn_model[variable_name] = build_dnn_model(normalizer[variable_name])\n",
    "    dnn_history[variable_name] = dnn_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=1000,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    dnn_results[variable_name] = dnn_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)\n",
    "\n",
    "dnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:    \n",
    "    df = pd.DataFrame(dnn_history[variable_name].history)\n",
    "    dfs = df.loc[[df.last_valid_index()]]\n",
    "    dfs.insert(0, 'Variable', [variable_name])\n",
    "    \n",
    "    print(dfs)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    xmax = np.max(train_features[variable_name])\n",
    "    xmin = np.min(train_features[variable_name])\n",
    "    x = tf.linspace(xmin, xmax, 101)\n",
    "    y = dnn_model[variable_name].predict(x)\n",
    "    plot_single_model_variable(x,y,variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plot_loss(dnn_history[variable_name])\n",
    "    ax.set_title(variable_name)\n",
    "#     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_full_model = build_dnn_model(normalizer['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dnn_history_full = dnn_full_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dnn_history_full.history)\n",
    "dfs = df.loc[[df.last_valid_index()]]\n",
    "dfs.insert(0, 'Variable', 'Multi-Variable')\n",
    "    \n",
    "print(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(dnn_history_full)\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_full_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dnn_full_model.predict(test_features)\n",
    "plt.plot(test_labels,y,'.')\n",
    "plt.plot((0,200),(0,200),'-')\n",
    "plt.xlabel('True Thickness (m)')\n",
    "plt.ylabel('Model Thickness (m)')\n",
    "plt.xlim((0,200))\n",
    "plt.ylim((0,200))\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_res.EPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (Cartopy)-f",
   "language": "python",
   "name": "python-cartopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
