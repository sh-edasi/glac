{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install ing_theme_matplotlib\n",
    "# import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import qbstyles\n",
    "from ing_theme_matplotlib import mpl_style\n",
    "# import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Organize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load and organize the Glathida dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlaThiDa_ID</th>\n",
       "      <th>GLACIER_DB</th>\n",
       "      <th>GLACIER_ID</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>AREA</th>\n",
       "      <th>MEAN_SLOPE</th>\n",
       "      <th>MEAN_THICKNESS</th>\n",
       "      <th>MAXIMUM_THICKNESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2093</td>\n",
       "      <td>RGI</td>\n",
       "      <td>16.00532</td>\n",
       "      <td>-16.302300</td>\n",
       "      <td>-68.106400</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2075</td>\n",
       "      <td>RGI</td>\n",
       "      <td>07.00428</td>\n",
       "      <td>78.185100</td>\n",
       "      <td>18.206400</td>\n",
       "      <td>39.9600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2076</td>\n",
       "      <td>RGI</td>\n",
       "      <td>07.00409</td>\n",
       "      <td>78.107100</td>\n",
       "      <td>17.697800</td>\n",
       "      <td>28.5900</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2085</td>\n",
       "      <td>RGI</td>\n",
       "      <td>10.00353</td>\n",
       "      <td>47.065194</td>\n",
       "      <td>85.563635</td>\n",
       "      <td>3.0780</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2096</td>\n",
       "      <td>RGI</td>\n",
       "      <td>13.31537</td>\n",
       "      <td>38.214000</td>\n",
       "      <td>99.881000</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>6619</td>\n",
       "      <td>RGI</td>\n",
       "      <td>01.13696</td>\n",
       "      <td>60.177000</td>\n",
       "      <td>-140.428000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>6620</td>\n",
       "      <td>RGI</td>\n",
       "      <td>01.14479</td>\n",
       "      <td>60.691000</td>\n",
       "      <td>-141.391000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>6621</td>\n",
       "      <td>RGI</td>\n",
       "      <td>01.14683</td>\n",
       "      <td>60.329000</td>\n",
       "      <td>-141.716000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>6622</td>\n",
       "      <td>RGI</td>\n",
       "      <td>01.23641</td>\n",
       "      <td>60.606705</td>\n",
       "      <td>-143.137146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>6623</td>\n",
       "      <td>RGI</td>\n",
       "      <td>01.23649</td>\n",
       "      <td>60.102000</td>\n",
       "      <td>-140.884000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4446 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GlaThiDa_ID GLACIER_DB GLACIER_ID        LAT         LON     AREA  \\\n",
       "522          2093        RGI   16.00532 -16.302300  -68.106400   0.3097   \n",
       "585          2075        RGI   07.00428  78.185100   18.206400  39.9600   \n",
       "586          2076        RGI   07.00409  78.107100   17.697800  28.5900   \n",
       "595          2085        RGI   10.00353  47.065194   85.563635   3.0780   \n",
       "605          2096        RGI   13.31537  38.214000   99.881000   0.5368   \n",
       "...           ...        ...        ...        ...         ...      ...   \n",
       "5128         6619        RGI   01.13696  60.177000 -140.428000      NaN   \n",
       "5129         6620        RGI   01.14479  60.691000 -141.391000      NaN   \n",
       "5130         6621        RGI   01.14683  60.329000 -141.716000      NaN   \n",
       "5131         6622        RGI   01.23641  60.606705 -143.137146      NaN   \n",
       "5132         6623        RGI   01.23649  60.102000 -140.884000      NaN   \n",
       "\n",
       "      MEAN_SLOPE  MEAN_THICKNESS  MAXIMUM_THICKNESS  \n",
       "522         21.0            22.0               48.0  \n",
       "585          3.0            85.0              285.0  \n",
       "586          3.0            74.0              212.0  \n",
       "595         17.0            23.0              122.0  \n",
       "605         24.0            16.0               66.0  \n",
       "...          ...             ...                ...  \n",
       "5128         NaN             NaN                NaN  \n",
       "5129         NaN             NaN                NaN  \n",
       "5130         NaN             NaN                NaN  \n",
       "5131         NaN             NaN                NaN  \n",
       "5132         NaN             NaN                NaN  \n",
       "\n",
       "[4446 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_dataset = pd.read_csv('/data/fast0/datasets/glathida-3.1.0/data/T.csv')\n",
    "raw_dataset = pd.read_csv('~/data/glac/T_models/T.csv')\n",
    "glathida = raw_dataset.copy()\n",
    "glathida = glathida.drop([\n",
    "#     'GlaThiDa_ID'\n",
    "#     'GLACIER_DB',\n",
    "#     'GLACIER_ID',\n",
    "    'POLITICAL_UNIT',\n",
    "    'GLACIER_NAME',\n",
    "    'SURVEY_DATE',\n",
    "#     'MAXIMUM_THICKNESS',\n",
    "    'MAX_THICKNESS_UNCERTAINTY',\n",
    "    'DATA_FLAG',\n",
    "    'ELEVATION_DATE',\n",
    "    'SPONSORING_AGENCY',\n",
    "    'REMARKS',\n",
    "    'SURVEY_METHOD_DETAILS',\n",
    "    'SURVEY_METHOD',\n",
    "    'NUMBER_OF_SURVEY_POINTS',\n",
    "    'NUMBER_OF_SURVEY_PROFILES',\n",
    "    'TOTAL_LENGTH_OF_SURVEY_PROFILES',\n",
    "    'INTERPOLATION_METHOD',\n",
    "    'INVESTIGATOR', \n",
    "    'REFERENCES',\n",
    "    'MEAN_THICKNESS_UNCERTAINTY'\n",
    "], axis=1)\n",
    "\n",
    "# filter data by searching for specific entries\n",
    "idx = glathida.index[glathida['GLACIER_DB'] == 'RGI']\n",
    "glathida = glathida.loc[idx]\n",
    "\n",
    "# ignore RGI version, e.g. RGI60\n",
    "glathida['GLACIER_ID'] = glathida['GLACIER_ID'].str[6:]\n",
    "glathida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Load and Organize the RGI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa42/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07.00001</td>\n",
       "      <td>17.0347</td>\n",
       "      <td>76.7052</td>\n",
       "      <td>0.597</td>\n",
       "      <td>142</td>\n",
       "      <td>459</td>\n",
       "      <td>268</td>\n",
       "      <td>16.7</td>\n",
       "      <td>204</td>\n",
       "      <td>1388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.00002</td>\n",
       "      <td>16.1891</td>\n",
       "      <td>76.7872</td>\n",
       "      <td>0.581</td>\n",
       "      <td>234</td>\n",
       "      <td>582</td>\n",
       "      <td>343</td>\n",
       "      <td>18.3</td>\n",
       "      <td>277</td>\n",
       "      <td>1658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.00003</td>\n",
       "      <td>16.3915</td>\n",
       "      <td>76.9194</td>\n",
       "      <td>0.388</td>\n",
       "      <td>157</td>\n",
       "      <td>540</td>\n",
       "      <td>330</td>\n",
       "      <td>19.8</td>\n",
       "      <td>222</td>\n",
       "      <td>1200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07.00004</td>\n",
       "      <td>15.9932</td>\n",
       "      <td>76.9423</td>\n",
       "      <td>1.044</td>\n",
       "      <td>665</td>\n",
       "      <td>933</td>\n",
       "      <td>799</td>\n",
       "      <td>13.8</td>\n",
       "      <td>62</td>\n",
       "      <td>1075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07.00005</td>\n",
       "      <td>16.4966</td>\n",
       "      <td>76.9564</td>\n",
       "      <td>0.5</td>\n",
       "      <td>186</td>\n",
       "      <td>396</td>\n",
       "      <td>263</td>\n",
       "      <td>17.7</td>\n",
       "      <td>35</td>\n",
       "      <td>1068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>16.02941</td>\n",
       "      <td>-74.8539</td>\n",
       "      <td>-11.8971</td>\n",
       "      <td>0.101</td>\n",
       "      <td>4779</td>\n",
       "      <td>5058</td>\n",
       "      <td>4922</td>\n",
       "      <td>33.9</td>\n",
       "      <td>275</td>\n",
       "      <td>405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>16.02942</td>\n",
       "      <td>-78.4438</td>\n",
       "      <td>-0.697071</td>\n",
       "      <td>1.564</td>\n",
       "      <td>4703</td>\n",
       "      <td>5818</td>\n",
       "      <td>5134</td>\n",
       "      <td>28.1</td>\n",
       "      <td>210</td>\n",
       "      <td>2130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>16.02943</td>\n",
       "      <td>-78.4414</td>\n",
       "      <td>-0.670835</td>\n",
       "      <td>0.243</td>\n",
       "      <td>5103</td>\n",
       "      <td>5580</td>\n",
       "      <td>5330</td>\n",
       "      <td>31.5</td>\n",
       "      <td>354</td>\n",
       "      <td>874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>16.02944</td>\n",
       "      <td>-78.428</td>\n",
       "      <td>-0.68772</td>\n",
       "      <td>9.337</td>\n",
       "      <td>4536</td>\n",
       "      <td>5864</td>\n",
       "      <td>5080</td>\n",
       "      <td>26.3</td>\n",
       "      <td>109</td>\n",
       "      <td>2419</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>16.02945</td>\n",
       "      <td>-78.4491</td>\n",
       "      <td>-0.680813</td>\n",
       "      <td>2.526</td>\n",
       "      <td>4806</td>\n",
       "      <td>5863</td>\n",
       "      <td>5283</td>\n",
       "      <td>29.5</td>\n",
       "      <td>275</td>\n",
       "      <td>1766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64134 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RGIId   CenLon    CenLat   Area  Zmin  Zmax  Zmed Slope Aspect  Lmax  \\\n",
       "0     07.00001  17.0347   76.7052  0.597   142   459   268  16.7    204  1388   \n",
       "1     07.00002  16.1891   76.7872  0.581   234   582   343  18.3    277  1658   \n",
       "2     07.00003  16.3915   76.9194  0.388   157   540   330  19.8    222  1200   \n",
       "3     07.00004  15.9932   76.9423  1.044   665   933   799  13.8     62  1075   \n",
       "4     07.00005  16.4966   76.9564    0.5   186   396   263  17.7     35  1068   \n",
       "...        ...      ...       ...    ...   ...   ...   ...   ...    ...   ...   \n",
       "2934  16.02941 -74.8539  -11.8971  0.101  4779  5058  4922  33.9    275   405   \n",
       "2935  16.02942 -78.4438 -0.697071  1.564  4703  5818  5134  28.1    210  2130   \n",
       "2936  16.02943 -78.4414 -0.670835  0.243  5103  5580  5330  31.5    354   874   \n",
       "2937  16.02944  -78.428  -0.68772  9.337  4536  5864  5080  26.3    109  2419   \n",
       "2938  16.02945 -78.4491 -0.680813  2.526  4806  5863  5283  29.5    275  1766   \n",
       "\n",
       "      NaN  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "...   ...  \n",
       "2934  NaN  \n",
       "2935  NaN  \n",
       "2936  NaN  \n",
       "2937  NaN  \n",
       "2938  NaN  \n",
       "\n",
       "[64134 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RGI_07 = pd.read_csv('/home/sa42/data/glac/glims/glims_extra/dump2/07_rgi60_Svalbard.csv',\n",
    "                 encoding = 'ISO-8859-1')\n",
    "\n",
    "RGI_10 = pd.read_csv('/home/sa42/data/glac/glims/glims_extra/dump2/10_rgi60_NorthAsia.csv',\n",
    "                 encoding='ISO-8859-1')\n",
    "\n",
    "RGI_16 = pd.read_csv('/home/sa42/data/glac/glims/glims_extra/dump2/16_rgi60_LowLatitudes.csv',\n",
    "                 encoding='ISO-8859-1')\n",
    "\n",
    "# RGI_13 has an extra value in it somewhere and causes token error when read.\n",
    "# open the file, count the columns, name the columns their number.\n",
    "# this ended up causing the original column names to be shunted to the first row.\n",
    "# rename columns to first entry, index 0, and reset index\n",
    "with open('/home/sa42/data/glac/glims/glims_extra/dump2/13_rgi60_CentralAsia.csv','r') as f:\n",
    "    col_count = [ len(l.split(',')) for l in f.readlines() ]\n",
    "column_names = [i for i in range(0, max(col_count))]\n",
    "df = pd.read_csv('/home/sa42/data/glac/glims/glims_extra/dump2/13_rgi60_CentralAsia.csv',\n",
    "                 header=None, delimiter=',',names=column_names)\n",
    "col_names = list(df.iloc[0])\n",
    "df = pd.read_csv('/home/sa42/data/glac/glims/glims_extra/dump2/13_rgi60_CentralAsia.csv',\n",
    "                 header=None, delimiter=',', names=col_names)\n",
    "df.drop(0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "RGI_13 = df\n",
    "\n",
    "# put all RGI tables into one RGI table.\n",
    "RGI = pd.concat([RGI_07,RGI_10,RGI_13,RGI_16])\n",
    "RGI['RGIId'] = RGI['RGIId'].str[6:]\n",
    "RGI = RGI.drop([\n",
    "    'GLIMSId',\n",
    "    'BgnDate',\n",
    "    'EndDate',\n",
    "    'O1Region',\n",
    "    'O2Region',\n",
    "    'Status',\n",
    "    'Connect',\n",
    "    'Form',\n",
    "    'TermType',\n",
    "    'Surging',\n",
    "    'Linkages',\n",
    "    'Name'\n",
    "],axis=1)\n",
    "RGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Merge RGI and GlaThiDa along the RGI-ID\n",
    "The output will include the above GlaThiDa fields, as well as Zmin, Zmax, Zmed, Aspect, and Lmax from RGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>AREA</th>\n",
       "      <th>MEAN_SLOPE</th>\n",
       "      <th>MEAN_THICKNESS</th>\n",
       "      <th>MAXIMUM_THICKNESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>15.4854</td>\n",
       "      <td>77.0272</td>\n",
       "      <td>0.418</td>\n",
       "      <td>323</td>\n",
       "      <td>587</td>\n",
       "      <td>422</td>\n",
       "      <td>18.8</td>\n",
       "      <td>144</td>\n",
       "      <td>1084</td>\n",
       "      <td>77.027200</td>\n",
       "      <td>15.485400</td>\n",
       "      <td>0.37000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>17.6978</td>\n",
       "      <td>78.1071</td>\n",
       "      <td>39.032</td>\n",
       "      <td>110</td>\n",
       "      <td>773</td>\n",
       "      <td>445</td>\n",
       "      <td>9.5</td>\n",
       "      <td>87</td>\n",
       "      <td>13945</td>\n",
       "      <td>78.107100</td>\n",
       "      <td>17.697800</td>\n",
       "      <td>28.59000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18.2064</td>\n",
       "      <td>78.1851</td>\n",
       "      <td>39.995</td>\n",
       "      <td>131</td>\n",
       "      <td>694</td>\n",
       "      <td>482</td>\n",
       "      <td>10.2</td>\n",
       "      <td>232</td>\n",
       "      <td>12142</td>\n",
       "      <td>78.185100</td>\n",
       "      <td>18.206400</td>\n",
       "      <td>39.96000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>14.0691</td>\n",
       "      <td>77.9714</td>\n",
       "      <td>6.737</td>\n",
       "      <td>195</td>\n",
       "      <td>521</td>\n",
       "      <td>336</td>\n",
       "      <td>10.1</td>\n",
       "      <td>56</td>\n",
       "      <td>3780</td>\n",
       "      <td>77.971400</td>\n",
       "      <td>14.069100</td>\n",
       "      <td>6.73700</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>90.481773</td>\n",
       "      <td>69.485641</td>\n",
       "      <td>0.078</td>\n",
       "      <td>805</td>\n",
       "      <td>934</td>\n",
       "      <td>859</td>\n",
       "      <td>26.3</td>\n",
       "      <td>9</td>\n",
       "      <td>237</td>\n",
       "      <td>47.065194</td>\n",
       "      <td>85.563635</td>\n",
       "      <td>3.07800</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>99.881000000</td>\n",
       "      <td>38.214000000</td>\n",
       "      <td>0.495</td>\n",
       "      <td>4328</td>\n",
       "      <td>4765</td>\n",
       "      <td>4545</td>\n",
       "      <td>25.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1051</td>\n",
       "      <td>38.214000</td>\n",
       "      <td>99.881000</td>\n",
       "      <td>0.53680</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>97.755000000</td>\n",
       "      <td>39.237000000</td>\n",
       "      <td>2.531</td>\n",
       "      <td>4317</td>\n",
       "      <td>5113</td>\n",
       "      <td>4797</td>\n",
       "      <td>19.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3007</td>\n",
       "      <td>39.237000</td>\n",
       "      <td>97.755000</td>\n",
       "      <td>2.96629</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>79.894</td>\n",
       "      <td>41.78</td>\n",
       "      <td>6.595</td>\n",
       "      <td>3802</td>\n",
       "      <td>5698</td>\n",
       "      <td>4598</td>\n",
       "      <td>30.0</td>\n",
       "      <td>194</td>\n",
       "      <td>5814</td>\n",
       "      <td>41.780000</td>\n",
       "      <td>79.894000</td>\n",
       "      <td>1.55417</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>84.391</td>\n",
       "      <td>43.731</td>\n",
       "      <td>1.099</td>\n",
       "      <td>3495</td>\n",
       "      <td>3901</td>\n",
       "      <td>3627</td>\n",
       "      <td>17.2</td>\n",
       "      <td>28</td>\n",
       "      <td>1492</td>\n",
       "      <td>43.731000</td>\n",
       "      <td>84.391000</td>\n",
       "      <td>1.24651</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>88.356</td>\n",
       "      <td>43.784</td>\n",
       "      <td>6.078</td>\n",
       "      <td>3415</td>\n",
       "      <td>5201</td>\n",
       "      <td>4233</td>\n",
       "      <td>24.7</td>\n",
       "      <td>172</td>\n",
       "      <td>7215</td>\n",
       "      <td>43.784000</td>\n",
       "      <td>88.356000</td>\n",
       "      <td>6.07800</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-68.1064</td>\n",
       "      <td>-16.3023</td>\n",
       "      <td>0.649</td>\n",
       "      <td>4877</td>\n",
       "      <td>5302</td>\n",
       "      <td>5134</td>\n",
       "      <td>27.0</td>\n",
       "      <td>209</td>\n",
       "      <td>1057</td>\n",
       "      <td>-16.302300</td>\n",
       "      <td>-68.106400</td>\n",
       "      <td>0.30970</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CenLon          CenLat            Area   Zmin   Zmax   Zmed  \\\n",
       "61          15.4854         77.0272           0.418    323    587    422   \n",
       "136         17.6978         78.1071          39.032    110    773    445   \n",
       "142         18.2064         78.1851          39.995    131    694    482   \n",
       "247         14.0691         77.9714           6.737    195    521    336   \n",
       "365       90.481773       69.485641           0.078    805    934    859   \n",
       "366    99.881000000    38.214000000           0.495   4328   4765   4545   \n",
       "367    97.755000000    39.237000000           2.531   4317   5113   4797   \n",
       "368          79.894           41.78           6.595   3802   5698   4598   \n",
       "369          84.391          43.731           1.099   3495   3901   3627   \n",
       "370          88.356          43.784           6.078   3415   5201   4233   \n",
       "371        -68.1064        -16.3023           0.649   4877   5302   5134   \n",
       "\n",
       "     Slope Aspect    Lmax        LAT        LON      AREA  MEAN_SLOPE  \\\n",
       "61    18.8    144    1084  77.027200  15.485400   0.37000        19.0   \n",
       "136    9.5     87   13945  78.107100  17.697800  28.59000         3.0   \n",
       "142   10.2    232   12142  78.185100  18.206400  39.96000         3.0   \n",
       "247   10.1     56    3780  77.971400  14.069100   6.73700         6.0   \n",
       "365   26.3      9     237  47.065194  85.563635   3.07800        17.0   \n",
       "366   25.6      3    1051  38.214000  99.881000   0.53680        24.0   \n",
       "367   19.2      2    3007  39.237000  97.755000   2.96629        21.0   \n",
       "368   30.0    194    5814  41.780000  79.894000   1.55417        10.0   \n",
       "369   17.2     28    1492  43.731000  84.391000   1.24651        20.0   \n",
       "370   24.7    172    7215  43.784000  88.356000   6.07800        25.0   \n",
       "371   27.0    209    1057 -16.302300 -68.106400   0.30970        21.0   \n",
       "\n",
       "     MEAN_THICKNESS  MAXIMUM_THICKNESS  \n",
       "61             27.0               82.0  \n",
       "136            74.0              212.0  \n",
       "142            85.0              285.0  \n",
       "247            65.0              191.0  \n",
       "365            23.0              122.0  \n",
       "366            16.0               66.0  \n",
       "367            41.0              121.0  \n",
       "368            29.0              148.0  \n",
       "369            15.0               72.0  \n",
       "370            58.0              177.0  \n",
       "371            22.0               48.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = glathida.index[glathida['GLACIER_DB']=='RGI']\n",
    "glathida = glathida.loc[idx]\n",
    "glathida.rename(columns = {'GLACIER_ID':'RGIId'},inplace=True)\n",
    "\n",
    "RGI_glathida = pd.merge(RGI,glathida, how = 'inner', on='RGIId')\n",
    "# passing the colulmns instead of dropping columns eliminates the NaN column from RGI13\n",
    "RGI_glathida = RGI_glathida[[\n",
    "#     'RGIId',\n",
    "    'CenLon',\n",
    "    'CenLat',\n",
    "    'Area',\n",
    "    'Zmin',\n",
    "    'Zmax',\n",
    "    'Zmed',\n",
    "    'Slope',\n",
    "    'Aspect',\n",
    "    'Lmax',\n",
    "#     'GlaThiDa_ID',\n",
    "#     'GLACIER_DB',\n",
    "    'LAT',\n",
    "    'LON',\n",
    "    'AREA',\n",
    "    'MEAN_SLOPE',\n",
    "    'MEAN_THICKNESS',\n",
    "    'MAXIMUM_THICKNESS'\n",
    "]]\n",
    "RGI_glathida = RGI_glathida.dropna()\n",
    "RGI_glathida\n",
    "# RGI_glathida=RGI_glathida.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate out features - what will be trained to predict desired attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset and reserve some to test what was trained.\n",
    "train_dataset = RGI_glathida.sample(frac=0.8, random_state=0)\n",
    "test_dataset = RGI_glathida.drop(train_dataset.index)\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "#define label - attribute training to be picked\n",
    "train_labels = train_features.pop('MAXIMUM_THICKNESS')\n",
    "test_labels = test_features.pop('MAXIMUM_THICKNESS')\n",
    "# train_features.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tensor = tf.convert_to_tensor(y, dtype=tf.int64) \n",
    "\n",
    "# RGI_glathida = pd.to_numeric(RGI_glathida)\n",
    "# RGI_glathida = tf.convert_to_tensor(RGI_glathida, dtype=tf.int64) \n",
    "# RGI_glathida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Setup the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_593777/1397724477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         distribute=False)\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m                **kwargs):\n\u001b[1;32m    234\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    237\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_single_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python-cartopy-f/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "normalizer = {}\n",
    "variable_list = (\n",
    " 'LAT',\n",
    " 'LON',\n",
    " 'AREA',\n",
    " 'MEAN_SLOPE',\n",
    " 'MEAN_THICKNESS',\n",
    " 'CenLon',\n",
    " 'CenLat',\n",
    " 'Aspect',\n",
    " 'Area',\n",
    " 'Zmin',\n",
    " 'Zmax',\n",
    " 'Zmed',\n",
    " 'Slope',\n",
    " 'Lmax'\n",
    ")\n",
    "for variable_name in variable_list:\n",
    "\n",
    "    normalizer[variable_name] = preprocessing.Normalization(input_shape=[1,], axis=None)\n",
    "    normalizer[variable_name].adapt(np.array(train_features[variable_name]))\n",
    "    \n",
    "    \n",
    "normalizer['ALL'] = preprocessing.Normalization(axis=-1)\n",
    "normalizer['ALL'].adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single variable linear regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glacierml\n",
    "\n",
    "def build_linear_model(normalizer):\n",
    "    model = tf.keras.Sequential([\n",
    "        normalizer,\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "        loss='mean_absolute_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_single_model_variable(x, y,feature_name):\n",
    "    plt.scatter(train_features[feature_name], train_labels, label='Data')\n",
    "    plt.plot(x, y, color='k', label='Predictions')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Avg Thickness (m)')\n",
    "#     plt.xlim((0,20))\n",
    "    plt.legend()\n",
    "      \n",
    "def plot_loss(history):\n",
    "#     plt.subplots(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #   plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "linear_model = {}\n",
    "linear_history = {}\n",
    "linear_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for variable_name in variable_list:\n",
    "\n",
    "    linear_model[variable_name] = build_linear_model(normalizer[variable_name])\n",
    "    linear_history[variable_name] = linear_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=1000,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    \n",
    "    \n",
    "    linear_results[variable_name] = linear_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)\n",
    "\n",
    "linear_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:    \n",
    "    df = pd.DataFrame(linear_history[variable_name].history)\n",
    "    dfs = df.loc[[df.last_valid_index()]]\n",
    "    dfs.insert(0, 'Variable', [variable_name])\n",
    "    \n",
    "    print(dfs)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ing_theme_matplotlib import mpl_style\n",
    " \n",
    "def plot(dark):\n",
    "  mpl_style(dark)\n",
    "  plt.plot([1, 3, 9, 5, 2, 1, 1], marker='o')\n",
    "  plt.plot([4, 5, 5, 7, 9, 8, 6], marker='o')\n",
    " \n",
    "  plt.show()\n",
    " \n",
    "plot(dark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,6,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    mpl_style(\"dark\")\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plot_loss(linear_history[variable_name])\n",
    "    ax.set_title(variable_name)\n",
    "#     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = build_linear_model(normalizer['ALL'])\n",
    "\n",
    "history_full = linear_model.fit(\n",
    "train_features, train_labels,        \n",
    "   epochs=1000,\n",
    "   verbose=0,\n",
    "   validation_split = 0.2)\n",
    "\n",
    "test_results['MULTI'] = linear_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history_full.history)\n",
    "dfs = df.loc[[df.last_valid_index()]]\n",
    "dfs.insert(0, 'Variable', 'Multi-Variable')\n",
    "    \n",
    "print(dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_full)\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_full_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model(norm):\n",
    "    model = keras.Sequential([\n",
    "              norm,\n",
    "              layers.Dense(64, activation='relu'),\n",
    "              layers.Dense(64, activation='relu'),\n",
    "              layers.Dense(1) ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def dnn_test_results(feature_name):\n",
    "    dnn_test_results[feature_name] = dnn_model.evaluate(\n",
    "        test_features[feature_name],\n",
    "        test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "dnn_model = {}\n",
    "dnn_history = {}\n",
    "dnn_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:\n",
    "\n",
    "    dnn_model[variable_name] = build_dnn_model(normalizer[variable_name])\n",
    "    dnn_history[variable_name] = dnn_model[variable_name].fit(\n",
    "                                        train_features[variable_name], train_labels,        \n",
    "                                        epochs=1000,\n",
    "                                        verbose=0,\n",
    "                                        validation_split = 0.2)\n",
    "    dnn_results[variable_name] = dnn_model[variable_name].evaluate(\n",
    "                                        test_features[variable_name],\n",
    "                                        test_labels, verbose=0)\n",
    "\n",
    "dnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_name in variable_list:    \n",
    "    df = pd.DataFrame(dnn_history[variable_name].history)\n",
    "    dfs = df.loc[[df.last_valid_index()]]\n",
    "    dfs.insert(0, 'Variable', [variable_name])\n",
    "    \n",
    "    print(dfs)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    xmax = np.max(train_features[variable_name])\n",
    "    xmin = np.min(train_features[variable_name])\n",
    "    x = tf.linspace(xmin, xmax, 101)\n",
    "    y = dnn_model[variable_name].predict(x)\n",
    "    plot_single_model_variable(x,y,variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(10,10))\n",
    "for i, variable_name in enumerate(variable_list):\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plot_loss(dnn_history[variable_name])\n",
    "    ax.set_title(variable_name)\n",
    "#     plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_loss.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_full_model = build_dnn_model(normalizer['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dnn_history_full = dnn_full_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dnn_history_full.history)\n",
    "dfs = df.loc[[df.last_valid_index()]]\n",
    "dfs.insert(0, 'Variable', 'Multi-Variable')\n",
    "    \n",
    "print(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(dnn_history_full)\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_dnn_full_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dnn_full_model.predict(test_features)\n",
    "plt.plot(test_labels,y,'.')\n",
    "plt.plot((0,200),(0,200),'-')\n",
    "plt.xlabel('True Thickness (m)')\n",
    "plt.ylabel('Model Thickness (m)')\n",
    "plt.xlim((0,200))\n",
    "plt.ylim((0,200))\n",
    "# plt.savefig(\"/home/sa42/notebooks/glac/figs/GTP1_res.EPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (Cartopy)-f",
   "language": "python",
   "name": "python-cartopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
